[
  {
    "path": "posts/2022-02-19-glm1/",
    "title": "GLM1",
    "description": "General Linear Modeling",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": {}
      }
    ],
    "date": "2022-02-19",
    "categories": [
      "Bayesian Statistics",
      "BGLM"
    ],
    "contents": "\n\nContents\nBayesian alternative to t-test\nTraditional t-test\nBayesian approach 1: normal model\nBayesian approach 2: generalized student’s t model\nBayesian approach 3: log-normal model\nสรุป\n\nBayesian alternative to ANOVA (BANOVA)\nOne-Way BANOVA\nMultiple Comparison\nTwo-Way BANOVA\nBANOVA package\n\nBayesian Regression\nExploring data\n\nModel Checking and Comparison\nResiduals\nPosterior Predictive Check\nPosterior Predictive P-value (PPP)\nDeviance\nDeviance Information Criterion (DIC)\nWAIC and LOO\nสรุป\n\n\nBayesian alternative to t-test\nกิจกรรมนี้จะกล่าวถึงการใช้สถิติแบบเบส์สำหรับการวิเคราะห์เพื่อเปรียบเทียบค่าเฉลี่ยสองกลุ่ม ผู้อ่านจะเห็นว่าการวิเคราะห์แบบเบส์เป็นวิธีการที่ให้สารสนเทศเกี่ยวกับความแตกต่างของค่าเฉลี่ยระหว่างตัวอย่างสองกลุ่มที่มากกว่าการทดสอบ t-test แบบดั้งเดิม\nการเปรียบเทียบด้วยวิธีการแบบเบส์ทำให้ผู้วิเคราะห์สามารถประมาณการแจกแจงความน่าจะเป็นภายหลัง ซึ่งเป็นข้อมูลสำคัญสำหรับการคำนวณช่วงความน่าเชื่อถือ (credible intervals) ของพารามิเตอร์ต่าง ๆ ได้แก่ ค่าเฉลี่ย ส่วนเบี่ยงเบนมาตรฐาน รวมทั้งความแตกต่างระหว่างค่าเฉลี่ย ส่วนเบี่ยงเบนมาตรฐาน และขนาดอิทธิพล\nผลการทดสอบเพื่อเปรียบเทียบความแตกต่างของค่าเฉลี่ยสามารถตัดสินใจได้ทั้ง การยอมรับสมมุติฐานหลัก (accept null hypothesis) และยอมรับสมมุติฐานทางเลือก (accept alternative hypothesis) ซึ่งแตกต่างและมีความยืดหยุ่นมากกว่าการทดสอบเพื่อเปรียบเทียบค่าเฉลี่ยแบบดั้งเดิมอย่างมาก\nTraditional t-test\nสมมุติว่านักวิจัยต้องการเปรียบเทียบความแตกต่างของผลสัมฤทธิ์ทางการเรียนวิชาคณิตศาสตร์ และทักษะการแก้ปัญหา ระหว่างนักเรียนที่ได้รับการสอนแบบบรรยาย และแบบใช้ปัญหาเป็นฐาน ข้อมูลค่าสังเกตเป็นดังนี้\n\n\nset.seed(1253)\ndat<-data.frame(Ach=c(rnorm(50,50,5),rnorm(50,48,15)),\n                Solve=c(rt(50,3,0)*5+50,rt(50,3,0)*10+70),\n                Method=c(rep(1,50),rep(2,50)))\nhead(dat)\n\n\n       Ach    Solve Method\n1 57.88928 50.01438      1\n2 51.20072 49.48460      1\n3 43.34361 43.94092      1\n4 55.12593 48.40898      1\n5 45.35700 50.11348      1\n6 53.47266 56.45850      1\n\ntail(dat)\n\n\n         Ach    Solve Method\n95  57.27558 59.71888      2\n96  55.89447 71.65605      2\n97  54.42124 66.07296      2\n98  50.62769 70.03023      2\n99  44.82859 79.04969      2\n100 46.05098 99.74767      2\n\nsummary(dat)\n\n\n      Ach            Solve            Method   \n Min.   :20.93   Min.   : 28.48   Min.   :1.0  \n 1st Qu.:43.60   1st Qu.: 49.28   1st Qu.:1.0  \n Median :49.68   Median : 57.62   Median :1.5  \n Mean   :49.06   Mean   : 60.96   Mean   :1.5  \n 3rd Qu.:55.05   3rd Qu.: 70.84   3rd Qu.:2.0  \n Max.   :80.01   Max.   :117.62   Max.   :2.0  \n\nโดยที่ Ach และ Solve คือผลสัมฤทธ์และทักษะการแก้ปัญหาตามลำดับ ส่วน TMethod = 1 คือกลุ่มนักเรียนที่ได้รับการสอนแบบบรรยาย และ TMethod = 2 คือกลุ่มนักเรียนที่ได้รับการสอนแบบใช้ปัญหาเป็นฐาน\n\n\npar(mfrow=c(1,2))\nplot(density(dat$Ach[1:50]),type=\"l\", main=\"Ach\", xlim=c(0,100), lty=1)\npoints(density(dat$Ach[51:100]),type=\"l\", main=\"\", lty=2)\nlegend(0,0.06, legend=c(\"LEC\",\"PBL\"),lty=c(1,2), bty=\"n\")\n\nplot(density(dat$Solve[1:50]),type=\"l\", main=\"Solve\", xlim=c(0,100), lty=1)\npoints(density(dat$Solve[51:100]),type=\"l\", main=\"\", lty=2)\nlegend(0,0.04, legend=c(\"LEC\",\"PBL\"),lty=c(1,2), bty=\"n\")\n\n\n\n\nหากทำการวิเคราะห์ด้วยสถิติทดสอบ t-test แบบดั้งเดิม พบว่าได้ผลการวิเคราะห์ดังนี้\n\n\n    Welch Two Sample t-test\n\ndata:  Ach by Method\nt = 1.9067, df = 66.984, p-value = 0.06085\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.179778  7.852900\nsample estimates:\nmean in group 1 mean in group 2 \n       50.97567        47.13911 \n\n    Welch Two Sample t-test\n\ndata:  Solve by Method\nt = -9.0266, df = 70.811, p-value = 2.144e-13\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -27.47607 -17.53326\nsample estimates:\nmean in group 1 mean in group 2 \n       49.70763        72.21230 \n\nผลการวิเคราะห์ที่ได้จาก t-test ข้างต้นให้สารสนเทศใดแก่ผู้วิเคราะห์บ้าง?\nBayesian approach 1: normal model\nการเปรียบเทียบค่าเฉลี่ยด้วยวิธีการแบบเบส์สามารถทำได้หลายวิธีการ วิธีการหนึ่งที่สามารถทำได้อาจกำหนดโมเดลดังรูปด้านล่าง\n\nจากรูปจะเห็นว่ามีการกำหนดโมเดลให้กับค่าสังเกตในแต่ละกลุ่มเป็นการแจกแจงแบบปกติที่มีค่าเฉลี่ยเท่ากับ \\(\\mu_1\\) และ \\(\\mu2\\) และพารามิเตอร์ความเที่ยงตรงเท่ากับ \\(\\tau_1\\) และ \\(\\tau_2\\) ตามลำดับ และ\nPrior Distributions\nการกำหนดการแจกแจงความน่าจะเป็นเบื้องต้นให้กับพารามิเตอร์ต่าง ๆ ของโมเดลค่าสังเกต โดยพารามิเตอร์ค่าเฉลี่ยมีการแจกแจงความน่าจะเป็นเบื้องต้นเป็นการแจกแจงแบบปกติ ส่วนพารามิเตอร์ความเที่ยงตรงมีการแจกแจงความน่าจะเป็นเบื้องต้นเป็นแบบแกมมา (Gamma distribution)\nการแจกแจงแบบแกมมา มีพารามิเตอร์กำกับการแจกแจง 2 ตัวได้แก่ shape และ rate parameters ซึ่งเขียนแทนด้วยสัญลักษณ์ \\(\\alpha>0\\) และ \\(\\beta >0\\) และมีฟังก์ชันความน่าจะเป็นดังนี้\n\\(p(\\theta)=\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\theta^{\\alpha-1}exp\\{-\\beta \\theta \\}\\) โดยที่ \\(\\theta>0\\)\nรูปต่อไปนี้แสดงตัวอย่างการแจกแจงความน่าจะเป็นแบบแกมมา เมื่อกำหนดพารามิเตอร์เป็นค่าต่าง ๆ\n\n\npar(mfrow=c(1,2), mar=c(5,5,1,1))\ntheta<-seq(0,5,0.01)\nplot(theta, dgamma(theta,1,1), type=\"l\", col=2, ylab=\"Density\", xlab=expression(tau))\npoints(theta, dgamma(theta,2,1), type=\"l\", col=3)\npoints(theta, dgamma(theta,3,1), type=\"l\", col=4)\npoints(theta, dgamma(theta,5,1), type=\"l\", col=5)\n\nplot(theta, dgamma(theta,1,2), type=\"l\", col=2, ylab=\"Density\", xlab=expression(tau))\npoints(theta, dgamma(theta,1,4), type=\"l\", col=3)\npoints(theta, dgamma(theta,1,6), type=\"l\", col=4)\npoints(theta, dgamma(theta,1,10), type=\"l\", col=5)\n\n\n\n\nแนวทางการกำหนดค่าพารามิเตอร์ในการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ความเที่ยงตรง (\\(\\tau\\)) การทำได้สองลักษณะ ลักษณะแรกคือ noninformative prior อาจกำหนดให้พารามิเตอร์ \\(\\alpha\\) และ \\(\\beta\\) มีค่าน้อย ๆ เช่น dgamma(0.01,0.01) หรือ dgamma(0.001,0.001) รูปด้านล่างแสดงตัวอย่างของการแจกแจงดังกล่าว\n\n\npar(mar=c(5,3,1,1))\ntheta<-seq(0,5,0.01)\nplot(theta, dgamma(theta,0.01,0.01), type=\"l\", col=2, ylab=\"Density\", xlab=expression(tau))\n\n\n\n\nอีกลักษณะหนึ่งคือการกำหนดให้มีสารสนเทศในการแจกแจงความน่าจะเป็นก่อนหน้า โดยอาจมองว่าพารามิเตอร์ \\(\\alpha\\) มีค่าเท่ากับฐานนิยมของ \\(\\tau\\) และ \\(\\beta\\) มีค่าเท่ากับส่วนเบี่ยงเบนมาตรฐานของ \\(\\tau\\) (Kruschke, 2012)\nกิจกรรม 1\nดำเนินการวิเคราะห์ข้อมูลเพื่อเปรียบเทียบค่าเฉลี่ยผลสัมฤทธิ์และทักษะการแก้ปัญหาทางคณิตศาสตร์ ระหว่างกลุ่มนักเรียนที่ได้รับการสอนแบบบรรยายและใช้ปัญหาเป็นฐาน ด้วยวิธีการแบบเบส์ โดยใช้การกำหนดโมเดลข้างต้น แล้วตอบคำถามต่อไปนี้\nตัวอย่างพารามิเตอร์ที่จำลองจากอัลกอริทึม MCMC มีคุณสมบัติที่เหมาะสมสำหรับนำไปวิเคราะห์เพื่อตอบคำถามข้างต้นหรือไม่ เพราะเหตุใด\nผลการวิเคราะห์เพื่อเปรียบเทียบความแตกต่างของผลสัมฤทธิ์และทักษะการแก้ปัญหาทางคณิตศาสตร์ระหว่างกลุ่มนักเรียนทั้งสองกลุ่มเป็นอย่างไร?\nสารสนเทศที่ได้จากการวิเคราะห์ด้วยสถิติแบบเบส์ กับสถิติแบบดั้งเดิมมีความแตกต่างกันอย่างไร\nBayesian approach 2: generalized student’s t model\nการกำหนดโมเดลสำหรับวิเคราะห์ข้อมูลด้วยสถิติแบบเบส์สามารถกำหนดได้อย่างหลากหลาย กล่าวคือในปัญหาเดียวกันหากผู้วิเคราะห์มีมุมมองหรือกรอบแนวคิดที่แตกต่างกันก็สามารถกำหนดโมเดลการวิเคราะห์ที่แตกต่างกันได้ รูปด้านล่างแสดงการกำหนดโมเดลสำหรับเปรียบเทียบค่าเฉลี่ยสองกลุ่มในอีกลักษณะหนึ่ง\n เมื่อเปรียบเทียบกับโมเดลที่ 1 ที่ได้ดำเนินการวิเคราะห์ไปแล้ว นิสิตคิดว่าโมเดลนี้มีความเหมือนและแตกต่างไปจากเดิมอย่างไรบ้าง?\nทั้งนี้การแจกแจงความน่าจะเป็นแบบทีดังกล่าวเป็นอีก version หนึ่งเรียกว่า Generalized student’s t distribution ซึ่งมีพารามิเตอร์กำกับการแจกแจง 3 ตัวได้แก่ ค่าเฉลี่ย ส่วนเบี่ยงเบนมาตรฐาน และองศาความเป็นอิสระ (\\(\\nu>0\\)) และมีฟังก์ชันความน่าจะเป็นดังนี้\n\\(p(y|\\mu, \\sigma, \\nu)=\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})\\sqrt{\\pi\\nu}\\sigma}(1+\\frac{1}{\\nu}(\\frac{y-\\mu}{\\sigma})^2)^{-\\frac{\\nu+1}{2}}\\)\nการเลือกใช้การแจกแจงแบบทีเป็นโมเดลค่าสังเกตมีข้อดีกว่าการแจกแจงแบบปกติคือ การแจกแจงแบบทีเป็นการแจกแจงที่มีส่วนปลาย (หาง) ของการแจกแจงที่หนากว่าการแจกแจงแบบปกติ ซึ่งทำให้โมเดลของค่าสังเกตมีความแกร่งต่อการเกิดค่าผิดปกติ (outlier) มากกว่าโมเดลที่ใช้การแจกแจงแบบปกติ ความหนา ณ ส่วนปลายของการแจกแจงแบบทีสามารถกำหนดผ่านค่าพารามิเตอร์องศาความเป็นอิสระ (\\(\\nu\\)) โดยถ้า \\(\\nu\\) ยิ่งมีค่าน้อย การแจกแจงทีจะยิ่งมีส่วนปลายที่หนาขึ้น ในทางกลับกันหาก \\(\\nu\\) มีค่ามาก การแจกแจงทีดังกล่าวจะลู่เข้าหาการแจกแจงแบบปกติ กล่าวได้ว่าโมเดลนี้เป็นกรณีทั่วไปของ model 1 ที่ได้กล่าวไว้ก่อนหน้านี้นั่นเอง รูปต่อไปนี้แสดงฟังก์ชันความหนาแน่นของการแจกแจงความน่าจะเป็นแบบที เมื่อมีองศาความเป็นอิสระต่าง ๆ กัน\n\n\npar(mar=c(5,5,1,1))\nx<-seq(-6,6,0.01)\nplot(x, dnorm(x,0,1), type=\"l\", lty=1, ylab=\"Density\")\npoints(x, dt(x,1), type=\"l\",lty=2)\npoints(x, dt(x,2), type=\"l\",lty=3)\npoints(x, dt(x,3), type=\"l\",lty=4)\npoints(x, dt(x,5), type=\"l\",lty=5)\npoints(x, dt(x,10), type=\"l\",lty=6)\n\ntext(0,0.1, \"t-Distribution\")\ntext(2, 0.38, \"Normal Distriibution\")\n\n\n\n\nกิจกรรม 2\nดำเนินการวิเคราะห์ข้อมูลเพื่อเปรียบเทียบค่าเฉลี่ยผลสัมฤทธิ์และทักษะการแก้ปัญหาทางคณิตศาสตร์ ระหว่างกลุ่มนักเรียนที่ได้รับการสอนแบบบรรยายและใช้ปัญหาเป็นฐาน ด้วยวิธีการแบบเบส์ โดยใช้การกำหนดโมเดลข้างต้น แล้วตอบคำถามต่อไปนี้\nตัวอย่างพารามิเตอร์ที่จำลองจากอัลกอริทึม MCMC มีคุณสมบัติที่เหมาะสมสำหรับนำไปวิเคราะห์เพื่อตอบคำถามข้างต้นหรือไม่ เพราะเหตุใด\nผลการวิเคราะห์เพื่อเปรียบเทียบความแตกต่างของผลสัมฤทธิ์และทักษะการแก้ปัญหาทางคณิตศาสตร์ระหว่างกลุ่มนักเรียนทั้งสองกลุ่มเป็นอย่างไร?\nระหว่างโมเดล 1 กับโมเดล 2 โมเดลใดเป็นโมเดลที่เหมาะสมมากกว่า เพราะเหตุใด\nBayesian approach 3: log-normal model\nนอกจากการกำหนดโมเดลการวิเคราะห์ทั้งสอง ผู้วิเคราะห์ยังสามารถกำหนดโมเดลการวิเคราะห์อื่น ๆ ได้อย่างหลากหลาย ทั้งนี้ต้องคำนึงถึงธรรมชาติของข้อมูลและพารามิเตอร์ภายในโมเดลการวิเคราะห์ เช่น หากผู้วิเคราะห์สำรวจข้อมูลแล้วพบว่าข้อมูลคะแนนค่าสังเกตที่ต้องการนำมาวิเคราะห์มีการแจกแจงที่เบ้ขวา (positively skewed) ผู้วิเคราะห์อาจกำหนดโมเดลของค่าสังเกตเป็นการแจกแจงแบบ log-normal โดยอาจเขียนคำสั่งดังนี้\n\n\n\"model{\n  \n  for(i in 1:n)\n  {\n    #log-normal likelihood\n    y[i]~dlnorm(mu[x[i]],tau[x[i]])\n  }\n  \n  for(j in 1:2)\n  {\n    # prior distributions\n    mu[j]~dnorm(0,0.01)\n    tau[j]~dgamma(0.01,0.01)\n    sigma2[j]<-1/tau[j]\n    \n    # calculate mean and sd of the distribution\n    mean[j]<-exp(mu[1]+sigma2[j]/2)\n    sd[j]<- sqrt((exp(sigma2[j])-1)*exp(2*mu[j]+sigma2[j]))\n  }\n\n}\"\n\n\n\nจากชุดคำสั่งระบุโมเดลในข้างต้นจะเห็นว่า การแจกแจง log-normal พารามิเตอร์ \\(\\mu\\) และ \\(\\sigma^2\\) ไม่ใช่พารามิเตอร์ค่าเฉลี่ยและความแปรปรวนของการแจกแจง การคำนวณค่าเฉลี่ย และความแปรปรวนของ log-normal distribution สามารถคำนวณได้ดังนี้ (https://en.wikipedia.org/wiki/Log-normal_distribution)\n\\(Mean = exp(\\mu+\\frac{\\sigma^2}{2})\\)\n\\(Variance = [exp(\\sigma^2)-1]exp(2\\mu+\\sigma^2)\\)\n\n\n\nรูปต่อไปนี้แสดงการตรวจสอบคุณภาพของตัวอย่างข้อมูลจำลองที่สร้างขึ้นจากลูกโซ่มาร์คอฟ จากรูปพบว่าตัวอย่างที่สร้างขึ้นมีลักษณะที่แสดงถึงการลู่เข้าสู่สถานะคงตัว (stationary distribution) เมื่อพิจารณาอัตสหสัมพันธ์ภายในแต่ละลูกโซ่ของพารามิเตอร์พบว่ามีค่าต่ำตั้งแต่ lag ที่ 1 เป็นต้นไป และเมื่อพิจารณาผลจากค่าสถิติ PSRF พบว่ามีค่าเท่ากับ 1 ในทุกพารามิเตอร์ นั่นหมายความว่า ลูกโซ่ของพารามิเตอร์ภายในโมเดลที่สร้างขึ้นพารามิเตอร์ละ 3 ชุดนั้น มีการลู่เข้าหาการแจกแจงสถานะคงตัวเดียวกัน ผลการวิเคราะห์ทั้งหมดนี้บ่งชี้ว่าตัวอย่างลูกโซ่ที่จำลองขึ้นจากกระบวนการสุ่มนี้มีคุณภาพที่ดี และน่าจะเป็นตัวอย่างของพารามิเตอร์ที่สุ่มจากการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ\n\n\n             mean[1]      mean[2]        sd[1]       sd[2]\nLag 0    1.000000000  1.000000000  1.000000000 1.000000000\nLag 10   0.002117818 -0.001586005 -0.004173995 0.001063236\nLag 50  -0.006628564 -0.007791238 -0.002182255 0.005589014\nLag 100  0.010180744  0.008790487  0.005640398 0.005188884\nLag 500 -0.002266881 -0.008254212 -0.002178094 0.001552742\n                 diff    effectsize\nLag 0    1.0000000000  1.0000000000\nLag 10   0.0000929066  0.0008682332\nLag 50  -0.0029025030 -0.0068767664\nLag 100  0.0033541139  0.0056011177\nLag 500 -0.0076327141 -0.0127589617\n\n\nเมื่อพิจารณาผลการวิเคราะห์สำหรับเปรียบเทียบค่าเฉลี่ยพบว่า ค่าเฉลี่ยภายหลังของพารามิเตอร์ค่าเฉลี่ยผลสัมฤทธิ์ในกลุ่มบรรยายและใช้ปัญหาเป็นฐาน มีค่าเท่ากับ 51.02 และ 52.99 คะแนน และมีค่าเฉลี่ยภายหลังของพารามิเตอร์ส่วนเบี่ยงเบนมาตรฐานของผลสัมฤทธิ์เป็น 6.23 และ 14.54 คะแนน ตามลำดับ นอกจากนี้ยังพบว่าส่วนเบี่ยงเบนมาตรฐานภายหลังของพารามิเตอร์ทั้ง 4 ภายในโมเดล มีค่าอยู่ในช่วง 0.66 - 1.85 ตามลำดับ คิดเป็นสัมประสิทธิ์การแปรผันภายหลังของพารามิเตอร์อยู่ในช่วงร้อยละ 1.72 - 12.72 แสดงให้เห็นว่าการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์มีความน่าเชื่อถืออยู่ในระดับที่รับได้\n\n                  mean          sd    95%_HPDL    95%_HPDU Rhat n.eff\nmean[1]    51.02448835 0.885342263 49.25368528 52.72227133    1 15000\nmean[2]    52.98708630 1.041930856 50.93246816 54.98998247    1 15000\nsd[1]       6.22197429 0.666306969  4.99772705  7.56166670    1 15000\nsd[2]      14.53318175 1.845666077 11.23820707 18.27661074    1 15000\ndiff       -1.96259795 0.513099955 -2.97031454 -1.04145854    1 15000\neffectsize -0.04676912 0.008715738 -0.06439884 -0.03034028    1 14778\n\nเมื่อพิจารณาความแตกต่างของค่าเฉลี่ยผลสัมฤทธิ์ระหว่างวิธีการสอนทั้งสองพบว่า มีค่าเฉลี่ยภายหลังของผลต่างเท่ากับ -1.96 คะแนน เมื่อพิจารณาการแจกแจงความน่าจะเป็นภายหลังของขนาดอิทธิพลประกอบพบว่า ขนาดอิทธิพลที่คำนวณจากสูตรของ Cohen มีการแจกแจงความน่าจะเป็นภายหลังอยู่บนช่วงประมาณ -0.08 ถึง -0.02 ซึ่งถือว่าเป็นขนาดอิทธิพลในระดับที่ต่ำมาก\n\n\n\nสรุป\nจากตัวอย่างทั้ง 3 จะเห็นว่า การวิเคราะห์แบบเบส์นี้ผู้วิเคราะห์สามารถเลือกกำหนดโมเดลได้ค่อนข้างหลากหลาย ขึ้นอยู่กับความเหมาะสมและวิจารณญาณของผู้วิเคราะห์ ปัญหาที่ตามมาคือหากในปัญหาเดียวกันผู้วิเคราะห์สมมุติฐานหรือโมเดลการวิเคราะห์ที่มากกว่า 1 โมเดลแล้ว จะทราบได้อย่างไรมากโมเดลใดเป็นโมเดลที่มีความเหมาะสมมากที่สุด ??\nBayesian alternative to ANOVA (BANOVA)\nหัวข้อนี้จะกล่าวถึงการวิเคราะห์ความแปรปรวนแบบเบส์ รายละเอียดมีดังนี้\nOne-Way BANOVA\nนักวิจัยทดลองใช้วิธีการสอน 4 วิธี กับนักเรียนจำนวน 4 กลุ่มที่มีการวิเคราะห์แล้วว่ามีพื้นฐานใกล้เคียงกัน เมื่อสอนจบตามแผนแล้วมีการวัดผลการเรียนรู้ภายหลัง ได้ผลดังนี้\n\n\nlec\n\n\npbl\n\n\ncop\n\n\ndem\n\n\n5\n\n\n11\n\n\n6\n\n\n3\n\n\n6\n\n\n8\n\n\n9\n\n\n4\n\n\n7\n\n\n7\n\n\n8\n\n\n1\n\n\n3\n\n\n7\n\n\n5\n\n\n1\n\n\n7\n\n\n9\n\n\n4\n\n\n4\n\n\n5\n\n\n7\n\n\n4\n\n\n5\n\n\n2\n\n\n8\n\n\n7\n\n\n2\n\n\n4\n\n\n10\n\n\n6\n\n\n3\n\n\nโมเดลการวิเคราะห์ความแปรปรวนทางเดียวสามารถเขียนได้สองลักษณะ ลักษณะแรกเรียกว่า mean model เขียนได้ดังนี้\n\\(y_{ij}=\\mu_j+\\epsilon_{ij}\\)\nอีกลักษณะหนึ่งคือ effect model\n\\(y_{ij}=\\alpha+\\beta_j+\\epsilon_{ij}\\) เมื่อ \\(\\sum_{j=1}^J\\beta_j=0\\) และ \\(\\alpha\\) คือ grand mean ดังนั้น \\(alpha+beta_j=\\mu_j\\) ก็คือ group mean\nรูปด้านล่างแสดงโมเดลค่าสังเกตแบบ effect model\n #### กิจกรรม 3\nวิเคราะห์ ANOVA เพื่อเปรียบเทียบค่าเฉลี่ยของชุดข้อมูลข้างต้น\nวิเคราะห์ BANOVA เพื่อเปรียบเทียบค่าเฉลี่ยของชุดข้อมูลข้างต้น\nผลการวิเคราะห์จากทั้งสองวิธีให้สารสนเทศที่เหมือนหรือแตกต่างกันอย่างไร?\nผลการวิเคราะห์แบบ Traditional\nเป็นแบบฝึกหัดให้ผู้อ่าน\nผลการวิเคราะห์แบบ Bayesian\nส่วนจัดการข้อมูลนำเข้า\n\n\n# dataset\nmethod<-gl(4,8) #teaching method\nJ<-4 #number of groups\nn<-32 #number of individual per group\nach<-c(lec, pbl, cop, dem)\ndataList<-list(y=ach, x=method, J=J, n=n)\n\n\n\nคำสั่งระบุโมเดลข้างล่างเขียนในลักษณะ effect model จะเห็นว่าการประมาณค่า treatment effect (beta) ในโมเดล ไม่ได้ประมาณอย่างอิสระทั้ง 4 กลุ่ม แต่จะประมาณเพียง 3 กลุ่ม แล้วใช้ผลการประมาณดังกล่าวมาเป็นค่าประมาณของกลุ่มที่เหลือ ที่ต้องเขียนในลักษณะนี้เป็นเพราะเงื่อนไขของ effect model ที่มีการ constraint พารามิเตอร์ treatment effect ดังกล่าว (\\(\\sum_{j=1}^J\\beta_j=0\\))\n\n\n\"model{\n\n#likelihood function\nfor(i in 1:n)\n{\ny[i]~dnorm(mu[i], tau) #homogeneity of variance model\nmu[i]<-alpha+beta[x[i]] #effects model\n}\n\n\n#prior distribution\ntau ~ dgamma(0.01,0.01)\nsigma<-1/sqrt(tau) #root mean square of the ANOVA model (RMSE)\nalpha~dnorm(0,0.01) #grand mean\n\nfor (j in 2:J)\n{\nbeta[j]~dnorm(0,0.01)\n}\n\nbeta[1]<- -(sum(beta[2:J]))\n\n}\"\n\n\n\n\n\n\n\n\nfit.banova<-run.jags(method=\"parallel\",\n                        model=banova,\n                        monitor=c(\"mean\",\"sigma\"),\n                        data=dataList,\n                        n.chains=3,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE,\n                        keep.jags.files = FALSE,\n                        silent.jags = T)\n\nsamples<-as.mcmc.list(fit.banova)\n\n\n\nผลการตรวจสอบคุณภาพของลูกโซ่ใน output ด้านขวาแสดงให้เห็นว่า ตัวอย่างลูกโซ่มีคุณภาพที่ดี และสามารถใช้เพื่อประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ภายในโมเดลได้\n\n\nMCMCtrace(samples, pdf=F)\n\n\n\nautocorr.diag(samples)\n\n\n             mean[1]      mean[2]      mean[3]       mean[4]\nLag 0    1.000000000  1.000000000  1.000000000  1.0000000000\nLag 3   -0.010322228  0.009402559  0.003240864  0.0007744016\nLag 15   0.004295750 -0.007530674 -0.001217727  0.0036276692\nLag 30   0.005091883  0.002204231 -0.012416509  0.0026950145\nLag 150 -0.006132002  0.000456659 -0.006595624 -0.0038344416\n                sigma\nLag 0    1.000000e+00\nLag 3   -1.638865e-04\nLag 15   1.030252e-02\nLag 30   5.322524e-06\nLag 150  9.192150e-03\n\nเมื่อพิจารณาผลการวิเคราะห์การแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ที่สำคัญภายในโมเดลพบว่า กลุ่มที่ได้รับการสอนแบบโครงงาน เป็นกลุ่มที่มีแนวโน้มที่จะมีคะแนนสอบสูงสุด โดยมีค่าเฉลี่ยคะแนนสอบที่คิดจากค่าเฉลี่ยภายหลังเท่ากับ 8.35 คะแนน (SD = 0.607) รองลงมาคือกลุ่มที่ได้รับวิธีการสอนแบบร่วมมือ มีค่าเฉลี่ยภายหลังเท่ากับ 6.12 คะแนน (SD = 0.605) และพบว่ากลุ่มที่ได้รับการสอนแบบสาธิตเป็นกลุ่มที่มีค่าเฉลี่ยภายหลังต่ำที่สุด โดยมีค่าเท่ากับ 2.89 คะแนน (SD = 0.605)\n\n\nMCMCsummary(samples, HPD=TRUE)\n\n\n            mean        sd 95%_HPDL 95%_HPDU Rhat n.eff\nmean[1] 4.869796 0.6035584  3.67108  6.04177    1 30916\nmean[2] 8.359963 0.6063316  7.12061  9.51072    1 29456\nmean[3] 6.116177 0.6087424  4.94823  7.33789    1 30000\nmean[4] 2.879811 0.6107672  1.67712  4.08693    1 30000\nsigma   1.700276 0.2378854  1.28503  2.18564    1 29595\n\nMultiple Comparison\nการวิเคราะห์ BANOVA ไม่จำเป็นต้องทำการทดสอบภาพรวมแบบการทดสอบ F-test ใน ANOVA ทั้งนี้เป็นเพราะ BANOVA ใช้การแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์เป็นเครื่องมือในการอนุมานเชิงสถิติ ซึ่งเป็นการแจกแจงที่อยู่ในปริภูมิของพารามิเตอร์โดยตรง และไม่ได้มีการเปลี่ยนแปลงแม้ว่าจำนวนคู่ของการเปรียบเทียบจะมีมากหรือน้อยก็ตาม ขอบเขตและความหนาแน่นของพารามิเตอร์ก็ยังเหมือนเดิม ดังนั้น BANOVA จึงสามารถทำการเปรียบเทียบรายคู่ (multiple comparison) ได้โดยที่ไม่จำเป็นต้องผ่านการทดสอบภาพรวมก่อน\nนอกจากการเปรียบเทียบแบบรายคู่แล้ว BANOVA ยังสามารถทำการวิเคราะห์เปรียบเทียบแบบไม่ใช่รายคู่ (non-pairwise comparison) ได้อีกด้วย ตัวอย่างด้านล่างแสดงการเขียนคำสั่งเพื่อสร้าง contrast สำหรับการเปรียบเทียบค่าเฉลี่ยผลสัมฤทธิ์ระหว่างคู่ของวิธีการสอนที่สนใจ ประกอบด้วย\nc1: PBL vs PBL\nc2: LEC vs DEM\nc3: LEC vs COP\nc4: PBL vs average of (LEC, DEM and COP)\n\n\n#banova with constrast\nbanova<-\"model{\n#likelihood function\n\nfor(i in 1:n)\n{\ny[i]~dnorm(mu[i], tau) #homogeneity of variance model\nmu[i]<-alpha+beta[x[i]] #effects model\n}\n\n#prior distribution\ntau ~ dgamma(0.01,0.01)\nsigma<-1/sqrt(tau) #root mean square of the ANOVA model (RMSE)\nalpha~dnorm(0,0.01) #grand mean\n\nfor (j in 2:J)\n{\nbeta[j]~dnorm(0,0.01)\n}\nbeta[1]<- -sum(beta[2:J])\n\n#define contrast\nc1<-beta[2]-beta[1] #pbl vs lec\nc2<-beta[1]-beta[4] #lec vs dem\nc3<-beta[1]-beta[3] #lec vs cop\nc4<-beta[2]-mean(beta[c(1,3,4)]) #pbl vs average of lec dem and cop\n}\"\n\nfit.banova<-run.jags(method=\"parallel\",\n                        model=banova,\n                        monitor=c(\"alpha\",\"beta\",\"sigma\",\"c1\",\"c2\",\"c3\",\"c4\"),\n                        data=dataList,\n                        n.chains=3,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE,\n                        keep.jags.files = FALSE,\n                        silent.jags = T)\n\n\nCalling 3 simulations using the parallel method...\nAll chains have finished\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nFinished running the simulation\n\nsamples<-as.mcmc.list(fit.banova)\nsamples.dat<-data.frame(as.matrix(samples))\n\n\n\nผลการวิเคราะห์ด้านล่างแสดงให้เห็นว่า มีเพียงการเปรียบเทียบเชิงเส้นที่ใช้เปรียบเทียบค่าเฉลี่ยคะแนนสอบของนักเรียนระหว่างกลุ่มที่ได้รับการจัดการเรียนการสอนด้วยวิธีบรรยายกับร่วมมือ ที่พบว่าช่วงความน่าเชื่อถือที่มีความหนาแน่นสูงสุด 95% มีค่าศูนย์อยู่บนช่วง ซึ่งบ่งชี้ว่าค่าเฉลี่ยคะแนนสอบระหว่างสองกลุ่มดังกล่าวมีค่าไม่แตกต่างกัน\n\n\nMCMCsummary(samples, params=c(\"c1\",\"c2\",\"c3\",\"c4\"), HPD = TRUE)\n\n\n        mean        sd  95%_HPDL 95%_HPDU Rhat n.eff\nc1  3.497851 0.8534245  1.783160 5.149180    1 29639\nc2  1.990585 0.8580990  0.313451 3.685220    1 30307\nc3 -1.239713 0.8559952 -2.951090 0.417758    1 31201\nc4  3.748142 0.6972171  2.366640 5.117360    1 28800\n\n\n\nsummary<-MCMCsummary(samples, params=c(\"c1\",\"c2\",\"c3\",\"c4\"), HPD = TRUE)\npar(mfrow=c(2,2))\nhist(samples.dat$c1, col=\"orange\", border=\"white\", main=\"\", xlab=\"c1: pbl vs lec\", freq=F)\nabline(v=0, lty=2)\nlines(x=c(summary[1,3],summary[1,4]), y=c(0.01,0.01), lwd=3)\ntext(mean(samples.dat$c1),0.05, \"95% HDI\")\n\nhist(samples.dat$c2, col=\"orange\", border=\"white\", main=\"\", xlab=\"c1: lec vs dem\", freq=F)\nabline(v=0, lty=2)\nlines(x=c(summary[2,3],summary[2,4]), y=c(0.01,0.01), lwd=3)\ntext(mean(samples.dat$c2),0.05, \"95% HDI\")\n\nhist(samples.dat$c3, col=\"orange\", border=\"white\", main=\"\", xlab=\"c1: lec vs cop\", freq=F)\nabline(v=0, lty=2)\nlines(x=c(summary[3,3],summary[3,4]), y=c(0.01,0.01), lwd=3)\ntext(mean(samples.dat$c3),0.05, \"95% HDI\")\n\nhist(samples.dat$c4, col=\"orange\", border=\"white\", main=\"\", xlab=\"c1: pbl vs average\", freq=F, xlim=c(0,7))\nabline(v=0, lty=2)\nlines(x=c(summary[4,3],summary[4,4]), y=c(0.01,0.01), lwd=3)\ntext(mean(samples.dat$c4),0.05, \"95% HDI\")\n\n\n\n\nTwo-Way BANOVA\nการวิเคราะห์ความแปรปรวนสองทางทั้งที่มีและไม่มีอิทธิพลปฏิสัมพันธ์สามารถทำได้โดยขยายแนวคิดของ One-Way ANOVA\nชุดข้อมูลตัวอย่าง\n\n\nlibrary(foreign)\ndat<-read.spss(\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-19-glm1/manova.sav\", to.data.frame=TRUE)\nhead(dat)\n\n\n  id gender     schsize location cognitiveE EmotionalE BehavioralE\n1  1  woman       small  นอกเมือง   3.666667   4.857143         4.0\n2  2  woman       small  นอกเมือง   3.666667   4.428571         3.2\n3  3  woman       large  นอกเมือง   2.916667   3.000000         3.6\n4  4    man       large  นอกเมือง   3.083333   3.000000         3.6\n5  5    man extra large  นอกเมือง   3.000000   3.142857         2.8\n6  6    man       large  นอกเมือง   3.833333   4.000000         4.0\n\nBANOVA package\nการวิเคราะห์ด้วย JAGs ถึงแม้จะมีความยืดหยุ่นสูงแต่ก็อาจมีความลำบากในการเขียน syntax ทั้งในส่วนของโมเดล และส่วนของการวิเคราะห์ ปัจจุบันโปรแกรม R มี package จำนวนมากที่ถูกพัฒนาขึ้นสำหรับการวิเคราะห์เพื่ออนุมานเชิงสถิติแบบเบส์ในโมเดลต่าง ๆ\nBANOVA เป็น pacakge หนึ่งที่มีประโยชน์สำหรับการอนุมานเชิงสถิติแบบเบส์โดยเฉพาะในการวิจัยเชิงทดลองที่มักมีการใช้การวิเคราะหืความแปรปรวนเป็นเครื่องมือหลักในการวิเคราะห์อิทธิพลของปัจจัยในการทดลองที่มีต่อตัวแปรตามที่สนใจ รายละเอียดต่าง ๆ ของ package สามารถอ่านเพิ่มเติมได้จาก https://www.jstatsoft.org/article/view/v081i09\nBayesian Regression\nชุดข้อมูลตัวอย่าง\n\n\ndat<-read.csv(\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-19-glm1/regression_dat1.csv\")\nhead(dat)\n\n\n  X Hour Class.Behav Home.Status Teach.Qua Score\n1 1    6         3.3        poor       bad  39.8\n2 2   11         3.7        poor       bad  59.6\n3 3    6         4.8        poor      good  50.8\n4 4   11         3.7      normal       bad  50.9\n5 5   10         1.3        poor      good  67.9\n6 6    2         3.1      normal       bad  26.0\n\nExploring data\nการวิเคราะห์เบื้องต้นด้วยทัศนภาพข้อมูลจะเห็นว่าตัวแปรอิสระเกือบทุกตัว ยกเว้น Teach.Qua มีแนวโน้มที่จะมีความสัมพันธ์เชิงเส้นกับตัวแปรตาม Score\n\n\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\ndat%>%mutate(Home.Status=ifelse(Home.Status==\"poor\",0,1),\n              Teach.Qua=ifelse(Teach.Qua==\"bad\",0,1))%>%\n  pivot_longer(cols=c(\"Hour\",\"Class.Behav\",\"Home.Status\",\"Teach.Qua\"), \n                   names_to=\"predictors\",\n                   values_to = \"predictor.value\")%>%\n  ggplot()+\n  geom_point(aes(x=predictor.value, y=Score))+\n  facet_wrap(.~predictors, scale=\"free\")+\n  theme_minimal()\n\n\n\n\nจากผลการวิเคราะห์ข้างต้นผู้วิเคราะห์ลอง fit regression model โดยใส่ตัวแปรอิสระทุกตัวเข้าสู่โมเดล\n\n\n#model syntax\n\n\"model{\n\nfor(i in 1:n)\n{\ny[i]~dnorm(mu[i],tau)\nmu[i]<-b0+b1*x1+b2*x2+b3*x3+b4*x4\n}\n\nb0~dnorm(0,0.01)\nb1~dnorm(0,0.01)\nb2~dnorm(0,0.01)\nb3~dnorm(0,0.01)\nb4~dnorm(0,0.01)\n\ntau~dunif(0,100)\nsigma<-1/sqrt(tau)\n}\"\n\n\n\n\n\n\n\n\ndataList<-list(y=dat$Score, x1=dat$Hour, x2=dat$Class.Behav, \n               x3=ifelse(dat$Home.Status==\"poor\",0,1),\n               x4=ifelse(dat$Teach.Qua==\"bad\",0,1),\n               n=dim(dat)[1])\n\nfit.reg<-run.jags(model=reg.model,\n                  data=dataList,\n                  monitor=c(\"b0\",\"b1\",\"b2\",\"b3\",\"b4\",\"sigma\"),\n                  n.chains=3,\n                  sample = 10000,\n                  thin=3,\n                  summarise=TRUE,\n                  plots=FALSE,\n                  keep.jags.files = FALSE)\n\n\nCompiling rjags model...\nCalling the simulation using the rjags method...\nAdapting the model for 1000 iterations...\nBurning in the model for 4000 iterations...\nRunning the model for 30000 iterations...\nSimulation complete\nCalculating summary statistics...\nCalculating the Gelman-Rubin statistic for 6 variables....\nFinished running the simulation\n\nsample<-as.mcmc.list(fit.reg)\nMCMCtrace(sample, pdf=F)\n\n\n\nMCMCsummary(sample, HPD=TRUE)\n\n\n           mean        sd   95%_HPDL  95%_HPDU Rhat n.eff\nb0    -5.306458 0.9835980 -7.2365907 -3.401244    1  7388\nb1     3.768245 0.1014221  3.5650456  3.962646    1 10708\nb2     4.677324 0.2335245  4.2163536  5.140814    1 12132\nb3     1.895899 0.6888546  0.5633311  3.255703    1 27373\nb4    19.646335 0.6754420 18.3315031 20.973072    1 25622\nsigma  6.659164 0.2374420  6.2071374  7.130879    1 30000\n\nModel Checking and Comparison\nอย่างที่กล่าวไปบ้างแล้ว การตรวจสอบความเหมาะสมของโมเดลนั้นเป็นกระบวนการที่ผู้วิเคราะห์ใช้เพื่อพิจารณาว่าโมเดลการวิเคราะห์ (หรือสมมุติฐานของผู้วิเคราะห์) ที่กำหนดขึ้นนั้นมีความสอดคล้องกับปรากฏการณ์จริงที่ทำการศึกษาหรือไม่\nโมเดลที่มีความเหมาะสมนั้น หมายถึงโมเดลที่สามารถใช้เป็นตัวแทนหรือประมาณปรากฏการณ์จริงที่ต้องการศึกษาได้อยู่ในระดับที่ดี อย่างไรก็ตามในความเป็นจริงเป็นไปได้ยากมากที่โมเดลดังกล่าวจะเป็นโมเดลจริงในประชากรที่ทำการศึกษา\nการตรวจสอบความสอดคล้องของโมเดลที่ประมาณค่าด้วยวิธีการแบบเบส์นั้นมีความแตกต่างไปจากวิธีการแบบดั้งเดิม ทั้งนี้เป็นเพราะสถิติแบบเบส์ใช้การแจกแจงความน่าจะเป็นภายหลัง (posterior distributions) เป็นเครื่องมือประมาณค่าพารามิเตอร์ต่าง ๆ ภายในโมเดล ดังนั้นดัชนีต่าง ๆ หรือการตรวจสอบความเหมาะสมของโมเดลดังกล่าว จึงจะอิงจากการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ภายในโมเดลทั้งหมด อีกปัจจัยหนึ่งที่มีผลต่อประสิทธิภาพของโมเดลวิเคราะห์คือ การแจกแจงความน่าจะเป็นเบื้องต้น (prior distributions) การตรวจสอบความไวที่ไม่ได้ตั้งใจให้เกิดขึ้นจากการกำหนดการแจกแจงความน่าจะเป็นเบื้องต้น รวมทั้งความไม่เข้ากันระหว่างการแจกแจงความน่าจะเป็นเบื้องต้นกับข้อมูลเชิงประจักษ์จึงเป็นสิ่งที่ผู้วิเคราะห์อาจจำเป็นต้องตรวจสอบด้วย\nการตรวจสอบความเหมาะสมของโมเดลแบบเบส์ด้วยวิธีการเชิงคณิตศาตร์ทำได้ยากมาก แต่สามารถทำได้ง่ายด้วยเทคนิค MCMC หัวข้อนี้จะกล่าวถึงดัชนี และวิธีการสำคัญหลายตัวที่สามารถใช้ประเมินความเหมาะสมของโมเดล\nResiduals\nเศษเหลือ (residuals) เป็นค่าที่ใช้วัดความเบี่ยงเบนระหว่างค่าสังเกต (\\(y_i\\)) กับค่าทำนาย/ค่าประมาณที่ได้จากโมเดลวิเคราะห์ ในอุดมคติแล้วค่าเศษเหลือนี้ควรคำนวณโดยใช้ค่าสังเกตคนละชุดกับค่าสังเกตที่ใช้ประมาณพารามิเตอร์ในโมเดลวิเคราะห์ เรียกว่า out-sample residuals (ในทางกลับกันเศษเหลือที่คำนวณจากค่าสังเกตชุดเดียวกับที่ใช้ประมาณค่าพารามิเตอร์ในโมเดลจะเรียกว่า in-sample residuals)\nในทำนองเดียวกับการวิเคราะห์แบบดั้งเดิม ในการวิเคราะห์แบบเบส์สามารถใช้การวิเคราะห์เศษเหลือ (residuals analysis) เพื่อตรวจสอบความเหมาะสมของโมเดลได้เหมือนกัน เช่น การวิเคราะห์ residual plot ระหว่างเศษเหลือกับค่าทำนาย หรือ residual plot ระหว่างเศษเหลือกับตัวแปรอิสระ หรือการตรวจสอบการแจกแจงของเศษเหลือว่าเป็นไปตามข้อสมมุติของโมเดลหรือไม่ รายละเอียดมีดังนี้\nStandardized Pearson Residuals\nคะแนนเศษเหลือมาตรฐานสามารถคำนวณได้ดังนี้\n\\(r_i(\\theta)=\\frac{y_i-E(y_i|\\theta)}{\\sqrt{Var(y_i|\\theta)}}\\)\nจะเห็นว่าเศษเหลือดังกล่าวก็เป็นฟังก์ชันที่ขึ้นกับค่าพารามิเตอร์ของโมเดล ดังนั้นเศษเหลือของแต่ละค่าสังเกตที่ \\(i\\) จึงมีการแจกแจง posterior เช่นเดียวกับพารามิเตอร์และค่าทำนายของโมเดล\n\n\nlibrary(ggplot2)\nlibrary(gridExtra)\ndat<-read.csv(\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-19-glm1/regression_dat1.csv\")\n\np1<-ggplot(dat)+geom_point(aes(x=Class.Behav, y=Score))+xlab(\"Class Behavior\")\np2<-ggplot(dat)+geom_boxplot(aes(x=factor(Teach.Qua), y=Score))+xlab(\"Teaching Quality\")\ngrid.arrange(p1,p2, ncol=2)\n\n\n\n\n\n\nreg.mod1<-\"model{\n\nfor(i in 1:n)\n{\ny[i]~dnorm(mu[i],tau)\nmu[i]<-b0+b1*x1[i]+b2*x2[i]\n\n#calculate residual\nresid[i]<-(y[i]-mu[i])/sigma\n}\n\n## x1 = Class.Behav\n## x2 = Teach.Qua\n\n# priors\nb0~dnorm(0,0.01)\nb1~dnorm(0,0.01)\nb2~dnorm(0,0.01)\ntau~dgamma(0.01,0.01)\n\nsigma<-sqrt(1/tau)\n}\"\n\nx2<-ifelse(dat$Teach.Qua==\"good\",1,0)\ndataList<-list(y=dat$Score, x1=dat$Class.Behav, x2=x2, n=dim(dat)[1])\nfit.reg<-run.jags(method=\"parallel\",\n                        model=reg.mod1,\n                        monitor=c(\"b0\",\"b1\",\"b2\",\"sigma\",\"resid\"),\n                        data=dataList,\n                        n.chains=3,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE,\n                        keep.jags.files = FALSE,\n                        silent.jags = TRUE)\n\n\nCalling 3 simulations using the parallel method...\nAll chains have finished\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nNote: Summary statistics were not produced as there are >50\nmonitored variables\n[To override this behaviour see ?add.summary and\n?runjags.options] FALSEFinished running the simulation\n\nsamples<-data.frame(as.matrix(as.mcmc.list(fit.reg)))\n\n\n\nรูปต่อไปนีแสดงการแจกแจงภายหลังของเศษเหลือของค่าสังเกตทั้งหมด\n\n\nlibrary(tidyr)\nsamples%>%\n  pivot_longer(cols=starts_with(\"resid\"),names_to=\"resid\", values_to=\"resid.val\")%>%\n  ggplot()+\n  geom_boxplot(aes(x=factor(resid), y=resid.val),\n               outlier.alpha= 0)+\n  geom_hline(yintercept=0)\n\n\n\n\nจะเห็นว่าข้อมูลของเศษเหลือในโมเดลที่ได้จากอัลกอริทึม MCMC มีปริมาณมาก และทำให้มีความลำบากในการวิเคราะห์ อีกวิธีการหนึ่งคือผู้วิเคราะห์อาจใช้ค่าเฉลี่ยภายหลังของพารามิเตอร์เพื่อคำนวณค่าเศษเหลือ หรือใช้ค่าเฉลี่ยภายหลังของเศษเหลือเองในการวิเคราะห์เศษเหลือ ดังตัวอย่างต่อไปนี้\n\n\n# posterior mean of intercept\nb0<-colMeans(samples[,1:3])[1]\nb0\n\n\n      b0 \n18.70508 \n\n# posterior mean of slope b1\nb1<-colMeans(samples[,1:3])[2]\nb1\n\n\n      b1 \n4.509844 \n\n# posterior mean of slope b2\nb2<-colMeans(samples[,1:3])[3]\nb2\n\n\n      b2 \n20.32643 \n\n#calculate predictive value from posterior mean of parameters\ny.hat<-b0+b1*dat$Class.Behav+b2*x2\n#calculate standardized residuals\nresid<-(dat$Score-y.hat)/mean(samples$sigma)\n\npar(mfrow=c(2,2))\nplot(y.hat, resid, pch=16, xlab=\"Fitted values\",ylab=\"Standardized Residuals\", col=\"skyblue\")\nabline(h=0, lty=2)\n\nhist(resid, col=\"skyblue\", main=\"\")\n\nqqnorm(resid)\nqqline(resid)\n\nplot(y.hat, resid^2, pch=16, xlab=\"Fitted values\",ylab=\"Standardized Residuals^2\", col=\"skyblue\")\nabline(lm(resid^2~y.hat), lty=2)\n\n\n\n\nผลการวิเคราะห์เศษเหลือข้างต้นจะเห็นว่า โมเดล reg.mod1 มีปัญหาความไม่เหมาะสมของโมเดล กล่าวคือมีหลักฐานว่าอาจเกิดปัญหา heteroscedasticity ซึ่งสาเหตุของปัญหาดังกล่าวเป็นไปได้ว่าผู้วิเคราะห์อาจยังระบุโมเดลวิเคราะห์ไม่เหมาะสม เช่น อาจลืมตัวแปรอิสระที่สำคัญ หรืออาจละเลยการวิเคราะห์อิทธิพลปฏิสัมพันธ์ เป็นต้น\nกิจกรรม\nจงใช้การวิเคราะห์เศษเหลือตรวจสอบความเหมาะสมของการวิเคราะห์ได้แก่\nการเปรียบเทียบค่าเฉลี่ยสองกลุ่ม\nBANOVA\nPosterior Predictive Check\nposteior predictve check เป็นการตรวจสอบความสอดคล้องเชิงประจักษ์ของโมเดลการวิเคราะห์ ด้วยการเปรียบเทียบกันระหว่างค่าทำนายของตัวแปรตามที่ได้จากโมเดลกับค่าสังเกตจริงจากข้อมูลตัวอย่าง\n\n\nset.seed(1253)\ndat<-data.frame(Ach=c(rnorm(50,50,5),rnorm(50,48,15)),\n                Solve=c(rt(50,3,0)*5+50,rt(50,3,0)*10+70),\n                Method=c(rep(1,50),rep(2,50)))\n\n\n\n\n\n\n\n\ntwosamples<-\"model{\n  #likelihood function\n  for(i in 1:n)\n  {\n    y[i]~dnorm(mu[x[i]],tau[x[i]])\n  }\n  \n  for (j in 1:2)\n  {\n  #prior distribution\n  mu[j]~dnorm(0,0.01)\n  tau[j]~dgamma(0.01,0.01)\n  \n  #deterministic nodes\n  sigma[j]<-sqrt(1/tau[j])\n  }\n  \n}\"\n\n\n\n\n\nlibrary(rjags)\nlibrary(runjags)\nlibrary(coda)\ndataList<-list(y=dat$Ach, x=dat$Method, n=dim(dat)[1])\nfit<-run.jags(method=\"rjparallel\",\n                        model=twosamples,\n                        monitor=c(\"mu\",\"sigma\"),\n                        data=dataList,\n                        n.chains=3,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE,\n                        keep.jags.files = FALSE)\n\n\nCompiling rjags model...\nNote: the model did not require adaptation\nStarting 3 rjags simulations using a Fork cluster with 3 nodes\non host 'localhost'\nSimulation complete\nCalculating summary statistics...\nCalculating the Gelman-Rubin statistic for 4 variables....\nFinished running the simulation\n\nขั้นตอนต่อไปนี้แสดงการสร้าง predictive value จาก posterior distribution โดยสุ่มเลือกค่าพารามิเตอร์ขึ้นมา 1000 ชุด เพื่อสร้าง posterior predictive distribution จำนวน 1000 ชุด โดยที่แต่ละชุดมีค่าสังเกตผลสัมฤทธิ์ทางการเรียนจำนวน 100 ค่า เหมือนกับข้อมูลตัวอย่างตั้งต้น\n\n\nsample<-as.mcmc.list(fit)\nsample<-as.matrix(sample)\ndim(sample)\n\n\n[1] 30000     4\n\nparam.id<-sample(1:30000,1000)\nsample<-sample[param.id,]\n\ny.rep<-matrix(nrow=100,ncol=1000)\nfor(i in 1:1000)\n{\ny1<-rnorm(50, sample[,1], sample[,3])\ny2<-rnorm(50, sample[,2], sample[,4])\ny.rep[,i]<-c(y1,y2)\n}\n\n### example of posterior predictive distribution\npar(mfrow=c(4,4), mar=c(3,1,1,1))\nfor(i in 1:16)\n{\n  hist(y.rep[,i], col=\"skyblue\", border=\"white\", main=\"Posterior Predictive Distribution\", nclass=30)\n}\n\n\n\n\nการใช้งาน posterior predictive distribution คือการพิจารณาว่าการแจกแจง predictive ดังกล่าวมีความลำเอียงไปจากการแจกแจงของข้อมูลค่าสังเกตอย่างมีนัยสำคัญหรือไม่ รูปต่อไปนี้แสดงการเปรียบเทียบระหว่าง posterior predictive ที่สร้างขึ้นกับข้อมูลจริง\n\n\nhist(dat$Ach, col=\"skyblue\", border=\"white\", main=\"\", nclass=30, xlab=\"Ach\", freq=F)\nfor (i in 1:50)\n{\n  points(density(y.rep[,i]), type=\"l\", lty=2, cex=0.5, col=\"black\")\n}\n\n\n\n\nนอกจากการตรวจสอบด้วย visualization ในข้างต้นแล้ว ยังสามารถเปรียบเทียบ posterior predictve กับข้อมูลจริงด้วยค่าสถิติ เช่นการใช้ posterior predictive p-value ดังรายละเอียดในหัวข้อต่อไป\nPosterior Predictive P-value (PPP)\nbayesian p-value เป็นวิธีการหนึ่งที่ใช้นำเสนอความแตกต่างระหว่างค่าสังเกตจริงกับค่าทำนายของโมเดล การคำนวณค่า bayesian p-value สามารถทำได้หลายลักษณะขึ้นอยู่กับค่าสถิติที่เลือกใช้ นิยามของค่า PPP เป็นดังนี้\n\\(PPP = P(T(y^{rep}) \\geq T(y))\\)\nเมื่อ \\(T(.)\\) คือ discrepancy measures หรือ test quantiles ที่จะใช้เป็นตัวเปรียบเทียบระหว่างการแจกแจงของ posterior predictive กับ observed value การกำหนด test quantile ดังกล่าวสามารถทำได้หลายลักษณะและไม่ได้มีกฎเกณฑ์ตายตัว ขึ้นอยู่กับว่าผู้วิเคราะห์ต้องการสารสนเทศในเชิงการเปรียบเทียบแบบใด ค่า test quantile ที่มักใช้ได้แก่ ค่าต่ำสุด ค่าสูงสุด ค่าเฉลี่ย และส่วนเบี่ยงเบนมาตรฐาน ตัวอย่างต่อไปนี้แสดงการคำนวณค่า PPP ข้างต้น\n\n\nlibrary(dplyr)\nTmax.y<-max(dat$Ach)\nTmax.yrep<-apply(y.rep,2,max)\n\nhist(Tmax.yrep, col=\"skyblue\", xlab=\"max Y.rep\", border=\"white\", nclass=30)\nabline(v=Tmax.y, col=\"red\", lty=1)\n\n\n\nppp<-table(Tmax.yrep>Tmax.y)%>%prop.table()\nppp[2] #PPP value\n\n\n TRUE \n0.235 \n\n\n\nTmin.y<-min(dat$Ach)\nTmin.yrep<-apply(y.rep,2,min)\nhist(Tmin.yrep, col=\"skyblue\", xlab=\"max Y.rep\", border=\"white\", nclass=30)\nabline(v=Tmin.y, col=\"red\", lty=1)\n\n\n\nppp<-table(Tmin.yrep>Tmin.y)%>%prop.table()\nppp[2] #PPP value\n\n\n TRUE \n0.161 \n\nจากนิยามของ PPP ข้างต้นจะเห็นว่าหาก PPP มีค่าเข้าใกล้ 0 หรือ 1 นั่นหมายความว่าโมเดลการวิเคราะห์สร้าง predictive value ที่มีความแตกต่าง/ลำเอียง ไปจากข้อมูลจริงอย่างมาก ดังนั้น PPP = 0.5 จึงหมายความว่าโมเดลมีความสอดคล้องกับข้อมูลจริงอย่างสมบูรณ์ ในทางปฏิบัติไม่ได้มีการกำหนด cut-off ไว้แน่นอน แต่ค่า cut-off ที่มักใช้กันคือ PPP<0.05,0.1 หรือ PPP>0.90,0.95\nDeviance\nสถิติ deviance เขียนแทนด้วย \\(D(\\theta)\\) เป็นฟังก์ชันของพารามิเตอร์ \\(\\theta\\) ดังสมการ\n\\(D(\\theta)=-2log\\ p(y|\\theta)\\)\nเนื่องจากพารามิิเตอร์ \\(\\theta\\) มีการแจกแจง posterior ดังนั้น deviance ก็จะมีการแจกแจง posterior ด้วยเช่นกัน จากสูตรของ deviance ข้างต้นจะเห็นว่ามีความหมายในลักษณะของความไม่สอดคล้องระหว่างโมเดลกับข้อมูลค่าสังเกต ดังนั้นโมเดลที่มีความเหมาะสมจึงควรมีค่า deviance ต่ำ ๆ อย่างไรก็ตามสถิติ deviance ไม่ได้มีหน่วยตายคัว (ไม่มี absolute unit) ทำให้การแปลความหมายขนาดของค่า deviance ทำได้ยาก การใช้งาน deviance จึงเป็นการใช้งานในลักษณะของการเปรียบเทียบกันระหว่างโมเดลคู่แข่งขัน\nสมมุติว่า ผู้วิเคราะห์ต้องการเปรียบเทียบค่าเฉลี่ยผลสัมฤทธิ์ทางการเรียนระหว่างกลุ่มนักเรียนที่ได้ับการสอนแบบบรรยาย กับใช้ปัญหาเป็นฐาน ผู้วิเคราะห์มีสมมุติฐานว่าโมเดลที่ยอมให้ความแปรปรวนระหว่างกลุ่มมีความแตกต่างกัน (heterogeneity of variances model) น่าจะเป็นโมเดลที่เหมาะสำหรับการเปรียบเทียบค่าเฉลี่ยในกรณีนี้มากกว่าโมเดลที่กำหนดให้ความแปรปรวนระหว่างกลุ่มเท่าเทียมกัน (homogeneity of variances model)\n\n\nset.seed(1253)\ndat<-data.frame(Ach=c(rnorm(50,50,5),rnorm(50,48,15)),\n                Solve=c(rt(50,3,0)*5+50,rt(50,3,0)*10+70),\n                Method=c(rep(1,50),rep(2,50)))\n\nhead(dat)\n\n\n       Ach    Solve Method\n1 57.88928 50.01438      1\n2 51.20072 49.48460      1\n3 43.34361 43.94092      1\n4 55.12593 48.40898      1\n5 45.35700 50.11348      1\n6 53.47266 56.45850      1\n\nเพื่อตรวจสอบสมมุติฐานดังกล่าว ผู้วิเคราะห์จึงรันโมเดลทั้งสองเปรียบเทียบกันดังนี้\nHomogeneity of Variances Model\n\n\n\"model{\n  #likelihood function\n  for(i in 1:n)\n  {\n    y[i]~dnorm(mu[x[i]],tau)\n    \n    # calculate log-lik\n    loglik[i]<- -0.5*log(2*pi)-0.5*log(sigma^2)-(1/(2*sigma^2))*(y[i]-mu[x[i]])^2\n  }\n  \n  for (j in 1:2)\n  {\n  #prior distribution\n  mu[j]~dnorm(0,0.01)\n  \n\n  }\n  \n  tau~dgamma(0.01,0.01)\n  sigma<-sqrt(1/tau)\n  \n  #calculate deviance value\n  deviance<- -2*sum(loglik)\n}\"\n\n\n\n\n\n\nHeterogeneity of Variances Model\n\n\n\"model{\n  #likelihood function\n  for(i in 1:n)\n  {\n    y[i]~dnorm(mu[x[i]],tau[x[i]])\n    \n    # calculate log-lik\n    loglik[i]<- -0.5*log(2*pi)-0.5*log(sigma[x[i]]^2)-(1/(2*sigma[x[i]]^2))*(y[i]-mu[x[i]])^2\n  }\n  \n  for (j in 1:2)\n  {\n  #prior distribution\n  mu[j]~dnorm(0,0.01)\n  tau[j]~dgamma(0.01,0.01)\n  \n  #deterministic nodes\n  sigma[j]<-sqrt(1/tau[j])\n  }\n  \n  #calculate deviance value\n  deviance<- -2*sum(loglik)\n}\"\n\n\n\n\n\n\n\n\nlibrary(rjags)\nlibrary(runjags)\nlibrary(coda)\n\ndataList<-list(y=dat$Ach, x=dat$Method, n=dim(dat)[1], pi=pi)\n\nfit.homo<-run.jags(method=\"parallel\",\n                        model=homo,\n                        monitor=c(\"mu\",\"sigma\",\"deviance\"),\n                        data=dataList,\n                        n.chains=3,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE,\n                        keep.jags.files = FALSE,\n                        silent.jags = TRUE)\n\n\nCalling 3 simulations using the parallel method...\nAll chains have finished\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nFinished running the simulation\n\nfit.hetero<-run.jags(method=\"parallel\",\n                        model=hetero,\n                        monitor=c(\"mu\",\"sigma\",\"deviance\"),\n                        data=dataList,\n                        n.chains=3,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE,\n                        keep.jags.files = FALSE,\n                        silent.jags = TRUE)\n\n\nCalling 3 simulations using the parallel method...\nAll chains have finished\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nFinished running the simulation\n\nsample.homo<-as.mcmc.list(fit.homo)\nsample.hetero<-as.mcmc.list(fit.hetero)\n\n\n\nสถิติสรุป posterior ของ homogeneity of variances model\n\n\nsummary(sample.homo)\n\n\n\nIterations = 5001:34998\nThinning interval = 3 \nNumber of chains = 3 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean     SD Naive SE Time-series SE\nmu[1]     49.94 1.4407 0.008318       0.008309\nmu[2]     46.16 1.4231 0.008217       0.008340\nsigma     10.19 0.7391 0.004267       0.004262\ndeviance 747.49 3.1995 0.018472       0.018722\n\n2. Quantiles for each variable:\n\n            2.5%     25%    50%    75%  97.5%\nmu[1]     47.055  48.992  49.95  50.91  52.71\nmu[2]     43.339  45.219  46.17  47.13  48.89\nsigma      8.877   9.677  10.14  10.66  11.77\ndeviance 743.803 745.149 746.70 748.98 755.86\n\nสถิติสรุป posterior ของ heterogeneity of variances model\n\n\nsummary(sample.hetero)\n\n\n\nIterations = 5001:34998\nThinning interval = 3 \nNumber of chains = 3 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n            Mean     SD Naive SE Time-series SE\nmu[1]     50.627 0.8220 0.004746       0.004746\nmu[2]     45.507 1.8797 0.010852       0.010801\nsigma[1]   5.783 0.5993 0.003460       0.003460\nsigma[2]  13.340 1.3977 0.008070       0.007963\ndeviance 717.405 3.4576 0.019962       0.020210\n\n2. Quantiles for each variable:\n\n            2.5%     25%     50%     75%   97.5%\nmu[1]     49.001  50.082  50.625  51.182  52.236\nmu[2]     41.779  44.264  45.526  46.768  49.147\nsigma[1]   4.752   5.365   5.729   6.149   7.101\nsigma[2]  10.925  12.355  13.216  14.199  16.401\ndeviance 713.043 714.855 716.642 719.109 726.097\n\nผลการวิเคราะห์ posterior distribution ของ โมเดลทั้งสองจะพบว่า โมเดลที่ยอมให้ความแปรปรวนระหว่างกลุ่มมีความแตกต่างกัน มีแนวโน้มที่จะให้ค่า deviance ต่ำกว่าโมเดลที่กำหนดให้ความแปรปรวนระหว่างกลุ่มเท่าเทียมกัน\nรูปต่อไปนี้แสดงการเปรียบเทียบการแจกแจง posterior ของค่าสถิติ deviance ระหว่างโมเดลทั้งสอง ผลการวิเคราะห์เห็นชัดเจนว่า การแจกแจง posterior ของสถิติ deviance ของโมเดล heterogeneity of variances มีแนวโน้มที่จะมีค่าต่ำกว่าโมเดล homogeneity of variance\n\n\ndev.homo<-as.matrix(sample.homo)[,4]\ndev.het<-as.matrix(sample.hetero)[,5]\n\nplot(density(dev.homo), type=\"l\", \n    xlim=c(700,780), main=\" \", \n    xlab=\"deviance\",\n    col=\"blue\")\npoints(density(dev.het), type=\"l\", col=\"red\")\n\n\n\n### Pr(Dev.het < Dev.homo)\np<-table(dev.het < dev.homo)%>%prop.table()\np\n\n\n\nTRUE \n   1 \n\nนอกจากนี้ยังพบว่า \\(P(deviance_{hetero}<deviance_{homo})=1\\) สรุปได้ว่าโมเดล heteogeneity of variances มีความเหมาะสมมากกว่า\nนอกจากการเปรียบเทียบ posterior distribution ของ deviance โดยตรงแล้ว ผู้วิเคราะห์ยังสามารถใช้ค่าสถิติที่คำนวณจาก posterior ของ deviance มาเปรียบเทียบกันได้ด้วย เช่น ค่า posterior mean ของ deviance (เขียนแทนด้วย \\(\\overline{D(\\theta)}\\))\nสถิติ deviance มีข้อจำกัดสำคัญคือ เป็นสถิติที่มักจะเข้าข้างโมเดลที่มีความซับซ้อนมากกว่าเสมอ ซึ่งเพิ่มโอกาสที่จะเลือกโมเดลระบุเกินพอดี (overfitting model) เป็นโมเดลที่เหมาะสม และส่งผลความเป็นนัยทั่วไปของข้อสรุปมีขอบเขตที่ลดลง หัวข้อถัดไปจะกล่าวถึงการแก้ปัญหานี้\nDeviance Information Criterion (DIC)\nการเปรียบเทียบโมเดลแบบดั้งเดิมมีหลายวิธีการ ทั้งการใช้ดัชนีเพื่อเปรียบเทียบ และการทดสอบเพื่อเปรียบเทียบ โดยส่วนใหญ่แล้ววิธีการดังกล่าวเหมาะสำหรับการเปรียบเทียบโมเดลคู่แข่งขันที่เป็น nested model ในกรณีที่ต้องการเปรียบเทียบโมเดลแบบ non-nested อาจใช้ดัชนี AIC (Akaike Information Criterion) มีสูตรดังนี้\n\\(AIC = -2\\ log(y|\\hat{\\theta})+2p = D(\\hat{\\theta})+2p\\)\nโดยที่ \\(\\hat{\\theta}\\) คือค่าประมาณ maximum likelhood (minimum deviance) ของพารามิเตอร์ \\(\\theta\\) ส่วน \\(p\\) คือจำนวนพารามิเตอร์ภายในโมเดล การแปลความหมาย AIC ทำได้ในทำนองเดียวกับ deviance คือโมเดลที่มีค่า AIC ต่ำจะเป็นโมเดลที่เหมาะสมกว่า ดัชนี AIC มีจุดเด่นเหนือ deviance คือมีการปรับสูตรชดเชยค่าดัชนีด้วยเทอม \\(2p\\) ทำให้ดัชนีมีความแกร่งต่อโมเดลระบุเกินพอดีมากกว่าการใช้ log-likelihood โดยตรง\nดัชนีอีกตัวที่อยู่ในกลุ่มเดียวกับ AIC คือ ดัชนี Bayesian Information Criterion (BIC) ดัชนีดังกล่าวมีการชดเชยความซับซ้อนของโมเดลแตกต่างไปจาก AIC ดังนี้\n\\(BIC = -2log\\ p(y|\\hat{\\theta})+p\\ log\\ n\\)\nโดยที่ \\(\\hat{\\theta}\\) คือค่าประมาณ maximum likelihood และการแปลผล BIC ทำในทำนองเดียวกับ AIC กล่าวคือ โมเดลที่มีค่า BIC ต่ำกว่ามีแนวโน้มที่จะเป็นโมเดลที่เหมาะสมกว่า\nแนวคิดการชดเชยความซับซ้อนของโมเดลที่ใช่้ในสูตรดัชนี AIC และ BIC สามารถนำมาใช้กับดัชนี DIC ได้เช่นเดียวกัน อย่างไรก็ตามการวิเคราะห์แบบเบส์ยอมให้มีการกำหนดการแจกแจงความน่าจะเป็นเบื้องต้นให้กับพารามิเตอร์ภายในโมเดล ซึ่งในกรณีที่ผู้วิเคราะห์กำหนดให้การแจกแจงดังกล่าวมีสารสนเทศ (informative priors) การแจกแจงดังกล่าวจะมีอิทธิพลต่อการประมาณค่าพารามิเตอร์ภายในโมเดล กล่าวคือจะทำให้ความเป็นอิสระของค่าประมาณที่ได้ลดลง จำนวนพารามิเตอร์ภายในโมเดลที่มีการกำหนดการแจกแจงเบื้องต้นแบบมีสารสนเทศจึงไม่เท่ากับ \\(p\\) เหมือนในสูตรดัชนี AIC และ BIC\nSpiegelhalter และคณะ (2002) ได้เสนอค่าสถิติจำนวนพารามิเตอร์ที่มีประสิทธิภาพของโมเดล (the effective number of parameter) เขียนแทนด้วย \\(p_D\\) ซึ่งมีค่าเท่ากับ\n\\(p_D = \\overline{D(\\theta)}-D(\\hat{\\theta})\\)\nโดยที่ \\(\\hat{\\theta}\\) เป็นค่าประมาณที่เหมาะสมของ \\(\\theta\\) จาก posterior distribution\nNote\nจากสูตรข้างต้นอาจเขียนได้ว่า \\(p_D=posterior\\ mean\\ deviance - deviance \\ of\\ posterior \\ mean\\)\nในกรณีที่โมเดลการวิเคราะห์เลือกใช้การแจกแจงความน่าจะเป็นเบื้องต้นแบบไม่มีสารสนเทศ \\(p_D \\approx p\\)\n\\(p_D\\) ไม่สามารถใช้ได้ในกรณีที่ปริภูมิของพารามิเตอร์ \\(\\theta\\) เป็นค่าไม่ต่อเนื่อง ทั้งนี้เป็นเพราะ posterior mean ของพารามิเตอร์ \\(\\theta\\) จะไม่มีความหมาย นอกจากนี้ยังไม่เหมาะในกรณีที่ posteior distribution ของพารามิเตอร์ \\(\\theta\\) มีการแจกแจงที่ไม่สมมาตร หรือมีหลายฐานนิยมอีกด้วย\nจาก \\(p_D\\) ในข้างต้นทำให้สามารถนิยามดัชนีวัดความสอดคล้องของโมเดลวิเคราะห์แบบเบส์เรียกว่า deviance information criterion (DIC) ได้ดังนี้\n\\(DIC = \\overline{D}+p_D = D(\\overline{\\theta})+2p_D\\)\nดัชนี DIC เป็นกรณีทั่วไปของดัชนี AIC กล่าวคือในกรณีที่โมเดลกำหนดการแจกแจงความน่าจะเป็นเบื้องต้นของพารามิเตอร์เป็นแบบไม่มีสารสนเทศ ค่า \\(p_D \\approx p\\) ซึ่งทำให้ \\(DIC \\approx AIC\\)\nการคำนวณค่า DIC และค่าสถิติที่เกี่ยวข้องจากโมเดลสามารถทำได้ดังนี้\nจากตัวอย่าง homogeneity และ heterogeneity of variances models\n\n\nextract.runjags(fit.homo, what=\"dic\")\n\n\nCompiling rjags model and adapting for 1000 iterations...\nObtaining DIC samples from 10000 iterations...\nMean deviance:  747.4 \npenalty 3.028 \nPenalized deviance: 750.5 \n\nextract.runjags(fit.hetero, what=\"dic\")\n\n\nCompiling rjags model and adapting for 1000 iterations...\nObtaining DIC samples from 10000 iterations...\nMean deviance:  717.4 \npenalty 4.2 \nPenalized deviance: 721.6 \n\nWAIC and LOO\nWatanabe-Akaike information criterion (WAIC) และ leave-one-out cross validation (LOO) เป็นดัชนีที่ถูกพัฒนาขึ้นภายหลังสำหรับใช้เปรียบเทียบโมเดลแบบเบส์ ซึ่งมีอำนาจการทดสอบที่สูงกว่าการทดสอบอัตราส่วนภาวะความควรจะเป็น, AIC, BIC และ DIC (Luo, and Al-Harbi, 2017)\n\n\n#install.packages(\"loo\")\nlibrary(loo)\n\"model{\n  #likelihood function\n  for(i in 1:n)\n  {\n    y[i]~dnorm(mu[x[i]],tau)\n    \n    # calculate log-lik\n    loglik[i]<- logdensity.norm(y[i],mu[x[i]],tau)\n  }\n  \n  for (j in 1:2)\n  {\n  #prior distribution\n  mu[j]~dnorm(0,0.01)\n  \n\n  }\n  \n  tau~dgamma(0.01,0.01)\n  sigma<-sqrt(1/tau)\n  \n  #calculate deviance value\n  deviance<- -2*sum(loglik)\n}\"\n\n\n\n\n\n\n\n\ndataList<-list(y=dat$Ach, x=dat$Method, n=dim(dat)[1])\nfit.homo<-run.jags(method=\"parallel\",\n                        model=homo,\n                        monitor=c(\"mu\",\"sigma\",\"loglik\"),\n                        data=dataList,\n                        n.chains=3,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE,\n                        keep.jags.files = FALSE,\n                        silent.jags = TRUE)\n\n\nCalling 3 simulations using the parallel method...\nAll chains have finished\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nNote: Summary statistics were not produced as there are >50\nmonitored variables\n[To override this behaviour see ?add.summary and\n?runjags.options] FALSEFinished running the simulation\n\nfit.hetero<-run.jags(method=\"parallel\",\n                        model=hetero,\n                        monitor=c(\"mu\",\"sigma\",\"loglik\"),\n                        data=dataList,\n                        n.chains=3,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE,\n                        keep.jags.files = FALSE,\n                        silent.jags = TRUE)\n\n\nCalling 3 simulations using the parallel method...\nAll chains have finished\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nNote: Summary statistics were not produced as there are >50\nmonitored variables\n[To override this behaviour see ?add.summary and\n?runjags.options] FALSEFinished running the simulation\n\nsample1<-data.frame(as.matrix(as.mcmc.list(fit.homo)))\nsample2<-data.frame(as.matrix(as.mcmc.list(fit.hetero)))\n\nlibrary(dplyr)\nloglik1<-sample1%>%select(starts_with(\"loglik\"))%>%as.matrix()\nloglik2<-sample2%>%select(starts_with(\"loglik\"))%>%as.matrix()\n\nwaic(loglik1)\n\n\n\nComputed from 30000 by 100 log-likelihood matrix\n\n          Estimate   SE\nelpd_waic   -375.7  9.8\np_waic         3.7  0.9\nwaic         751.4 19.6\n\n2 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\nloo(loglik1)\n\n\n\nComputed from 30000 by 100 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -375.7  9.8\np_loo         3.7  0.9\nlooic       751.4 19.6\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nwaic(loglik2)\n\n\n\nComputed from 30000 by 100 log-likelihood matrix\n\n          Estimate   SE\nelpd_waic   -360.9  8.6\np_waic         4.0  0.8\nwaic         721.7 17.3\n\n2 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\nloo(loglik2)\n\n\n\nComputed from 30000 by 100 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -360.9  8.6\np_loo         4.1  0.8\nlooic       721.8 17.3\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nฝากไปดู\n\n\nBayes Factor\nในกรณีที่ผู้วิเคราะห์ไม่ได้สนใจที่จะอธิบายค่าอิทธิพลต่าง ๆ ผ่านการประมาณค่าพารามิเตอร์ แต่ต้องการดำเนินการทดสอบเพื่อตัดสินใจเกี่ยวกับนัยสำคัญของอิทธิพลต่าง ๆ หรือเปรียบเทียบโมเดลการวิเคราะห์หลาย ๆ โมเดล ในกรณีนี้จำเป็นต้องใช้การเปรียบเทียบโมเดลแบบเบส์ ซึ่งเครื่องมือหนึ่งที่สามารถนำมาใช้ได้คือ ตัวประกอบเบส์ (Bayes Factor: BF)\nจากตัวอย่างการเปรียบเทียบค่าเฉลี่ยสองกลุ่ม สมมุติว่าต้องการทดสอบว่า\n\\(H_0: \\mu_1 =\\mu_2\\) vs \\(H_1: \\mu_1 \\neq \\mu_2\\)\nในการวิเคราะห์แบบเบส์ผู้วิเคราะห์จำเป็นต้องกำหนดโมเดล 2 โมเดลที่เป็นคู่แข่งขันกัน คือโมเดลตามสมมุติฐาน \\(H_0\\) ที่กำหนดการแจกแจงความน่าจะเป็นเบื้องต้นของผลต่างระหว่างค่าเฉลี่ยทั้งสองกลุ่มมีค่าเป็น 0 ด้วยความน่าเชื่อถือที่สูงมาก และโมเดลตามสมมุติฐาน \\(H_1\\) ที่กำหนดการแจกแจงความน่าจะเป็นเบื้องต้นของพารามิเตอร์ผลต่างดังกล่าวเป็นค่าใด ๆ จากนั้นทำการประมาณการแจกแจงความน่าจะเป็นภายหลังของโมเดลทั้งสองเพื่อประมาณค่า bayes factor\nกำหนดให้ M1 และ M2 แทนโมเดลตามสมมุติฐาน \\(H_0\\) และ \\(H_1\\) ตามลำดับ หากมองว่าโมเดลก็มีความไม่แน่นอน ดังนั้นโมเดลจึงมีความเป็นไปได้ได้มากกว่า 1 โมเดล ตามแนวคิดของเบส์ผู้วิเคราะห์ก็สามารถประมาณการแจกแจง posterior ของแต่ละโมเดลที่ based on ข้อมูลเชิงประจักษ์ได้เหมือนกับการแจกแจง posterior ของพารามิเตอร์ในแต่ละโมเดล ดังนี้\n\\(p(M_1|D)=\\frac{p(D|M_1)p(M_1)}{\\sum_{m=1}^2 p(D|M_m)p(M_m)}\\)\n\\(p(M_2|D)=\\frac{p(D|M_2)p(M_2)}{\\sum_{m=1}^2 p(D|M_m)p(M_m)}\\)\nจาก posterior ของโมเดลข้างต้นจะได้ว่า posterior odd ของโมเดล มีค่าเท่ากับ\n\nนิยามของ bayes factor ข้างต้นอาจเขียนสัญลักษณ์แทนด้วย \\(BF_{12}\\) ซึ่งหมายถึงน้ำหนักการเกิดค่าสังเกต \\(D\\) ในโมเดล \\(M_1\\) เมื่อเปรียบเทียบกับน้ำหนักการเกิดค่าสังเกต \\(D\\) ในโมเดล \\(M_2\\) ถ้าอัตราส่วนดังกล่าวมีค่ามากกว่า 1 แสดงว่ามีแนวโน้มที่โมเดล \\(M_1\\) จะสอดคล้องกับข้อมูลจริงมากกว่า \\(M_2\\)\nbayes factor มีจุดเด่นคล้ายกับ AIC คือสามารถใช้เพื่อเปรียบเทียบโมเดลคู่แข่งขันแบบ non-nested ได้ แต่มีความแตกต่างจาก AIC คือ bayes factor ให้สารสนเทศที่มีความเป็นปรนัยมากกว่า AIC ตารางด้านล่างแสดงการแปลความหมายขนาดของ bayes factor\n\nการหา bayes factor ด้วย JAGs สามารถทำได้ดังนี้\n\nCalling 3 simulations using the parallel method...\nFollowing the progress of chain 1 (the program will wait for\nall chains to finish before continuing):\nWelcome to JAGS 4.3.0 on Sat Mar  5 00:00:15 2022\nJAGS is free software and comes with ABSOLUTELY NO WARRANTY\nLoading module: basemod: ok\nLoading module: bugs: ok\n. . Reading data file data.txt\n. Compiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 100\n   Unobserved stochastic nodes: 5\n   Total graph size: 223\n. Reading parameter file inits1.txt\n. Initializing model\n. Adaptation skipped: model is not in adaptive mode.\n. Updating 4000\n-------------------------------------------------| 4000\n************************************************** 100%\n. . . . . Updating 30000\n-------------------------------------------------| 30000\n************************************************** 100%\n. . . . Updating 0\n. Deleting model\n. \nAll chains have finished\nNote: the model did not require adaptation\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nCalculating summary statistics...\nCalculating the Gelman-Rubin statistic for 5 variables....\nFinished running the simulation\n\nIterations = 5001:34998\nThinning interval = 3 \nNumber of chains = 3 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n            Mean     SD Naive SE Time-series SE\nb0       50.3202 0.8379 0.004838       0.005096\nb1       -1.4407 7.7151 0.044543       0.045706\nsigma[1]  5.8127 0.6063 0.003500       0.003543\nsigma[2] 13.3630 1.3766 0.007948       0.007962\nmod       0.5451 0.4980 0.002875       0.003446\n\n2. Quantiles for each variable:\n\n            2.5%    25%    50%    75%  97.5%\nb0        48.641 49.768 50.327 50.879 51.957\nb1       -16.755 -5.107 -2.658  1.433 16.907\nsigma[1]   4.775  5.388  5.760  6.183  7.167\nsigma[2]  10.969 12.398 13.247 14.219 16.365\nmod        0.000  0.000  1.000  1.000  1.000\n\n\nNode mod ในโมเดลข้างต้นมีการแจกแจงความน่าจะเป็นภายหลังคือ \\(p(M|D)\\) ดังนั้นค่าเฉลี่ยภายหลังของ node ดังกล่าวจึงมีค่าเท่ากับ \\(P(M=1|D)=P(Model_1|D)=0.5518\\) และ \\(P(M=0|D)=P(Model_2)=1-0.5518=0.4482\\)\nposterior odd ระหว่างโมเดลสองค่าเฉลี่ยต่อโมเดลหนึ่งค่าเฉลี่ยจึงมีค่าเท่ากับ\n\\(\\frac{P(M=1|D)}{P(M=0|D)}=\\frac{0.5518}{0.4482}=1.2311\\)\nเนื่องจาก prior odd ของโมเดลทั้งสองมีค่าเท่ากับ 1 ดังนั้น Bayes factor ของโมเดลสองค่าเฉลี่ยเทียบกับโมเดลหนึ่งค่าเฉลี่ย จึงมีค่าเท่ากับ\n\\(BF_{10}=\\frac{P(M=1|D)}{P(M=0|D)} \\times \\frac{P(M=0)}{P(M=1)}=1.2311\\)\nbayes factor มีความสัมพันธ์กับดัชนี BIC กล่าวคือในกรณีที่โมเดลวิเคราะห์มีการกำหนดการแจกแจงความน่าจะเป็นเบื้องต้นของพารามิเตอร์เป็นแบบไม่ให้สารสนเทศ และ \\(BIC_0\\) กับ \\(BIC_1\\) คือค่า BIC ของโมเดลคู่แข่งขันตามสมมุติฐาน \\(H_0\\) กับ \\(H_1\\) จะได้ว่า\n\\(BIC_0-BIC_1 \\approx -2log\\ B_{01}\\)\nตัวอย่างต่อไปนี้แสดงการใช้ bayes factor เปรียบเทียบใน regression model\n\n\ndat<-read.csv(\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-19-glm1/regression_dat1.csv\")\nhead(dat)\n\n\n  X Hour Class.Behav Home.Status Teach.Qua Score\n1 1    6         3.3        poor       bad  39.8\n2 2   11         3.7        poor       bad  59.6\n3 3    6         4.8        poor      good  50.8\n4 4   11         3.7      normal       bad  50.9\n5 5   10         1.3        poor      good  67.9\n6 6    2         3.1      normal       bad  26.0\n\nx1=dat$Hour\nx3=ifelse(dat$Home.Status==\"poor\",0,1)\nx4=ifelse(dat$Teach.Qua==\"bad\",0,1)\ndataList<-list(y=dat$Score, x1=x1, x2=dat$Class.Behav,\n               x3=x3,\n               x4=x4,\n               x13=x1*x3, x14=x1*x4, n=dim(dat)[1])\n\n\n\n\n\n\"model{\nM~dcat(p[])\np[1]<-0.5\np[2]<-0.5\n\nfor (i in 1:n)\n{\ny[i]~dnorm(mu[i,M],tau)\nmu[i,1]<-b[1]+b[2]*x1[i]+b[3]*x2[i]+b[4]*x3[i]+b[5]*x4[i]\nmu[i,2]<-b[1]+b[2]*x1[i]+b[3]*x2[i]+b[4]*x3[i]+b[5]*x4[i]+b[6]*x13[i]+b[7]*x14[i]\n\nloglik[i,1]<-logdensity.norm(y[i],mu[i,1],tau)\nloglik[i,2]<-logdensity.norm(y[i],mu[i,2],tau)\n}\n\nfor(j in 1:7)\n{\nb[j]~dnorm(0,0.01)\n}\ntau~dunif(0,100)\nsigma<-1/sqrt(tau)\ndeviance[1]<- -2*sum(loglik[,1])\ndeviance[2]<- -2*sum(loglik[,2])\nmod<-M-1\n}\"\n\n\n\n\n\n\n\n\nfit.reg<-run.jags(method=\"rjparallel\",\n                  model=reg,\n                  data=dataList,\n                  monitor = c(\"b\",\"sigma\",\"deviance1\",\"deviance2\",\"mod\"),\n                  n.chains=3,\n                  sample=10000,\n                  thin=10,\n                  silent.jags = TRUE)\n\n\nStarting 3 rjags simulations using a Fork cluster with 3 nodes\non host 'localhost'\nNote: The monitored variable 'mod' appears to be\nnon-stochastic; it will not be included in the convergence\ndiagnostic\nFinished running the simulation\n\nsample<-as.mcmc.list(fit.reg)\nMCMCtrace(sample, pdf=F)\n\n\n\nautocorr.diag(sample)\n\n\n                b[1]         b[2]        b[3]         b[4]\nLag 0    1.000000000  1.000000000 1.000000000 1.0000000000\nLag 10   0.478741831  0.478030041 0.045576428 0.2972476729\nLag 50   0.031756941  0.033047259 0.008957884 0.0034219372\nLag 100  0.002119377  0.001547937 0.001961193 0.0065605508\nLag 500 -0.003658869 -0.002361700 0.008864129 0.0007987568\n                b[5]         b[6]          b[7]        sigma\nLag 0    1.000000000  1.000000000  1.0000000000  1.000000000\nLag 10   0.346574005  0.297304349  0.3439219783  0.005877118\nLag 50   0.017539222  0.013688928  0.0158047066 -0.006979039\nLag 100 -0.001839661  0.004583672 -0.0062815703  0.005027590\nLag 500 -0.002497264 -0.003953694 -0.0005292672 -0.004922956\n           deviance1     deviance2 mod\nLag 0    1.000000000  1.0000000000 NaN\nLag 10   0.365950164  0.0617608001 NaN\nLag 50   0.022391005  0.0001485375 NaN\nLag 100  0.008272329 -0.0071807816 NaN\nLag 500 -0.005184251 -0.0057359607 NaN\n\nMCMCsummary(sample, HPD=TRUE)\n\n\n                   mean          sd     95%_HPDL     95%_HPDU Rhat\nb[1]        -0.19501978   1.0770284   -2.3255289    1.8976548    1\nb[2]         2.92804772   0.1352189    2.6700161    3.1990427    1\nb[3]         4.70771123   0.2050836    4.2973840    5.0999076    1\nb[4]         1.56875824   1.2534138   -0.8988280    4.0227520    1\nb[5]         7.11517476   1.2580737    4.6870549    9.6098821    1\nb[6]         0.01101063   0.1790583   -0.3522547    0.3502642    1\nb[7]         2.02212721   0.1790835    1.6626798    2.3640088    1\nsigma        5.81279244   0.2069761    5.4220694    6.2227881    1\ndeviance1 3585.53673547 197.6093589 3216.7338393 3982.7709518    1\ndeviance2 2544.57454131   4.0094290 2537.9501585 2552.5464849    1\nmod          1.00000000   0.0000000    1.0000000    1.0000000  NaN\n          n.eff\nb[1]      10405\nb[2]      10294\nb[3]      26803\nb[4]      15246\nb[5]      13809\nb[6]      15473\nb[7]      14126\nsigma     30000\ndeviance1 12636\ndeviance2 26513\nmod           0\n\nสรุป\nการตรวจสอบเศษเหลือของโมเดลสามารถใช้ได้ในการวิเคราะห์แบบเบส์ แต่มีขอบเขตการใช้อยู่ภายใต้โมเดลการวิเคราะห์แบบเชิงเส้นแบบพาราเมทริกที่มีการกำหนดข้อตกลงเบื้องต้นเกี่ยวกับค่าคลาดเคลื่อนสุ่มของโมเดล ส่วนในกรณีอื่น ๆ เศษเหลือสามารถใช้เพื่อพิจารณาความแม่นยำ/ความถูกต้องของค่าทำนายที่ได้จากโมเดล โดยปกติค่าเศษเหลือที่นำมาประเมินโมเดลนั้นควรเป็น out-sample residual ทั้งนี้เพื่อไม่ให้มีความลำเอียงในการประเมินความคลาดเคลื่อนในการทำนายของโมเดล ส่วน in-sample residual มักใช้สำหรับตรวจสอบข้อตกลงเบื้องต้นของโมเดลมากกว่า\nจาก concept ที่กล่าวไว้ในข้างต้นสรุปได้ว่า bayes factor เป็นสถิติที่ใช้สำหรับระบุโมเดลที่ถูกต้องที่สุดภายใต้ปริภูมิของโมเดลคู่แข่งขัน ทั้งนี้เป็นเพราะ bayes factor คำนวณจากค่าน้ำหนักซึ่งเป็นความน่าจะเป็นของการเกิดชุดข้อมูลตัวอย่างภายใต้แต่ละโมเดล ในขณะที่ DIC และ AIC เป็นดัชนีสำหรับเปรียบเทียบโมเดลด้วย concept ที่แตกต่างออกไป ทั้งนี้เป็นเพราะดัชนีดังกล่าวใช้บ่งชี้ความถูกต้องของค่าทำนายที่ได้จากแต่ละโมเดลมากกว่าที่จะใช้เฟ้นหา/ระบุโมเดลที่ถูกต้อง\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\nhtml {\n  scroll-behavior: smooth;\n}\nd-article {\n    contain: none;\n  }\n#TOC {\n  position: responsive;\n  z-index: 50;\n  background: \"white\";     /* or   background: white; */\n  top: 4;\n  padding: -5px;           /* optional */\n  border-radius: 5px;      /* optional */\n  color: \"grey\";\n  }\n\n/* Hide the ToC when resized to mobile or tablet:  480px, 768px, 900px */\n@media screen and (max-width: 900px) {\n#TOC {\n    position: relative;\n  }\n}\n\n\n\n",
    "preview": "posts/2022-02-19-glm1/glm1_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-03-05T00:06:17+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-03-05-introbrms/",
    "title": "brms package",
    "description": "Bayesian modelling using brms package",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": {}
      }
    ],
    "date": "2022-02-19",
    "categories": [
      "Bayesian Statistics",
      "brms package",
      "GLM",
      "GLMs",
      "Multilevel"
    ],
    "contents": "\n\nContents\npackage-brms\nTwo-way ANOVA model\nANCOVA model\nLogistic Regression\nBinomial model\n\npackage-brms\nผู้เรียนจะเห็นว่าการระบุโมเดลในภาษา JAGS ข้างต้นจำเป็นต้องอาศัยความเชี่ยวชาญพอสมควร นอกจากนี้ยังค่อนข้างใช้เวลาในการเขียนโมเดลถึงแม้จะเป็นโมเดลพื้นฐานอย่าง one-way ANOVA ในข้างต้น ปัจจุบันมี package หลายตัวที่ทำหน้าที่เป็นส่วนต่อประสานระหว่างผู้ใช้กับ engine ต่าง ๆ ซึ่งใช้ภาษาที่เรียบง่ายกว่า ทำให้การ modelling ด้วยวิธีการแบบเบส์ทำได้สะดวกและง่ายขึ้น หัวข้อนี้จะกล่าวถึง package-brms (ย่อมาจาก bayesian multilevel models using stan) ซึ่งเป็น high-level API ตัวหนึ่งของภาษา Stan รายละเอียดมีดังนี้\nขอบเขตของ model ใน package-brms\nโมเดลทั่วไปที่สามารถวิเคราะห์ได้ด้วย package-brms มีรูปแบบดังนี้\n\\(y_i \\sim D(f(\\eta_i),\\theta)\\)\nเมื่อ \\(y_i\\) คือค่าสังเกตของตัวแปรตาม ที่มีการแจกแจง \\(D\\) ในโปรแกรม R จะเรียก \\(D\\) นี้ว่า family ในขณะที่ \\(f(.)\\) คือ link function, \\(\\theta\\) คือพารมิเตอร์ของการแจกแจง \\(D\\) ซึ่งสามารถมีได้หลายตัวขึ้นอยู่กับการแจกแจงที่กำหนด และ \\(eta_i\\) คือผลรวมเชิงเส้นของตัวแปรอิสระซึ่งสามารถเขียนได้ในรูปทั่วไปดังนี้\n\\(\\bf{\\eta}=\\bf{X}\\beta+\\bf{Z}u\\)\n\\(\\beta\\) คือสัมประสิทธิ์ความถดถอยในระดับ individual ส่วน \\(u\\) คือสัมประสิทธิ์ความถดถอยในระดับกลุ่ม \\(X\\) และ \\(Z\\) คือ design matrix ของตัวแปรอิสระในระดับ individual และ กลุ่ม ตามลำดับ\nprior distribution\nนอกจากจะมีประสิทธิภาพที่ดีในด้านของอัลกอริทึม MCMC แล้ว Stan ยังสามารถกำหนด prior distribution ได้มีประสิทธิภาพมากกว่าใน JAGS รวมถึง BUGS ด้วย รายละเอียดไปอ่านเอง ไม่อ่านก็ตามใจ\nindividual-level reg coef —> flat prior\ngroup-level reg coef —> \\(\\bf{u} \\sim N(\\bf{0},\\Sigma)\\)\nเมื่อ \\(\\Sigma\\) คือเมทริกซ์ความแปรปรวนร่วม ซึ่งเป็นไปได้ทั้ง diagonal matrix และ symmetry matrix ขึ้นอยู่กับการกำหนด prior distribution ของเมทริกซ์ความแปรปรวนร่วมดังกล่าว นอกจากนี้ยังสามารถ model ให้ group-level reg coef นี้มีการแจกแจงที่เป็นอิสระไปตามกลุ่มได้อีกด้วย —> \\(\\bf{u}_j \\sim N(\\bf{0},\\Sigma_j)\\)\nโดยปกติ prior distribution ของ covariance matrix จะกำหนดให้เป็นการแจกแจงแบบ Inverse-Wishart ซึ่งเป็น conjugacy prior กับ exponential family ต่าง ๆ และทำให้อัลกอริทึม Gibb-samplers มีประสิทธิภาพสูง อย่างไรก็ตามใน Stan ไม่จำเป็นต้องกำหนดการแจกแจงในลักษณะดังกล่าว ทำให้การกำหนด prior ของพารามิเตอร์นี้ทำได้ง่ายและมีความหมายที่เข้าใจได้ชัดเจนมากขึ้น ดังนี้\nกำหนดให้ \\(\\Sigma_k=D(\\sigma_k)\\Omega_kD(\\sigma_k)\\)\nเมื่อ \\(D(\\sigma_k)\\) คือ diagonal matrix ของส่วนเบี่ยงเบนมาตรฐานของ \\(u_k\\) ส่วน \\(\\Omega\\) คือเมทริกซ์สหสัมพันธ์ของพารามิเตอร์ \\(\\bf{u}\\) ดังกล่าว Lewandowski และคณะ (2009) เสนอให้กำหนด prior ของเมทริกซ์สหสัมพันธ์นี้เป็น LKJ-Correlation prior ที่มีพารามิเตอร์ \\(\\zeta>0\\) กล่าวคือ \\(\\Omega \\sim LKJ(\\zeta)\\)\nถ้า \\(\\zeta=1\\) (ค่าเริ่มต้น) การแจกแจงจะมีลักษณะเป็น uniform บน correlation matrix\nถ้า \\(\\zeta>1\\) การแจกแจงจะมีลักษณะลู่เข้าหา identity matrix ขึ้นอยู่กับค่าของ \\(zeta\\)\nถ้า \\(0<\\zeta<1\\) การแจกแจงมีลักษณะเป็น U-shape กล่าวคือให้ค่าความน่าจะเป็นที่จะมีค่า correlation สูง\nส่วน \\(sigma_k\\) สามารถกำหนด prior distribution แยกรายตัวหรือให้เหมือนกันทั้งหมดก็ได้ ค่าเริ่มต้นของ brms คือการแจกแจงทีแบบครึ่งเดียว (half-Student-t prior) ที่มีองศาความเป็นอิสระเท่ากับ 3\nbrms ยังสามารถ model ให้พารามิเตอร์ในระดับ individual กับ group มีความสัมพันธ์กันได้ด้วย โดยการแตกเมทริกซ์ \\(\\Sigma_k\\) เป็นดังนี้ \\(\\Sigma_k=V_k \\otimes A_k\\) เมื่อ \\(V_k\\) คือเมทริกซ์ความแปรปรวนร่วมในระดับกลุ่ม (แทน \\(\\Sigma_k\\) ตัวเดิม) และ \\(A_k\\) คือเมทริกซืความแปรปรวนร่วมของพารามิเตอร์ระหว่างระดับ individual กับ group\nการประมาณค่าพารามิเตอร์ในโมเดล\nอย่างที่กล่าวไว้ก่อนหน้าแล้วว่า brms ที่ใช้ Stan เป็น engine นั้นมีอัลกอริทึมประมาณค่าพารามิเตอร์ที่มีประสิทธิภาพสูงกว่า JAGS และ BUGS ในแง่ของคุณภาพของตัวอย่างพารามิเตอร์ที่ได้จาก MCMC กล่าวคือตัวอย่างที่ได้จะลู่เข้าหาการแจกแจงความน่าจะเป็นภายหลังได้อย่างรวดเร็ว และมีความค่าอัตสหสัมพันธ์ต่ำ ทำให้ผู้วิเคราะห์ไม่จำเป็นต้องรันลูกโซ่ยาวมากเหมือนกับ Gibb-sampler ใน JAGS และ BUGS อย่างไรก็ตามหากเปรียบเทียบกันต่อรอบ Stan จะใช้เวลามากกว่า\nข้อดีอีกประการหนึ่งของการใช้ Stan ผ่าน brms คือจะให้ค่าสถิติสำหรับเปรียบเทียบโมเดลไว้หลายตัวได้แก่ WAIC และ LOO ซึ่งเป็นดัชนีทีปรับปรุงจาก DIC\nผู้เรียนได้ติดตั้ง package-brms ลงในเครื่องแล้ว ตัวอย่างต่อไปนี้จะแสดงการรัน regression model\n\n\ndat<-read.csv(\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-19-glm1/regression_dat1.csv\")\nhead(dat)\n\n\n  X Hour Class.Behav Home.Status Teach.Qua Score\n1 1    6         3.3        poor       bad  39.8\n2 2   11         3.7        poor       bad  59.6\n3 3    6         4.8        poor      good  50.8\n4 4   11         3.7      normal       bad  50.9\n5 5   10         1.3        poor      good  67.9\n6 6    2         3.1      normal       bad  26.0\n\n\n\nlibrary(brms)\nlibrary(ggplot2)\nfit.reg<-brm(Score~., data=dat[,-1],\n             family=gaussian(),\n             warmup=1000,\n             iter=3000,\n             chains=3,\n             cores=3)\n\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB \\\n  foo.c\nclang -mmacosx-version-min=10.13 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:\n/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'\nnamespace Eigen {\n^\n/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator\nnamespace Eigen {\n               ^\n               ;\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:\n/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found\n#include <complex>\n         ^~~~~~~~~\n3 errors generated.\nmake: *** [foo.o] Error 1\n\n\n\nplot(fit.reg, N=3,\n     theme=theme(text=element_text(family=\"ChulaCharasNew\")))\n\n\n\nsummary(fit.reg)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Score ~ Hour + Class.Behav + Home.Status + Teach.Qua \n   Data: dat[, -1] (Number of observations: 400) \n  Draws: 3 chains, each with iter = 3000; warmup = 1000; thin = 1;\n         total post-warmup draws = 6000\n\nPopulation-Level Effects: \n                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept          -3.47      1.05    -5.49    -1.39 1.00     8723\nHour                3.77      0.10     3.57     3.97 1.00     9013\nClass.Behav         4.68      0.24     4.23     5.15 1.00     8342\nHome.Statuspoor    -1.92      0.70    -3.28    -0.54 1.00     8057\nTeach.Quagood      19.74      0.70    18.38    21.09 1.00     7491\n                Tail_ESS\nIntercept           4263\nHour                4281\nClass.Behav         4350\nHome.Statuspoor     4998\nTeach.Quagood       4647\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     6.68      0.23     6.24     7.16 1.00     6903     4120\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nผู้วิเคราะห์สามารถตรวจสอบความเหมาะสมของโมเดลได้ง่าย ๆ ดังนี้\n\n\n    Estimate   Est.Error      Q2.5    Q97.5\nR2 0.8692361 0.004575642 0.8588778 0.876921\n\nComputed from 6000 by 400 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -1330.0 14.0\np_loo         6.4  0.5\nlooic      2660.0 27.9\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nComputed from 6000 by 400 log-likelihood matrix\n\n          Estimate   SE\nelpd_waic  -1330.0 14.0\np_waic         6.4  0.5\nwaic        2660.0 27.9\n\nเราสามารถปรับเปลี่ยน prior ได้หลายวิธีการ วิธีการหนึ่งคือการเรียกค่าเริ่มต้นของ prior มาก่อน แล้วปรับเปลี่ยนทีละตัวตามต้องการดังนี้\n\n                    prior     class            coef group resp dpar\n                   (flat)         b                                \n                   (flat)         b     Class.Behav                \n                   (flat)         b Home.Statuspoor                \n                   (flat)         b            Hour                \n                   (flat)         b   Teach.Quagood                \n student_t(3, 35.8, 19.2) Intercept                                \n    student_t(3, 0, 19.2)     sigma                                \n nlpar bound       source\n                  default\n             (vectorized)\n             (vectorized)\n             (vectorized)\n             (vectorized)\n                  default\n                  default\n\nจากนั้นก็ run ใหม่โดยกำหนดอาร์กิวเมนท์ prior ดังนี้\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB \\\n  foo.c\nclang -mmacosx-version-min=10.13 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:\n/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'\nnamespace Eigen {\n^\n/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator\nnamespace Eigen {\n               ^\n               ;\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:\n/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found\n#include <complex>\n         ^~~~~~~~~\n3 errors generated.\nmake: *** [foo.o] Error 1\n\nSAMPLING FOR MODEL 'a58cec21ebe357bb5e15fa0ff85e86c4' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.5e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 1: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 1: Iteration:  600 / 3000 [ 20%]  (Warmup)\nChain 1: Iteration:  900 / 3000 [ 30%]  (Warmup)\nChain 1: Iteration: 1001 / 3000 [ 33%]  (Sampling)\nChain 1: Iteration: 1300 / 3000 [ 43%]  (Sampling)\nChain 1: Iteration: 1600 / 3000 [ 53%]  (Sampling)\nChain 1: Iteration: 1900 / 3000 [ 63%]  (Sampling)\nChain 1: Iteration: 2200 / 3000 [ 73%]  (Sampling)\nChain 1: Iteration: 2500 / 3000 [ 83%]  (Sampling)\nChain 1: Iteration: 2800 / 3000 [ 93%]  (Sampling)\nChain 1: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.034233 seconds (Warm-up)\nChain 1:                0.04828 seconds (Sampling)\nChain 1:                0.082513 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'a58cec21ebe357bb5e15fa0ff85e86c4' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 8e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 2: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 2: Iteration:  600 / 3000 [ 20%]  (Warmup)\nChain 2: Iteration:  900 / 3000 [ 30%]  (Warmup)\nChain 2: Iteration: 1001 / 3000 [ 33%]  (Sampling)\nChain 2: Iteration: 1300 / 3000 [ 43%]  (Sampling)\nChain 2: Iteration: 1600 / 3000 [ 53%]  (Sampling)\nChain 2: Iteration: 1900 / 3000 [ 63%]  (Sampling)\nChain 2: Iteration: 2200 / 3000 [ 73%]  (Sampling)\nChain 2: Iteration: 2500 / 3000 [ 83%]  (Sampling)\nChain 2: Iteration: 2800 / 3000 [ 93%]  (Sampling)\nChain 2: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.033134 seconds (Warm-up)\nChain 2:                0.050125 seconds (Sampling)\nChain 2:                0.083259 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'a58cec21ebe357bb5e15fa0ff85e86c4' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 8e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 3: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 3: Iteration:  600 / 3000 [ 20%]  (Warmup)\nChain 3: Iteration:  900 / 3000 [ 30%]  (Warmup)\nChain 3: Iteration: 1001 / 3000 [ 33%]  (Sampling)\nChain 3: Iteration: 1300 / 3000 [ 43%]  (Sampling)\nChain 3: Iteration: 1600 / 3000 [ 53%]  (Sampling)\nChain 3: Iteration: 1900 / 3000 [ 63%]  (Sampling)\nChain 3: Iteration: 2200 / 3000 [ 73%]  (Sampling)\nChain 3: Iteration: 2500 / 3000 [ 83%]  (Sampling)\nChain 3: Iteration: 2800 / 3000 [ 93%]  (Sampling)\nChain 3: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.032406 seconds (Warm-up)\nChain 3:                0.051693 seconds (Sampling)\nChain 3:                0.084099 seconds (Total)\nChain 3: \n\nผู้วิเคราะห์สามารถทดสอบสมมุติฐานของพารามิเตอร์ที่ต้องการในโมเดลได้ โดยใช้วิธีการเปรียบเทียบ test value กับ HDI โดยใช้ฟังก์ชัน hypothesis() ดังตัวอย่างต่อไปนี้\n\nHypothesis Tests for class b:\n  Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (Hour) > 0     3.77       0.1      3.6     3.94        Inf\n  Post.Prob Star\n1         1    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\nHypothesis Tests for class b:\n             Hypothesis Estimate Est.Error CI.Lower CI.Upper\n1 (Home.Statuspoor) < 0    -1.92       0.7    -3.07    -0.78\n  Evid.Ratio Post.Prob Star\n1        374         1    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\nExtract output from brm\nผู้วิเคราะห์สามารถแปลงผลการวิเคราะห์ที่ได้ใช้เป็น mcmc objects แล้วไปวิเคราะห์แบบเดิมก็ได้ดังนี้\n\n\n\nอีกลักษณะหนึ่งสามารถทำได้โดยใช้ package-tidybayes ช่วย สามารถอ่านเพิ่มเติมได้จาก ไม่อ่านก็ตามใจ\nTwo-way ANOVA model\nANCOVA model\nLogistic Regression\nการวิเคราะห์โมเดลในกลุ่ม BGLMs สามารถระบุโมเดลและวิเคราะห์ในทำนองเดียวกับการวิเคราะห์ BGLM ความแตกต่างระหว่าง BGLM กับ BGLMs คือ ค่าสังเกตของ BGLMs มีการแจกแจงไม่ใช่การแจกแจงแบบปกติ และจำเป็นต้องใช้ link function เพื่อแปลงค่าของพารามิเตอร์ในการแจกแจงของค่าสังเกต ให้อยู่ในรูปแบบของโมเดลเชิงเส้นเพื่อให้พารามิเตอร์ที่ผ่านการแปลงแล้วมีความหมาย และสามารถใช้บรรยายความสัมพันธ์ระหว่างตัวแปรที่ต้องการได้\nโมเดล glms สามารถนิยามในรูปแบบทั่วไปได้ดังนี้ กำหนดให้ \\(y_i\\) เมื่อ \\(i=1,2,3,...,n\\) เป็นค่าสังเกตของตัวแปรตามที่มีการแจกแจงอยู่ในวงศ์ชี้กำลัง (exponential family) โดยที่\n\\(E[y_i]=\\mu_i=g^{-1}(\\eta_i)\\), \\(\\eta_i=\\beta_0+\\beta_1x_{1i}+...+\\beta_kx_{ki}\\)\nการแจกแจงในวงศ์ชี้กำลังเป็นกลุ่มของการแจกแจงความน่าจะเป็นที่ฟังก์ชันความน่าจะเป็นอยู่ในรูปของ exponential function เช่น normal distribution, poisson และ binomial\nBinomial model\nจากนิยามข้างต้นจะเห็นว่า การกำหนด link function \\(g(.)\\) ที่เหมาะสม จะช่วยแปลงพารามิเตอร์ในการแจกแจงของค่าสังเกต \\(y_i\\) ให้อยู่ในรูปแบบของสมการเชิงเส้นตรงได้ เช่นใน binomial model ที่มีพารามิเตอร์กำกับการแจกแจงคือ ความน่าจะเป็นของการเกิดเหตุการณ์ที่สนใจ \\(\\theta\\) สามารถกำหนด link function ได้เป็น logit function \\(logit(\\theta)=log(\\theta/(1-\\theta))\\) หรือ probit function \\(\\Phi^{-1}(\\theta)\\) ที่เป็น inverse ของ cumulative normal probability function เป็นต้น\nใน binomial model เนื่องจาก \\(y_i\\) มีค่าที่เป็นไปได้ 2 ค่าได้แก่ 0, 1 ดังนั้นค่าเฉลี่ยของ \\(y\\) จึงมีค่าเป็นสัดส่วนหรือความน่าจะเป็นของการเกิดค่าสังเกต \\(y=1\\) กล่าวคือ \\(E[y_i]=\\theta\\) ดังนั้น\n\\(g(E[y_i])=\\eta_i \\implies logit(\\theta)=\\eta_i=\\beta_0+\\beta_1x_{1i}+...+\\beta_kx_{ki}\\)\nสมมุติว่า ผู้วิเคราะห์ต้องการวิเคราะห์ความสำเร็จในการเรียน online ของนักเรียน โดยใช้ตัวแปรได้แก่ จำนวนเวลาที่นักเรียนใช้ในการเข้ามาเรียน online ต่อครั้ง (Hours) ค่าเฉลี่ยของความถี่ในการเข้ามาเรียน online ต่อสัปดาห์ (Freq) และฐานนิยมของคุณภาพชิ้นงานที่นักเรียนทำส่งในระบบ online (Mode_Qua)\n\n  X success hour freq mode.qua\n1 1       0    6  3.3      bad\n2 2       1   11  3.7      bad\n3 3       1    6  4.8     good\n4 4       1   11  3.7      bad\n5 5       1   10  1.3     good\n6 6       0    2  3.1      bad\n[1] 400   5\n\nกำหนดโมเดลของค่าสังเกตเป็น\n\\(y_i \\sim Binomial(\\theta_i, n_i)\\)\nและ \\(logit(\\theta_i)=\\beta_0+\\beta_1hour+\\beta_2freq+\\beta_3mod.qua\\)\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2022-03-05-introbrms/introbrms_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-03-05T12:44:00+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-08-priors/",
    "title": "Prior Distributions",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": {}
      }
    ],
    "date": "2022-02-07",
    "categories": [
      "Bayesian Statistics",
      "priors"
    ],
    "contents": "\n\nContents\nประเภทของ priors\nNoninformative priors\nUniform Distribution\nJeffrey’s prior\nLocation parameters\nConjugacy priors\nInformative priors\n\n\nการแจกแจงความน่าจะเป็นก่อนหน้า (prior distribution) เป็นส่วนประกอบสำตัญในการวิเคราะห์ข้อมูลด้วยสถิติแบบเบส์ ทั้งนี้เป็นเพราะการแจกแจงความน่าจะเป็นก่อนหน้าทำให้ผู้วิเคราะห์สามารถสร้าง statement ความน่าจะเป็นของพารามิเตอร์ภายในโมเดลสถิติที่ใช้ในการวิเคราะห์ข้อมูลได้ นอกจากนี้การแจกแจงความน่าจะเป็นก่อนหน้ายังมีส่วนช่วยเพิ่มเติมสารสนเทศจากแหล่งอื่น ๆ นอกเหนือจากข้อมูลเชิงประจักษ์ให้กับผลการวิเคราะห์ได้อีกด้วย บทเรียนนี้จะกล่าวถึงมโนทัศน์และการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าในโมเดลการวิเคราะห์ รายละเอียดมีดังนี้\nประเภทของ priors\nโดยทั่วไปแล้วอาจจำแนกการแจกแจงความน่าจะเป็นก่อนหน้าออกได้เป็น 2 ประเภท ได้แก่ การแจกแจงความน่าจะเป็นก่อนหน้าแบบไม่ให้สารสนเทศ (noninformative priors) และการแจกแจงความน่าจะเป็นก่อนหน้าแบบให้สารสนเทศ (informative priors)\nในกรณีที่ผู้วิเคราะห์เลือกใช้การแจกแจงความน่าจะเป็นก่อนหน้าแบบไม่ให้สารสนเทศ ผลการวิเคราะห์ที่ได้ในสถานการณ์นี้จะมีความเป็นปรนัย (objective) ทั้งนี้เป็นเพราะ noninformative priors เป็นการแจกแจงที่ไม่ได้ให้สารสนเทศใด ๆ เกี่ยวกับพารามิเตอร์ในโมเดลเพิ่มเติม ทำให้ผลการวิเคราะห์ต่าง ๆ ทั้งการประมาณค่า การทำนาย การเปรียบเทียบโมเดล จะขึ้นกับสารสนเทศที่ได้จากข้อมูลตัวอย่างเท่านั้น การที่ผู้วิเคราะห์เลือกใช้การแจกแจงความน่าจะเป็นก่อนหน้าประเภทนี้ในการวิเคราะห์ แสดงว่าผู้วิเคราะห์ต้องการให้ผลการวิเคราะห์ที่ได้มีความเป็นปรนัยมากที่สุด\nหนังสือหลายเล่มใช้คำว่า vague หรือ diffuse priors แทนคำว่า noninformative priors เพราะต้องการหลีกเลี่ยงการเข้าใจผิดว่า noninformative priors ไม่มีสารสนเทศ แต่ในความเป็นจริงการแจกแจงทุกตัวนั้นมีสารสนเทศเสมอ เพียงแต่ว่าเป็นการแจกแจงที่มีการกระจายค่อนข้างมากจึงไม่ได้ช่วยให้การวิเคราะห์มีสารสนเทศเพิ่มเติมไปจากสารสนเทศในข้อมูลตัวอย่าง\nในทางกลับกันหากผู้วิเคราะห์เลือกใช้ informative priors ในการวิเคราะห์ นั่นหมายความว่าผู้วิเคราะห์ดำเนินการวิเคราะห์โดยไม่ได้ใช้แต่สารสนเทศที่อยู่ภายในข้อมูลตัวอย่างเท่านั้น แต่ยังใช้สารสนเทศที่อยู่ภายในการแจกแจงความน่าจะเป็นก่อนหน้ามาร่วมประมวลผลด้วย ผลการวิเคราะห์ที่ได้ในกรณีนี้จะมีความเป็นอัตวิสัยมากกว่า\nNoninformative priors\nการแจกแจงความน่าจะเป็นก่อนหน้าแบบไม่ให้สารสนเทศในโมเดลมักใช้ในกรณีที่ผู้วิเคราะห์ไม่ได้มีความรู้หรือสารสนเทศเพิ่มเติมเกี่ยวกับพารามิเตอร์ต่าง ๆ ภายในโมเดลการวิเคราะห์ หรืออีกกรณีคือใช้ผลการวิเคราะห์ดังกล่าวเป็นผลการวิเคราะห์อ้างอิง (reference output) สำหรับการวิเคราะห์ผลกระทบที่เกิดจากการกำหนด informative priors หัวข้อนี้จะกล่าวถึงการแจกแจงความน่าจะเป็นก่อนหน้าแบบไม่ให้สารสนเทศบางตัวที่มักใช้เป็นการแจกแจงมาตรฐานในโปรแกรม JAGs รายละเอียดมีดังนี้\nUniform Distribution\nการแจกแจงแบบสม่ำเสมอ (uniform) เป็นการแจกแจงหนึ่งที่นิยมใช้เป็นการแจกแจงความน่าจะเป็นก่อนหน้าแบบไม่ให้สารสนเทศการแจกแจงหนึ่ง ซึ่งมีลักษณะเด่นคือ เป็นการแจกแจงที่ให้น้ำหนักกับความเป็นไปได้ต่าง ๆ ของค่าพารามิเตอร์ที่เท่าเทียมกัน กล่าวคือเป็น prior ที่มีฟังก์ชันความน่าจะเป็นอยู่ในรูปแบบ\n\\(p(\\theta)=Const.\\) เมื่อ \\(\\theta \\in A\\) โดยที่ \\(A\\) คือช่วงที่เป็นไปได้ของพารามิเตอร์ \\(\\theta\\)\nจากตัวอย่างการวิเคราะห์ความเที่ยงตรงของเหรียญ หากกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ความลำเอียงเป็น uniform(0,1) จะได้ \\(p(\\theta)=1\\) เมื่อ \\(\\theta \\in [0,1]\\) รูปต่อไปนี้แสดงฟังก์ชันความน่าจะเป็นแบบ uniform บนช่วง 0,1\n\n\n\nจากรูปการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าในข้างต้นไม่ได้ให้น้ำหนักกับค่าหรือช่วงใดช่วงหนึ่งของพารามิเตอร์ความลำเอียงเป็นพิเศษ ซึ่งทำให้การแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ความลำเอียงถูกพัฒนาขึ้นโดยใช้สารสนเทศจากฟังก์ชันภาวะความควรจะเป็นเกือบทั้งหมด ดังจะเห็นจากสมการด้านล่าง\n\\(p(\\theta|D) = \\frac{p(D|\\theta)p(\\theta)}{p(D)} =\\frac{p(D|\\theta) \\times 1}{P(D)}\\varpropto p(D|\\theta)\\)\nข้อควรระวังในการใช้การแจกแจงแบบ uniform เป็นการแจกแจงความน่าจะเป็นก่อนหน้าคือ การแจกแจงแบบ uniform ไม่มีคุณสมบัติ invariant กล่าวคือ ถ้า \\(\\theta \\sim Uniform(a,b)\\) แต่ \\(\\theta^2\\) ไม่ได้มีการแจกแจงแบบ \\(Uniform(a,b)\\) ดังกล่าว\nJeffrey’s prior\nจากปัญหาข้างต้น Harold Jeffrey (1961) ได้เสนอการแจกแจงความน่าจะเป็นก่อนหน้าแบบไม่ให้สารสนเทศที่มีคุณสมบัติ invariant ชื่อว่า Jeffrey’s prior ฟังก์ชันความน่าจะเป็นของการแจกแจงนี้แปรผันตรงกับรากที่สองของ determinant ของเมทริกซ์สารสนเทศของ Fisher (Fisher information matrix) ดังนี้\n\\(p(\\theta) \\varpropto |J(\\theta)|^{1/2}\\)\nเมื่อ \\(J(\\theta)\\) คือ Fisher information matrix ที่คำนวณได้จาก\n\\(J(\\theta)=Var(\\frac{\\partial}{\\partial \\theta}ln \\ p(\\theta|y))\\)\n\\(=E[-\\frac{\\partial^2 ln p(y|\\theta)}{\\partial \\theta^2}|\\theta]\\)\nจะเห็นว่า Fisher information ในข้างต้นเป็นดัชนีที่ใช้วัดสารสนเทศที่ข้อมูลตัวอย่างมีเกี่ยวกับพารามิเตอร์ต่าง ๆ ภายในโมเดล จากสูตรจะเห็นว่าดัชนีดังกล่าวคำนวณค่าสารสนเทศดังกล่าวโดยอิงกับค่าความแปรปรวน เนื่องจากในกรณีทั่วไปโมเดลการวิเคราะห์สามารถมีพารามิเตอร์ได้มากกว่าหนึ่งตัว ทำให้ Fisher information ดังกล่าวมีลักษณะเป็นเมทริกซ์ความแปรปรวนร่วม (covariance matrix) การสรุปสารสนเทศจากเมทริกซ์ดังกล่าวในเชิงของความแปรปรวน วิธีการหนึ่งคือการหาค่าความแปรปรวนทั่วไป (generalized variance) ด้วยการหา determinant ของเมทริกซ์ความแปรปรวนร่วมดังกล่าว\nจากมโนทัศน์ดังกล่าวจะเห็นว่า Jeffrey’s prior เป็นการแจกแจงความน่าจะเป็นก่อนหน้าที่อิงกับการแจกแจงความน่าจะเป็นของตัวอย่างสุ่มเป็นหลัก จึงจัดเป็น noninformative prior ตัวหนึ่งสำหรับโมเดลการวิเคราะห์แบบพาราเมทริกซ์\nตัวอย่างต่อไปนี้แสดงการแจกแจงความน่าจะเป็นก่อนหน้าแบบ Jeffrey สำหรับปัญหาการวิเคราะห์ความเที่ยงของของเหรียญ\nจากตัวอย่างการวิเคราะห์ความเที่ยงตรงของเหรียญ เนื่องจากฟังก์ชันภาวะความควรจะเป็นของพารามิเตอร์ความลำเอียงเมื่อกำหนดข้อมูลตัวอย่างคือ \\(p(D|\\theta)=\\theta^{\\sum y_i}(1-\\theta)^{n-\\sum y_i}\\) ดังนั้น log ของฟังก์ชันภาวะความควรจะเป็นดังกล่าวคือ\n\\(ln \\ p(D|theta) = \\sum y_i ln\\theta+(n-\\sum y_i)ln(1-\\theta)\\)\nและอนุพันธ์อันดับที่ 2 ของ \\(ln \\ p(D|theta)\\) มีค่าเท่ากับ\n\\(\\frac{\\partial^2 ln\\ p(D|\\theta)}{\\partial\\theta^2}=-\\frac{\\sum y_i}{\\theta^2}-\\frac{n-\\sum y_i}{(1-\\theta)^2}\\)\nดังนั้น Fisher Information ของพารามิเตอร์ \\(\\theta\\) ในโมเดลข้างต้นจึงมีค่าเท่ากับ\n\\(J(\\theta)=E[-\\frac{\\partial^2 ln p(y|\\theta)}{\\partial \\theta^2}|\\theta]=E[-(-\\frac{\\sum y_i}{\\theta^2}-\\frac{n-\\sum y_i}{(1-\\theta)^2})]=\\frac{n}{\\theta}+\\frac{n(1-\\theta)}{(1-\\theta)^2}\\)\nสมมุติว่าจากการเก็บรวบรวมข้อมูลพบว่า โยนเหรียญ 20 ครั้ง มีหน้าหัวเกิดขึ้น 7 ครั้ง แล้ว Jeffrey’s prior ของพารามิเตอร์ความลำเอียงคือ\n\\(p(\\theta)=|J(\\theta)|^{1/2}=|\\frac{20}{\\theta}+\\frac{20(1-\\theta)}{(1-\\theta)^2}|^{-1/2}\\)\n\n\npar(mar=c(5,5,1,1))\ntheta<-seq(0.01,0.99,0.01)\np.theta<-abs((20/theta+(20*(1-theta))/(1-theta)^2))^{0.5}\nplot(theta, p.theta, type=\"l\", col=\"#004D80\",xlab=expression(theta), ylab=\"Density\")\n\n\n\n\nหมายเหตุ ในปัญหาที่ใช้ฟังก์ชันภาวะความควรจะเป็นแบบ binomial จะได้ว่า Jeffrey’s prior จะมีการแจกแจงเทียบเท่ากับการแจกแจง beta ที่มีพารามิเตอร์ a = 0.5 และ b = 0.5\nตัวอย่างต่อไปนี้แสดงการเปรียบเทียบการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ความลำเอียง เมื่อกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าเป็นแบบ uniform(0,1) และเป็นแบบ Jeffrey’s prior\n\nCompiling rjags model...\nCalling the simulation using the rjags method...\nNote: the model did not require adaptation\nBurning in the model for 4000 iterations...\nRunning the model for 5000 iterations...\nSimulation complete\nCalculating summary statistics...\nCalculating the Gelman-Rubin statistic for 2 variables....\nFinished running the simulation\n\n\nIterations = 5001:10000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean     SD  Naive SE Time-series SE\ntheta1 0.3646 0.1009 0.0008238      0.0008451\ntheta2 0.3567 0.1019 0.0008318      0.0008318\n\n2. Quantiles for each variable:\n\n         2.5%    25%    50%    75%  97.5%\ntheta1 0.1823 0.2924 0.3602 0.4324 0.5716\ntheta2 0.1717 0.2839 0.3519 0.4262 0.5639\n\nคุณสมบัติเด่นของ Jeffrey priors คือมีคุณสมบัติ invariant to transformation กล่าวคือ หาก \\(\\psi=f(\\theta)\\) จะได้ว่า \\(p(\\psi) \\varpropto |J(\\psi)|^{0.5}\\)\nพารามิเตอร์ในโมเดลการวิเคราะห์อาจจำแนกได้หลากหลายประเภท ขึ้นอยู่กับโมเดลการวิเคราะห์และตัวแปรในการวิเคราะห์ ทั้งนี้ธรรมชาติของพารามิเตอร์ดังกล่าวก็มีความแตกต่างกัน การกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์แต่ละประเภทจึงมีความแตกต่างกันตามธรรมชาติดังกล่าว โดยทั่วไปอาจจำแนกประเภทของพารามิเตอร์ได้ออกเป็น 4 ประเภทได้แก่ พารามิเตอร์ตำแหน่ง (location parameters) พารามิเตอร์สเกล (scale parameters) พารามิเตอร์สัดส่วน (proportion parameters) และพารามิเตอร์อัตรา (rate parameters) เนื้อหาต่อจากนี้จะกล่าวถึงการกำหนด informative priors สำหรับพารามิเตอร์แต่ละประเภท\nLocation parameters\nกำหนดให้ \\(\\theta\\) เป็นพารามิเตอร์ของโมเดลค่าสังเกต \\(p(y|\\theta)\\) หากการแจกแจงของ \\(y-\\theta\\) เป็นอิสระจากพารามิเตอร์ \\(\\theta\\) จะเรียกว่าพารามิเตอร์ \\(\\theta\\) เป็นพารามิเตอร์ตำแหน่ง (location parameters)\nConjugacy priors\nการแจกแจงความน่าจะเป็นก่อนหน้าจะเป็นการแจกแจงแบบ conjugacy prior ถ้าการแจกแจงความน่าจะเป็นก่อนหน้าและภายหลังเป็นการแจกแจงภายใน family เดียวกัน ด้วยคุณสมบัติดังกล่าวจึงทำให้การพิสูจน์หาสูตรหรือรูปแบบปิดของการแจกแจงความน่าจะเป็นภายหลังสามารถทำได้โดยที่ไม่ต้องหาเทอม \\(p(D)\\) ที่เป็นตัวส่วนใน Bayes’s rule\nตัวอย่างการแจกแจงก่อนหน้าแบบ conjugacy prior เช่น\nการแจกแจง beta คู่กับ binomial likelihood จะได้ posterior แบบ beta\nการแจกแจง normal คู่กับ normal likelihood จะได้ posterior แบบ normal\n\n\nInformative priors\ninformative prior หรือการแจกแจงความน่าจะเป็นก่อนหน้าแบบมีสารสนเทศ เป็นการแจกแจงความน่าจะเป็นก่อนหน้าที่รูปแบบของการแจกแจงไม่จำเป็นต้องขึ้นกับหรือเกี่ยวข้องกับฟังก์ชันภาวะความควรจะเป็น แต่ขึ้นกับสารสนเทศจากแหล่งอื่น ๆ นอกเหนือจากข้อมูลจริงที่ผู้วิเคราะห์มีเกี่ยวกับพารามิเตอร์ต่าง ๆ ภายในโมเดล สารสนเทศภายในการแจกแจงความน่าจะเป็นก่อนหน้าประเภทนี้อาจเรียกว่า ความรู้ก่อนหน้า (prior knowledge)\nการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าลักษณะนี้จึงมีผลโดยตรงต่อการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ ซึ่งอาจทำให้ผลการรวิเคราะห์ที่ได้มีความถูกต้องมากขึ้น หรืออาจทำให้ผลการวิเคราะห์ที่ได้มีความลำเอียงก็ได้ ขึ้นอยู่กับการออกแบบ informative prior ของผู้วิเคราะห์\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2022-02-08-priors/priors_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-02-21T22:57:29+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-05-jags/",
    "title": "Introduction to JAGS",
    "description": "การใช้งาน JAGS เบื้องต้น",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": {}
      }
    ],
    "date": "2022-02-04",
    "categories": [
      "Bayesian Statistics",
      "MCMC",
      "JAGs"
    ],
    "contents": "\n\nContents\nติดต้ังโปรแกรม\nการเขียนคำสั่งใน JAGS\nการนำเข้าและจัดการข้อมูล\nการระบุโมเดล\nโมเดลของค่าสังเกต\nการแจกแจงความน่าจะเป็นก่อนหน้า\nสภาพแวดล้อมของ JAGs\n\nการประมวลผล\nระบุ JAGs โมเดล\n\nrunjags packages\nrjags packages\nการตรวจสอบคุณสมบัติของตัวอย่างจาก MCMC algorithm\nการอนุมานเชิงสถิติแบบเบส์โดยใช้ตัวอย่างจาก MCMC algorithm\n\n\nผู้อ่านได้ทำความเข้าใจมโนทัศน์เกี่ยวกับอัลกอริทึม MCMC แล้ว อย่างไรก็ตามจะเห็นว่าการเขียนอัลกอริทึมดังกล่าวค่อนข้างลำบาก และมีโอกาสสูงที่จะเกิดความผิดพลาด ปัจจุบันมีโปรแกรมสำเร็จรูปหลายตัวที่ช่วยให้ผู้วิเคราะห์สามารถประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ภายในโมเดลใด ๆ ได้อย่างสะดวกมากยิ่งขึ้น บทเรียนนี้จะกล่าวถึงโปรแกรม JAGS (Just Another Gibb Sampler) รายละเอียดมีดังนี้\nติดต้ังโปรแกรม\nนิสิตสามารถ เข้าไปดาวน์โหลดโปรแกรม JAGS (Just Another Gibb Sampler) ได้ที่\nhttps://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/\nการใช้งาน JAGS ในข้างต้นจะไม่ได้ใช้งานแบบ standard alone แต่จะใช้งานผ่านโปรแกรม R ทั้งนี้ปัจจุบันมี package หลายตัวที่ถูกพัฒนาขึ้นเพื่อทำงานบน R ร่วมกับโปรแกรม JAGs เช่น R2jags, rjags และ runjags ในบทเรียนนี้จะกล่าวถึงการใช้งาน package ทั้งสาม โดยก่อนการใช้งานผู้้วิเคราะห์จำเป็นต้องดาวน์โหลด package ดังกล่าวก่อน ด้วยคำสั่งดังนี้\n\n\ninstall.packages(\"R2jags\")\ninstall.packages(\"rjags\", dependencies = TRUE)\ninstall.packages(\"runjags\", dependencies = TRUE)\n\n\n\nก่อนใช้งาน package ทั้งสองผู้ใช้จำต้องเรียกใช้ package ดังกล่าวก่อนโดยพิมพ์คำสั่งดังนี้\n\n\nlibrary(R2jags)\nlibrary(rjags)\nlibrary(runjags)\n\n\n\nกระบวนการทำงานร่วมกันระหว่าง R กับ JAGSการเขียนคำสั่งใน JAGS\nการเขียนคำสั่งต่าง ๆ จะทำบนโปรแกรม R ทั้งหมด โดยอาจแบ่งขั้นตอนการดำเนินงานออกเป็น 4 ขั้นตอนได้แก่ การนำเข้าและจัดการข้อมูล การระบุโมเดล การประมวลผล และการตรวจสอบและวิเคราะห์ผลลัพธ์ที่ได้ รายละเอียดมีดังนี้\nการนำเข้าและจัดการข้อมูล\nข้อมูลตัวอย่างผลสัมฤทธิ์ทางการเรียนวิชา calculas ของนิสิตจำนวน 100 คน บันทึกอยู่ในไฟล์ชื่อ bayes_exam1.csv ทั้งนี้เมื่อดาวน์โหลดข้อมูลมาแล้วสามารถนำเข้าสู่ R ได้โดยเขียนคำสั่งดังนี้\n\n\nlibrary(dplyr)\ndat<-read.csv(\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/bayes_exam1.csv\")\nglimpse(dat)\n\n\nRows: 100\nColumns: 2\n$ id  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ CAL <dbl> 68.8, 89.8, 40.0, 61.2, 8.8, 59.0, 57.5, 65.8, 50.9, 79.…\n\nการระบุโมเดล\nวัตถุประสงค์ของการวิเคราะห์มี 2 ข้อ ได้แก่\nเพื่อวิเคราะห์ระดับผลสัมฤทธิ์ทางการเรียนวิชา calculas ของนิสิต\nเพื่อวิเคราะห์ว่าค่าเฉลี่ยผลสัมฤทธิ์วิชา calculas ของนิสิตมีค่าสูงกว่า 50 คะแนนหรือไม่\nจากวัตถุประสงค์การวิเคราะห์และข้อมูลค่าสังเกตที่มี สามารถระบุโมเดลการวิเคราะห์ได้ดังนี้\nโมเดลของค่าสังเกต\nกำหนดให้โมเดลของคะแนนผลสัมฤทธิ์ (\\(y_i\\)) มีการแจกแจงแบบปกติที่มีค่าเฉลี่ยและความแปรปรวนเท่ากับ \\(\\mu\\) และ \\(\\sigma^2\\) ตามลำดับ เขียนแทนด้วย \\(y_i \\sim N(\\mu,\\sigma^2)\\) อย่างไรก็ตามในโปรแกรม JAGS จะไม่ได้ใช้พารามิเตอร์ความแปรปรวนเป็นพารามิเตอร์ของการแจกแจงแบบปกติ แต่ละใช้พารามิเตอร์ความเที่ยงตรง (precision parameter) ซึ่งเป็นส่วนกลับของพารามิเตอร์ความแปรปรวนแทน ดังนั้นโมเดลค่าสังเกตในกรณีนี้สามารถเขียนได้ดังนี้\n\\(y_i \\sim N(\\mu, \\tau=1/\\sigma^2)\\)\nจากโมเดลค่าสังเกตข้างต้นจะได้ ฟังก์ชันภาวะความควรจะเป็น (likelihood function) เป็น\n\\(p(D|y)=\\Pi_{i=1}^nN(y_i|\\mu, \\tau=1/\\sigma^2)\\)\nการแจกแจงความน่าจะเป็นก่อนหน้า\nจากการระบุโมเดลค่าสังเกตข้างต้น พบว่ามีพารามิเตอร์ 2 ตัวได้แก่ พารามิเตอร์ค่าเฉลี่ย และความเที่ยงตรง จึงระบุการแจกแจงความน่าจะเป็นก่อนหน้าให้กับพารามิเตอร์ทั้งสองเป็นดังนี้\n\\(\\mu \\sim N(m, t=1/S^2)\\) และ \\(\\tau \\sim Uniform(a,b)\\)\nความสัมพันธ์ระหว่างค่าสังเกต โมเดลความน่าจะเป็น และการแจกแจงความน่าจะเป็นก่อนหน้าสภาพแวดล้อมของ JAGs\nเมื่อผู้วิเคราะห์ระบุโมเดลเชิงทฤษฎีในข้างต้นแล้ว ขั้นตอนถัดมาคือการระบุโมเดลสำหรับโปรแกรม JAGS การระบุโมเดลใน JAGs จำเป็นต้องมีความรู้เบื้องต้นเกี่ยวกับสภาพแวดล้อมของโปรแกรม JAGs ก่อน ประเด็นแรกคือเรื่องวัตถุหรือตัวแปรภายต่าง ๆ ภายในโปรแกรม JAGs จะเรียกว่า node จำแนกออกเป็น 3 ประเภทได้แก่\nค่าคงที่ (constant nodes)\nค่าตัวแปรสุ่ม (Stochastic nodes) เป็นตัวแปรที่มีการแจกแจงความน่าจะเป็นกำกับโดเมนหรือค่าของตัวแปรไว้ การนิยามตัวแปรประเภทนี้จะเขียนอยู่ในรูปแบบ variable ~ distribution_name(par1, par2, ...) ยกตัวอย่างเช่น ตัวอย่างข้างต้นกำหนดให้โมเดลของค่าสังเกต \\(y_i\\) มีการแจกแจงแบบปกติ สามารถนิยามตัวแปรนี้บน JAGs ได้เป็น y[i] ~ dnorm(mu, tau) ส่วนการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ \\(\\mu\\) และ \\(\\tau\\) สามารถระบุได้เป็น mu ~ dnorm(m,t) และ tau ~ dunif(a,b)\n\nฟังก์ชันเชิงคณิตศาสตร์ (Deterministic nodes) เป็นตัวแปรที่สร้างขึ้นจากฟังก์ชันหรือความสัมพันธ์เชิงคณิตศาสตร์กับ node อื่น ๆ เช่น mu[i] <- b0+b1*x[i]\nประเด็นที่สองเป็นเรื่องเกี่ยวกับโครงสร้างของตัวแปร และการระบุตำแหน่งของสมาชิกภายในโครงการของตัวแปร ตัวแปรอาจจำแนกโดยใช้โครงสร้างของตัวแปรออกได้เป็น 4 ประเภทหลัก ๆ ได้แก่ ค่าคงที่หรือสเกลาร์ เวกเตอร์ เมทริกซ์ และอาร์เรย์ที่มีมิติตั้งแต่ 3 มิติขึ้นไป การระบุตำแหน่งของสมาชิกภายในตัวแปรดังกล่าวทำได้ในวิธีเดียวกับในโปรแกรม R เช่น\ny[i] หมายถึงสมาชิกตัวที่ i ในเวกเตอร์ y\nmu.p[i,j] หมายถึงสมาชิกในแถวที่ i และคอลัมนท์ที่ j\nประเด็นที่สามเป็นเรื่องการดำเนินการทวนซ้ำ (repeated structures) ในโปรแกรม JAGs ผู้วิเคราะห์ไม่จำเป็นต้องพิสูจน์เพื่อหารูปแบบของฟังก์ชันภาวะความควรจะเป็นด้วยตัวเอง แต่สามารถสั่งให้โปรแกรมประมวลผลได้โดยกำหนดโมเดลของค่าสังเกตเอาไว้ภายใต้ loop เช่น ฟังก์ชันภาวะความควรจะเป็นในตัวอย่างข้างต้นสามารถระบุได้ดังนี้\n\n\nfor (i in 1:n)\n{\n  y[i]~dnorm(mu, tau)\n}\n\n\n\nประเด็นสุดท้ายเป็นโครงสร้างของชุดคำสั่งสำหรับระบุโมเดลทั้งหมด แต่ละโมเดลจะมีส่วนประกอบ 3 ส่วนได้แก่\nฟังก์ชันภาวะความควรจะเป็น (likelihood function) ระบุภายใต้ for loop ดังตัวอย่างด้านบน\nการแจกแจงความน่าจะเป็นก่อนหน้า (prior distributions) ของพารามิเตอร์ภายใต้โมเดลการวิเคราะห์\nส่วน deterministic function ที่ใช้สำหรับสร้างสารสนเทศที่ต้องการจากพารามิเตอร์ของโมเดล\nตัวอย่างด้านล่างแสดงโครงสร้างของชุดข้อมูลที่ใช้ระบุโมเดลในโปรแกรม JAGs\n\nmodel{\n  \n  # Likelihood\n  for (i in 1:n)\n  {\n    \n  }\n  \n  # Prior Distributions\n  \n  \n  \n  # Derived quantities \n  \n  \n\n  } #end of model\n\nการประมวลผล\nตัวอย่างต่อไปนี้แสดงขั้นตอนการสั่งให้ JAGs ประมวลผลเพื่อสร้างตัวอย่างสุ่มของลูกโซ่มาร์คอฟ\nระบุ JAGs โมเดล\n\n\nmean.model<-\"\nmodel{\n  \n  # Likelihood\n  for (i in 1:n)\n  {\n    y[i]~dnorm(mu, tau)\n  }\n  \n  # Prior Distributions\n  mu~dnorm(0,0.01)\n  tau~dunif(0,5)\n  \n  # Derived quantities \n  sigma2<-1/tau\n  \n  }\"\n# write mean.model to model1.txt\nwriteLines(mean.model, con=\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/model1.txt\") \n\n\n\nในบางกรณี ผู้วิเคราะห์อาจไม่ต้องการสร้างไฟล์โมเดลเพิ่ม ก็สามารถเขียนโมเดลให้เก็บอยู่ใน R Console แล้วนำไปใช้ได้เลย โดยเขียนโมเดลเหมือนปกติ และบันทึกไว้ในลักษณะของ character variable ดังนี้\n\n\nmean.model<- \"model{\n  \n  # Likelihood\n  for (i in 1:n)\n  {\n    y[i]~dnorm(mu, tau)\n  }\n  \n  # Prior Distributions\n  mu~dnorm(0,0.01)\n  tau~dunif(0,5)\n  \n  # Derived quantities \n  sigma2<-1/tau\n\n}\"\n\n\n\nrunjags packages\nเป็น package หนึ่งที่สามารถเรียก JAGS จาก R ได้ ซึ่งมีจุดเด่นคือสามารถสั่งประมวลแบบคู่ขนาน (parallel) แยกตาม core ของ CPU ได้ในกรณีที่ผู้วิเคราะห์กำหนดให้สุ่มตัวอย่างจากลูกโซ่มาร์คอฟที่มีจำนวนมากกว่า 1 ลูกโซ่ ตัวอย่างคำสั่งเป็นดังนี้\n\n\n\n\n\nlibrary(runjags)\ndataList<-list(y=dat[,2], n=dim(dat)[1])\ninit1<-list(mu=50, tau=0.1)\ninit2<-list(mu=30, tau=0.01)\ninit3<-list(mu=90, tau=0.05)\ninitsList<-list(init1, init2, init3)\n\nmodel.runjags<-run.jags(method=\"parallel\",\n                        model=mean.model,\n                        monitor=c(\"mu\",\"sigma2\"),\n                        data=dataList,\n                        inits=initsList,\n                        n.chains=3,\n                        adapt = 1000,\n                        burnin=1000,\n                        sample = 10000,\n                        thin=1,\n                        summarise=TRUE,\n                        plots=FALSE,\n                        keep.jags.files = FALSE)\n\n\nCalling 3 simulations using the parallel method...\nFollowing the progress of chain 1 (the program will wait for\nall chains to finish before continuing):\nWelcome to JAGS 4.3.0 on Mon Feb 21 22:51:46 2022\nJAGS is free software and comes with ABSOLUTELY NO WARRANTY\nLoading module: basemod: ok\nLoading module: bugs: ok\n. . Reading data file data.txt\n. Compiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 100\n   Unobserved stochastic nodes: 2\n   Total graph size: 108\n. Reading parameter file inits1.txt\n. Initializing model\n. Adapting 1000\n-------------------------------------------------| 1000\n++++++++++++++++++++++++++++++++++++++++++++++++++ 100%\nAdaptation successful\n. Updating 1000\n-------------------------------------------------| 1000\n************************************************** 100%\n. . . Updating 10000\n-------------------------------------------------| 10000\n************************************************** 100%\n. . . . Updating 0\n. Deleting model\n. \nAll chains have finished\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nCalculating summary statistics...\nCalculating the Gelman-Rubin statistic for 2 variables....\nFinished running the simulation\n\nเมื่อประมวลผลเสร็จผู้วิเคราะห์สามารถเรียกดูข้อสรุปเบื้องต้นเกี่ยวกับตัวอย่างที่จำลองจากกระบวนการสุ่มข้างต้นได้ โดยพิมพ์ชื่อของตัวแปรที่เก็บผลลัพธ์จาก run.jags() ดังนี้\n\n\nJAGS model summary statistics from 30000 samples (chains = 3; adapt+burnin = 2000):\n                                                                 \n       Lower95 Median Upper95   Mean     SD Mode    MCerr MC%ofSD\nmu       53.76 57.155  60.486 57.148 1.7142   -- 0.009897     0.6\nsigma2  220.78 294.38  386.98  298.7 43.365   --   0.3183     0.7\n                              \n       SSeff     AC.10    psrf\nmu     30000 0.0010623 0.99998\nsigma2 18561 0.0020924  1.0001\n\nTotal time taken: 0.8 seconds\n\nสำหรับการตรวจสอบและวิเคราะห์ในเชิงลึกอื่น ๆ ผู้วิเคราะห์สามารถดึงกระบวนการสุ่มหรือลูกโซ่ของพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma^2\\) ที่จำลองขึ้นมาอยู่ในโปรแกรม R เพื่อดำเนินการวิเคราะห์ในขั้นตอนต่อไปได้โดยใช้คำสั่ง as.mcmc.list() ดังนี้\n\n\n# sampling posterior samples\nsamples2<-as.mcmc.list(model.runjags)\nhead(samples2)\n\n\n[[1]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 2001 \nEnd = 2007 \nThinning interval = 1 \n          mu  sigma2\n2001 57.7183 254.932\n2002 58.5496 243.467\n2003 57.9328 293.119\n2004 57.5600 294.991\n2005 56.2513 293.347\n2006 58.8261 269.252\n2007 56.7390 394.889\n\n[[2]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 2001 \nEnd = 2007 \nThinning interval = 1 \n          mu  sigma2\n2001 56.1406 257.030\n2002 60.0052 267.742\n2003 54.6358 297.965\n2004 61.1648 276.278\n2005 57.2437 266.714\n2006 56.3080 269.413\n2007 55.9064 293.455\n\n[[3]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 2001 \nEnd = 2007 \nThinning interval = 1 \n          mu  sigma2\n2001 58.2742 234.981\n2002 56.8457 379.848\n2003 60.4932 411.175\n2004 52.4721 358.486\n2005 57.9276 279.754\n2006 57.9101 271.696\n2007 55.6369 355.024\n\nattr(,\"class\")\n[1] \"mcmc.list\"\n\nrjags packages\n\n\nlibrary(rjags)\ndataList<-list(y=dat[,2], n=dim(dat)[1])\ninit1<-list(mu=50, tau=0.1)\ninit2<-list(mu=30, tau=0.01)\ninit3<-list(mu=90, tau=0.05)\ninitsList<-list(init1, init2, init3)\n\nmodel<-jags.model(file=\"/Users/siwachoat/Documents/myblog/myblog/_site/posts/2022-02-05-jags/model1.txt\",\n                  data = dataList,\n                  inits = initsList,\n                  n.chains = 3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 100\n   Unobserved stochastic nodes: 2\n   Total graph size: 108\n\nInitializing model\n\n\n\n# sampling posterior samples\nsamples<-coda.samples(model,\n                      variable.names = c(\"mu\",\"sigma2\"),\n                      n.iter = 10000,\n                      thin = 3)\n\n\n\n\n\nhead(samples)\n\n\n[[1]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 1003 \nEnd = 1021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 56.43256 260.1827\n[2,] 58.08109 240.6020\n[3,] 57.15929 309.9268\n[4,] 57.81921 305.7733\n[5,] 53.12747 297.9870\n[6,] 57.77474 256.4704\n[7,] 55.10281 338.0285\n\n[[2]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 1003 \nEnd = 1021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 58.06828 275.2967\n[2,] 56.13325 301.8069\n[3,] 58.43187 362.6531\n[4,] 59.48585 336.4785\n[5,] 54.42154 286.7141\n[6,] 57.87049 296.4444\n[7,] 56.62374 250.7779\n\n[[3]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 1003 \nEnd = 1021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 58.75184 289.5539\n[2,] 59.20780 242.4779\n[3,] 60.23269 334.7610\n[4,] 55.07300 294.2167\n[5,] 56.58239 404.0100\n[6,] 58.43708 290.1907\n[7,] 58.62258 335.7425\n\nattr(,\"class\")\n[1] \"mcmc.list\"\n\nการตรวจสอบคุณสมบัติของตัวอย่างจาก MCMC algorithm\n\n\nsummary(samples)\n\n\n\nIterations = 1003:10999\nThinning interval = 3 \nNumber of chains = 3 \nSample size per chain = 3333 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean     SD Naive SE Time-series SE\nmu      57.14  1.714  0.01714         0.0169\nsigma2 299.23 43.918  0.43921         0.4617\n\n2. Quantiles for each variable:\n\n         2.5%   25%    50%   75%  97.5%\nmu      53.71  56.0  57.15  58.3  60.43\nsigma2 226.06 268.1 294.94 325.8 398.87\n\n\n\nplot(samples)\n\n\n\nlibrary(MCMCvis)\nMCMCtrace(samples,  pdf = FALSE)\n\n\n\nMCMCtrace(samples,  pdf = FALSE, iter=100) #plot last 100 iterations\n\n\n\nprior<-rnorm(10000,0,100)\nMCMCtrace(samples,  pdf = FALSE, \n          param=\"mu\",\n          priors=prior, \n          n.eff=TRUE, \n          Rhat=TRUE,\n          post_zm = TRUE)\n\n\n\n\n\n\nautocorr.diag(samples)\n\n\n                  mu       sigma2\nLag 0    1.000000000  1.000000000\nLag 3   -0.013854327  0.031131352\nLag 15  -0.005109261 -0.003313333\nLag 30   0.003374236 -0.004582291\nLag 150 -0.002278163 -0.008102540\n\nautocorr.plot(samples)\n\n\n\n\n\n\ngelman.diag(samples)\n\n\nPotential scale reduction factors:\n\n       Point est. Upper C.I.\nmu              1          1\nsigma2          1          1\n\nMultivariate psrf\n\n1\n\ngelman.plot(samples)\n\n\n\n\n\n[[1]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n    mu sigma2 \n2.0851 0.5484 \n\n\n[[2]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n     mu  sigma2 \n0.03287 0.40353 \n\n\n[[3]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n     mu  sigma2 \n 0.9664 -0.8700 \n\n\n\nlibrary(ggplot2)\ntheta_sim_posterior <- data.frame(as.matrix(samples))\nnames(theta_sim_posterior) = c(\"mu\",  \"sigma2\")\n\nggplot(theta_sim_posterior, aes(mu, sigma2)) +\n  geom_point(color = \"skyblue\", alpha = 0.4) +\n  geom_density_2d(color = \"orange\", size = 1)+\n  theme_minimal()\n\n\n\n\nการอนุมานเชิงสถิติแบบเบส์โดยใช้ตัวอย่างจาก MCMC algorithm\nsummary\n\n\nsummary(samples)\n\n\n\nIterations = 1003:10999\nThinning interval = 3 \nNumber of chains = 3 \nSample size per chain = 3333 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean     SD Naive SE Time-series SE\nmu      57.14  1.714  0.01714         0.0169\nsigma2 299.23 43.918  0.43921         0.4617\n\n2. Quantiles for each variable:\n\n         2.5%   25%    50%   75%  97.5%\nmu      53.71  56.0  57.15  58.3  60.43\nsigma2 226.06 268.1 294.94 325.8 398.87\n\nhist(theta_sim_posterior$mu, xlim=c(49,65))\nabline(v=quantile(theta_sim_posterior$mu, c(0.025, 0.975)), lty=2)\n\n\n\n\nMCMCsummary\n\n\nlibrary(MCMCvis)\nMCMCsummary(samples)\n\n\n            mean        sd      2.5%       50%     97.5% Rhat n.eff\nmu      57.13614  1.714003  53.71186  57.15313  60.42819    1 10305\nsigma2 299.22542 43.918370 226.06284 294.93688 398.87008    1  9056\n\nMCMCsummary(samples, params=\"mu\", round=2)\n\n\n    mean   sd  2.5%   50% 97.5% Rhat n.eff\nmu 57.14 1.71 53.71 57.15 60.43    1 10305\n\nMCMCplot\nMCMCplot is used to create caterpillar plots from MCMC output. Points represent posterior medians. Thick and thin lines represent credible intervals specified by the user using the ci argument, where the default is 50% and 95% credible intervals, respectively. Note, that the first element in ci should be less than or equal to the second element. By default, MCMCplot plots equal-tailed credible intervals (HPD = FALSE). However, highest posterior density intervals can be visualized using HPD = TRUE. As with the other functions in the package, particular parameters of interest can be specified.\n\n\n\n\n\n## HPD interval\nHPDinterval(samples)\n\n\n[[1]]\n           lower     upper\nmu      53.80359  60.55682\nsigma2 220.22488 386.86409\nattr(,\"Probability\")\n[1] 0.949895\n\n[[2]]\n           lower     upper\nmu      53.74889  60.19107\nsigma2 220.10985 386.38192\nattr(,\"Probability\")\n[1] 0.949895\n\n[[3]]\n           lower     upper\nmu      53.79186  60.57281\nsigma2 217.05962 383.50001\nattr(,\"Probability\")\n[1] 0.949895\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2022-02-05-jags/jags_files/figure-html5/unnamed-chunk-16-1.png",
    "last_modified": "2022-02-21T22:51:55+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-03-mcmc-via-jags/",
    "title": "Markov Chain Monte Carlo (MCMC)",
    "description": "มโนทัศน์ของลูกโซ่มาร์คอฟมอนติคาร์โล",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [
      "Bayesian Statistics",
      "MCMC",
      "JAGs"
    ],
    "contents": "\n\nContents\nMCMC algorithm\nMetropolis algorithm\nExample 1: Tossing coin\nExample 2: One-sample Mean and SD\n\nGibbs Sampling algorithm\nAssessing MCMC samples\nConvergence\nการตรวจสอบแนวโน้มการลู่เข้าด้วย Trace plot และ Density plot\nAutocorrelation\nThining\nEffective Sample Size (ESS)\n\nMonte Carlo Standard Error\nPotential Scale Reduction (\\(\\hat{R}\\) หรือ RSRF)\n\n\nMCMC algorithm\nหัวข้อนี้จะกล่าวถึงมโนทัศน์ของลูกโซ่มาร์คอฟมอนติคาร์โล (Monte Carlo Markov Chain: MCMC) ที่เป็นเครื่องมือสำคัญสำหรับประมาณการแจกแจงความน่าจะเป็นภายหลัง (posterior distribution) สำหรับการวิเคราะห์ข้อมูลที่อาศัยแนวคิดแบบเบส์\nแนวคิดเกี่ยวกับ MCMC มีมาค่อนข้างยาวนานประมาณ 40 ปีแล้ว แต่ด้วยข้อจำกัดทั้งด้านโปรแกรมและประสิทธิภาพของคอมพิวเตอร์ทำให้การใช้งานอัลกอริทึม ในสมัยก่อนทำได้ยาก และเกือบจะเป็นไปไม่ได้ที่จะใช้งานอัลกอริทึม MCMC กับปัญหาทางสถิติที่มีความซับซ้อน แต่ด้วยความก้าวหน้าทางเทคโนโลยีในยุคปัจจุบันทำให้ข้อจำกัดดังกล่าวลดลงจนแทบไม่มีอีกต่อไป\nอัลกอริทึม MCMC เป็นอัลกอริทึมที่ใช้สำหรับประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ โดยใช้ตัวอย่างสุ่มที่สร้างจากเทคนิคการจำลองแบบมอนติคาร์โล แทนการพิสูจน์หรือการทดลองแทนค่าเพื่อหาค่าที่ดีที่สุดทางคณิตศาสตร์ คำตอบที่ได้จากอัลกอริทึม MCMC นี้จึงไม่ใช่สูตรหรือฟังก์ชันทางคณิตศาสตร์ แต่จะเป็นตัวอย่างสุ่มของพารามิเตอร์ที่สร้างขึ้น ตัวอย่างดังกล่าวหากมีจำนวนที่มากเพียงพอ จะสามารถใช้เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ และสามารถนำตัวอย่างดังกล่าวมาผ่านกระบวนการทางสถิติเพื่อสร้างข้อสรุปเกี่ยวกับพารามิเตอร์ในโมเดลได้โดยตรง กล่าวโดยสรุปได้ว่าอัลกอริทึม MCMC เป็นเทคนิคที่นำมาประยุกต์ใช้ในการวิเคราะห์ข้อมูลแบบเบส์ เพื่อประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ต่าง ๆ ภายในโมเดล ด้วยตัวอย่างสุ่มของพารามิเตอร์\nรูปต่อไปนี้แสดงการเปรียบเทียบระหว่างการแจกแจงความน่าจะเป็นเชิงทฤษฎี (theoretical/exact distribution) กับการแจกแจงความน่าจะเป็นที่ประมาณด้วยตัวอย่างสุ่มที่สร้างจากเทคนิคการจำลองแบบมอนติคาร์โล\nด้วยเทคนิคการจำลองแบบมอนติคาร์โล ผู้วิเคราะห์สามารถจำลองตัวอย่างสุ่มจากการแจกแจงความน่าจะเป็นใดก็ได้ แต่มีเงื่อนไขว่าต้องทราบฟังก์ชันความน่าจะเป็นของการแจกแจงดังกล่าวก่อน เงื่อนไขนี้เป็นข้อจำกัดที่ทำให้ไม่สามารถใช้เทคนิคการจำลองแบบมอนติคาร์โลแบบปกติได้โดยตรง ทั้งนี้เป็นเพราะในโมเดลที่มีความซับซ้อนระดับหนึ่ง เป็นการยากมากที่ผู้วิเคราะห์จะทราบรูปแบบหรือฟังก์ชันของการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ในโมเดลที่ต้องการใช้งาน\n\n\nlibrary(scales)\nx<-seq(-3,3,0.01)\npar(mfrow=c(2,3), mar=c(1,5,6,5))\nplot(x, dnorm(x,0,1),type=\"l\", main=\"exact distribution N(0,1)\", xlab=\"X\")\nhist(rnorm(500,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=500\", xlab=\"X\")\nhist(rnorm(1000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=1000\", xlab=\"X\")\nhist(rnorm(5000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=5000\", xlab=\"X\")\nhist(rnorm(10000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=10000\", xlab=\"X\")\nhist(rnorm(50000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=50000\", xlab=\"X\")\n\n\n\n\nMetropolis algorithm\nMetropolis algorithm เป็นกระบวนการสุ่ม (random process/stochastic process) ประเภทหนึ่ง ตั้งชื่ออัลกอริทึมตามคณะผู้พัฒนาได้แก่ Metropolis, Rosenbluth, Rosenbluth, Teller & Teller (1953)\nอัลกอริทึมนี้สามารถนำมาประยุกต์ใช้เพื่อหาการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ โดยปริภูมิของพารามิเตอร์ (parameters space) ดังกล่าวนั้นเป็นไปได้ทั้งแบบไม่ต่อเนื่อง (discrete) และแบบต่อเนื่อง (continuous) และสามารถใช้ได้กับปริภูมิพารามิเตอร์ที่มีมิติตั้งแต่หนึ่งมิติ (unidimensional) ไปจนถึงหลายมิติ (multidimensional) อัลกอริทึม Metropolis มีลักษณะการทำงานแบบทวนซ้ำ (interative) มีรายละเอียดของขั้นตอนวิธีดังนี้\nกำหนดให้ \\(p(\\theta)\\) เป็นการแจกแจงความน่าจะเป็นภายหลังที่ต้องการประมาณ\nสุ่ม/เลือกค่าตั้งต้น (initial values) ของพารามิเตอร์ในการแจกแจงความน่าจะเป็นภายหลัง เขียนแทนด้วย \\(\\theta_0\\) ทั้งนี้ค่าพารามิเตอร์ที่สุ่มมามีเงื่อนไขคือต้องอยู่ภายใต้ปริภูมิของพารามิเตอร์ กล่าวคือ \\(p(\\theta_0)>0\\)\nสร้างค่า proposal jump เพื่อใช้เป็นตัวปรับค่าตั้งต้นของพารามิเตอร์ เขียนแทนด้วย \\(\\Delta\\theta\\) จากการแจกแจงความน่าจะเป็นโครงร่าง (proposal distribution) ที่กำหนดไว้ เช่นอาจกำหนดให้ \\(\\Delta\\theta \\sim N(0, \\sigma)\\) ซึ่งจะได้ proposed values ของพารามิเตอร์ค่าใหม่เขียนแทนด้วย \\(\\theta_{pro}\\) โดยที่ \\(\\theta_{pro}=\\theta_{i-1}+\\Delta\\theta\\) เมื่อ \\(i=1,2,3,...,m\\)\nคำนวณค่าความน่าจะเป็นในการเดิน/เปลี่ยนแปลงของ proposed values ดังนี้ \\(p_{move}=min(1,\\frac{p(\\theta_{pro})}{p(\\theta_{i-1})})\\) โดยที่ \\(p(\\theta_{pro})=p(D|\\theta_{pro}p(\\theta_{pro}))\\) และ \\(p(\\theta_{i-1})=p(D|\\theta_{i-1})p(\\theta_{i-1})\\) จากความน่าจะเป็นข้างต้น จะเห็นว่า ถ้า \\(\\theta_{pro}\\) มีค่าอยู่นอกเหนือค่าที่เป็นไปได้หรือค่าที่ควรจะเป็นของพารามิเตอร์ \\(\\theta\\) ในโมเดล ค่าความน่าจะเป็นก่อนหน้า \\(p(\\theta_{pro})\\) และ/หรือค่าของฟังก์ชันภาวะความควรจะเป็น \\(p(D|\\theta_{pro})\\) จะมีค่าเท่ากับ 0 ซึ่งทำให้ค่า \\(p_{move}=0\\)\nเกณฑ์การพิจารณายอมรับค่า proposed value \\(\\theta_{pro}\\) จะยอมรับด้วยความน่าจะเป็นเท่ากับ \\(p_{move}\\) ในทางปฏิบัติจะสุ่มเลขสุ่มจากการแจกแจงแบบ uniform [0,1] ขึ้นมา 1 ค่า เขียนแทนด้วย \\(u\\) หาก \\(u<p_{move}\\) จะยอมรับค่า \\(theta_{pro}\\) ดังกล่าว แต่ถ้าหาก \\(u > p_{move}\\) จะปฏิเสธค่า \\(\\theta_{pro}\\) ในกรณีนี้ค่าพารามิเตอร์ \\(\\theta_{i-1}\\) ก็จะไม่ได้มีการเปลี่ยนแปลงสถานะ\nอัลกอริทึมข้างต้นเป็นกระบวนการทวนซ้ำโดยจะดำเนินการทวนซ้ำในขั้นตอนที่ 2-4 จนกระทั่งตัวอย่างพารามิเตอร์ \\(\\theta\\) มีจำนวนเพียงพอ และมีคุณสมบัติที่เหมาะสม\nExample 1: Tossing coin\nจากตัวอย่างปัญหาการวิเคราะห์ความเที่ยงตรงของเหรียญ หากต้องการทำ MCMC เพื่อประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ความลำเอียง อาจดำเนินการดังนี้\nกำหนดให้ \\(y_i\\) คือค่าสังเกตของการโยนเหรียญ โดยที่ \\(i=1,2,3...,n\\) และโมเดลของค่าสังเกตดังกล่าวคือ \\(p(y_i|\\theta)=\\theta^y_i(1-\\theta)^{n-y_i}\\) จากการกำหนดนี้จะได้ฟังก์ชันภาวะความควรจะเป็นคือ\n\n\\(p(y|\\theta)=\\theta^{\\sum y_i}(1-\\theta)^{n-\\sum y_i}\\)\n\nและกำหนดให้พารามิเตอร์ \\(\\theta\\) มีการแจกแจงความน่าจะเป็นก่อนหน้าเป็น\n\n\\(p(\\theta)=Beta(\\theta|a,b)\\)\n\nการแจกแจงความน่าจะเป็นแบบ Beta มีธรรมชาติของการแจกแจงคือ ค่าที่เป็นไปได้ของโดเมนอยู่บนช่วง [0,1] ซึ่งสอดคล้องกับธรรมชาติของพารามิเตอร์ความลำเอียงในโมเดลค่าสังเกต\nKruschke, 2015ในกรณีนี้เลือกการแจกแจงความน่าจะเป็นก่อนหน้าเป็น \\(Beta(1,1)\\) ซึ่งจะเห็นว่าเทียบเท่ากับการแจกแจงแบบ uniform ที่หมายถึงผู้วิเคราะห์ไม่ได้มีสารสนเทศเบื้องต้นใด ๆ เกี่ยวกับความลำเอียงของเหรียญที่ทำการศึกษา นอกจากขอบเขตที่เป็นไปได้ของค่าพารามิเตอร์\nจากการกำหนดเงื่อนไขของการศึกษาในข้างต้น จะค่าความน่าจะเป็นในการเปลี่ยนแปลงสถานะหรือ \\(p_{move}\\) เป็น\n\\(p_{move}=min(1,\\frac{p(\\theta_{pro})}{p(\\theta{i-1})})\\)\n\\(=min(1, \\frac{[\\theta_{pro}^{\\sum y_i}(1-\\theta_{pro})^{n-\\sum y_i}] \\times Beta(\\theta_{pro}|1,1)}{[\\theta_{i-1}^{\\sum y_i}(1-\\theta_{i-1})^{n-\\sum y_i}] \\times Beta(\\theta_{i-1}|1,1)})\\)\nเนื่องจากการแจกแจงความน่าจะเป็นแบบ Beta มีฟังก์ชันความน่าจะเป็นคือ \\(p(\\theta|a,b)=\\frac{1}{B(a,b)} \\theta^{a-1}(1-\\theta)^{b-1}\\) โดยที่ \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) และ \\(\\Gamma(.)\\) คือฟังก์ชันแกมมา (Gamma function)\nดังนั้นความน่าจะเป็นในการเปลี่ยนสถานะของ proposed values จะมีค่าเท่ากับ\n\\(p_{move}=min(1,\\frac{\\theta_{pro}^{\\sum y_i+a-1}(1-\\theta_{pro})^{n-\\sum y_i+b-1}/B(a,b)}{\\theta_{i-1}^{\\sum y_i+a-1}(1-\\theta_{i-1})^{n-\\sum y_i+b-1}/B(a,b)})\\)\nสมมุติว่าผู้วิเคราะห์ทำการทดสอบโยนเหรียญ 20 ครั้ง และได้หน้าหัวเท่ากับ 7 ครั้ง\n\n\ntheta<-0.99 #initial value\nm<-5000 #iteration number\ntheta.dat<-matrix(nrow=m,ncol=3)\nsd.pro<-c(0.02,0.2,2) #learning rate\ncount<-matrix(nrow=m, ncol=3)\n\nfor(j in 1:length(sd.pro))\n  {\n  for(i in 1:m)\n    {\ndelta.theta<-rnorm(1,0,sd.pro[j]) #proposal jump (change)\ntheta.pro<-theta+delta.theta #proposed bias parameter\n\nnom<-theta.pro^(7+1-1)*(1-theta.pro)^(20-7+1-1)\ndenom<-theta^(7+1-1)*(1-theta)^(20-7+1-1)\n\np.move<-min(1,nom/denom)\n\nif(runif(1,0,1)<p.move)\n{theta<-theta.pro\ncount[i,j]<-1\n}else{\n\ntheta<-theta  \ncount[i,j]<-0\n}\ntheta.dat[i,j]<-theta\n  } # end of m iteration\n} # end of sd loop\n\n\n\nจากการดำเนินอัลกอริทึมในข้างต้น พบว่าได้ผลการวิเคราะห์ดังต่อไปนี้\n\n\n\nเราอาจพิจารณาประสิทธิภาพของอัลกอริทึมในข้างต้นจากสัดส่วนของจำนวนค่าพารามิเตอร์ผ่านการยอมรับต่อจำนวน proposed values ของพารามิเตอร์ ซึ่งจะพบว่ามีค่าเท่ากับ\n\n\ncolSums(count)/5000\n\n\n[1] 0.9410 0.5086 0.0658\n\nExample 2: One-sample Mean and SD\nสมมุตินักวิจัยต้องการประมาณค่าเฉลี่ย IQ ของนักเรียนในโรงเรียนสังกัด สพฐ. ว่ามีค่าสูงกว่าเกณฑ์มาตรฐานคือ 90 คะแนน หรือไม่ ในการวิจัยนักวิจัยได้สร้างแบบวัด IQ และนำไปเก็บรวบรวมข้อมูลจากนักเรียนดังกล่าวจำนวน 3000 คน พบว่ามีคะแนนดังนี้\n\n\nset.seed(123)\niq<-rnorm(3000,99,10) #IQ sample data\nhist(iq, nclass=30, xlab=\"IQ score\",col=alpha(\"#004D80\",0.7))\n\n\n\n\nจากปัญหาในข้างต้น นักวิจัยได้กำหนดโมเดลของค่าสังเกตด้วยการแจกแจงความน่าจะเป็นแบบปกติ ดังนี้ \\(y_i \\sim N(\\mu,\\ \\sigma)\\) ที่มีฟังก์ชันความน่าจะเป็นคือ\n\\(p(y_i|\\mu,\\ \\sigma)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp\\{-\\frac{1}{2\\sigma^2}(y_i-\\mu)^2\\}\\)\nซึ่งทำให้ได้ว่าฟังก์ชันภาวะความควรจะเป็นของข้อมูลค่าสังเกตเมื่อกำหนดพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\) คือ\n\\(\\Pi_{i=1}^n p(y_i|\\mu,\\sigma)=(\\frac{1}{\\sqrt{2\\pi\\sigma^2}})^nexp\\{-\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\sum_{i=1}^n(y_i-\\mu)^2 \\}\\)\nเนื่องจากพารามิเตอร์ทั้งสองเป็นอิสระซึ่งกันและกัน การกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าให้กับพารามิเตอร์ดังกล่าวจึงสามารถกำหนดแยกจากการได้อย่างอิสระ โดยในตัวอย่างนี้จะกำหนดให้การแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ค่าเฉลี่ยมีการแจกแจงแบบปกติ ที่มีค่าเฉลี่ยเท่ากับ 90 และส่วนเเบี่ยงเบนมาตรฐานเท่ากับ 30 ดังนี้\n\\(p(\\mu|\\mu_p=90, \\sigma_p=30)=\\frac{1}{\\sqrt{2\\pi\\times30^2}}exp\\{-\\frac{1}{2\\times30^2}(\\mu-90)^2 \\}\\)\nและกำหนดให้พารามิเตอร์ความแปรปรวน (\\(\\sigma^2\\) ) มีการแจกแจงความน่าจะเป็นก่อนหน้าเป็นแบบ uniform บนช่วง [0,10000] ซึ่งมีฟังก์ชันความน่าจะเป็นดังนี้\n\\(p(\\sigma^2)=\\frac{1}{10000}\\)\nรูปด้านล่างแสดงโค้งความหนาแน่นของการแจกแจงความน่าจะเป็นก่อนหน้าของ \\(\\mu \\sim N(90,30)\\) และ \\(\\sigma^2 \\sim U(0,10000)\\)\n\n\n\nจากการกำหนดในข้างต้นจะได้ว่าความน่าจะเป็นในการเปลี่ยนสถานะของพารามิเตอร์ทั้งสองมีค่าเท่ากับ\n\\(p.move=min(1,\\frac{p(y|\\mu_{pro},\\sigma_{pro})p(\\mu_{pro},\\sigma_{pro})}{p(y|mu_{i-1},\\sigma_{i-1})p(\\mu_{i-1},\\sigma_{i-1})})\\)\n\\(=min(1,\\frac{p(y|\\mu_{pro},\\sigma_{pro})\\times N(mu_{pro}|90,30) \\times (1/10000)}{p(y|\\mu_{i-1},\\sigma_{i-1})\\times N(mu_{i-1}|90,30) \\times (1/10000)})\\)\nอย่างไรก็ตามจะเห็นว่าความน่าจะเป็นข้างต้นมีสูตรค่อนข้างซับซ้อนและการคำนวณตรง ๆ อาจมีปัญหา ผู้วิเคราะห์จึง take log เข้าที่ความน่าจะเป็นดังกล่าวจึงทำให้เกณฑ์การพิจารณากลายเป็น\n\\(p.move = min(0, [lnp(y|\\mu_{pro},\\sigma_{pro})+lnN(mu_{pro}|90,30)+0]-[lnp(y|\\mu_{i-1},\\sigma_{i-1})+lnN(mu_{i-1}|90,30)+0]\\)\nจากเงื่อนไขข้างต้นสามารถเขียนอัลกอริทึม Metropolis เพื่อประมาณพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\) ได้ดังนี้\n\n\n#initial value\nmu<-50\nsigma<-30\n\n#iteration number\nm<-5000 \ntheta.dat<-matrix(nrow=m,ncol=6)\nsd.pro<-c(0.05,0.2,2)\ncount<-matrix(nrow=m, ncol=3)\n\nfor(j in 1:length(sd.pro))\n  {\nfor(i in 1:m)\n{\n\ndelta.mu<-rnorm(1,0,sd.pro[j])\ndelta.sigma<-rnorm(1,0,sd.pro[j])\n\n#proposed values\nmu.pro<-mu+delta.mu \nsigma.pro<-sigma+delta.sigma\n\nnom<-sum(dnorm(iq,mean = mu.pro,sd = sigma.pro, log=TRUE))+dnorm(mu.pro,90,30, log=TRUE)\ndenom<-sum(dnorm(iq,mean = mu,sd = sigma, log=TRUE))+dnorm(mu,90,30, log=TRUE)\n\np.move<-min(1,exp(nom-denom))\n\nif(p.move==\"NaN\")\n{\nmu<-mu\nsigma<-sigma\ncount[i,j]<-0\n} else if (runif(1,0,1)<p.move)\n{\nmu<-mu.pro\nsigma<-sigma.pro\ncount[i,j]<-1\n}\nelse\n{\nmu<-mu\nsigma<-sigma\ncount[i,j]<-0\n}\n\ntheta.dat[i,2*j-1]<-mu\ntheta.dat[i,2*j]<-sigma\n  } # end of m iteration\n}#end of sd loop\n\ncolnames(theta.dat)<-c(\"mu_sdpro1\",\"sigma_sdpro1\",\"mu_sdpro2\",\"sigma_sdpro2\",\"mu_sdpro3\",\"sigma_sdpro3\")\n\n\n\nประสิทธิภาพในด้านการยอมรับ proposed value ในแต่ละเงื่อนไขเป็นดังนี้\n\n\ncolSums(count)\n\n\n[1] 3355 2245   52\n\nการแจกแจงความน่าจะเป็นภายหลังที่ประมาณได้ในตัวอย่างนี้เป็นการแจกแจงความน่าจะเป็นร่วม (joint probability distribution) เนื่องจากมีพารามิเตอร์ 2 ตัวที่ต้องการประมาณค่า รูปต่อไปนี้แสดงการประมาณการแจกแจงความน่าจะเป็นภายหลังจากตัวอย่างสุ่มของพารามิเตอร์ทั้งสองที่สร้างจากอัลอริทึม Metropolis\n\n\npar(mfrow=c(2,3))\nplot(theta.dat[,1],theta.dat[,2], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=0.005\")\nplot(theta.dat[,3],theta.dat[,4], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=0.02\")\nplot(theta.dat[,5],theta.dat[,6], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=2\")\n\nlibrary(MASS)\nden3d<-kde2d(theta.dat[1000:5000,1],theta.dat[1000:5000,2])\npersp(den3d, box=T,phi=20,theta=-30, xlab=\"mu\", ylab=expression(sigma))\n\nden3d<-kde2d(theta.dat[1000:5000,3],theta.dat[1000:5000,4])\npersp(den3d, box=T,phi=20,theta=50, xlab=expression(mu), ylab=expression(sigma))\n\nden3d<-kde2d(theta.dat[1000:5000,5],theta.dat[1000:5000,6])\npersp(den3d, box=T,phi=20,theta=50, xlab=expression(mu), ylab=expression(sigma))\n\n\n\n\nจากตัวอย่างในข้างต้น ผู้อ่านจะเห็นว่าตัวอย่างที่สุ่มจากอัลกอริทึม Metropolis ข้างต้นมีลักษณะที่แตกต่างกันออกไปตามลักษณะของ proposal distribution ที่กำหนด\nถ้า proposal distribution มีลักษณะการกระจายที่แคบกว่าการแจกแจงความน่าจะเป็นภายหลัง/การแจกแจงเป้าหมาย ที่ต้องการประมาณมาก กระบวนการสุ่มที่สร้างขึ้นจากอัลกอริทึม Metropolis ในข้างต้นจะสร้างตัวอย่างสุ่มของพารามิเตอร์ที่เป็นตัวแทน ครอบคลุมการแจกแจงความน่าจะเป็นภายหลังที่ต้องการได้ช้า ภายใต้สถานการณ์ดังกล่าว ผู้วิเคราะห์จึงต้องใช้จำนวนการทวนซ้ำที่เพ่ิมจึ้นกว่าปกติเพื่อที่จะได้ตัวอย่างของพารามิเตอร์ที่เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังดังกล่าวได้ ในทางกลับกันหาก proposal distribution มีการกระจายที่กว้างเมื่อเปรียบเทียบกับการแจกแจงความน่าจะเป็นภายหลัง จะทำให้การพัฒนาค่าของพารามิเตอร์ในแต่ละรอบมีการเปลี่ยนแปลงมากเกินไป และอาจไม่สามารถลู่เข้าไปสู่การแจกแจงความน่าจะเป็นภายหลังที่ต้องการได้\nปัจจัยในข้างต้นส่งผลโดยตรงต่อประสิทธิภาพของอัลกอริทึม Metropolis การพิจารณาว่า proposal distribution ดังกล่าวมีความเหมาะสมแล้วหรือไม่ อาจพิจารณาได้จากอัตราส่วนการยอมรับ ซึ่งคำนวณได้จาก จำนวนพารามิเตอร์ที่ได้รับการยอมรับต่อจำนวนการทวนซ้ำทั้งหมด รูปต่อไปนี้แสดงการเปรียบเทียบกระบวนการสุ่มที่สร้างจากอัลกอริทึม MCMC ภายใต้สถานการณ์ที่มีการกำหนดการกระจายของ proposal distribution แตกต่างกัน\nปัจจัยในข้างต้นส่งผลโดยตรงต่อประสิทธิภาพของอัลกอริทึม Metropolis การพิจารณาว่า proposal distribution ดังกล่าวมีความเหมาะสมแล้วหรือไม่ อาจพิจารณาได้จากอัตราส่วนการยอมรับ ซึ่งคำนวณได้จาก จำนวนพารามิเตอร์ที่ได้รับการยอมรับต่อจำนวนการทวนซ้ำทั้งหมด\n\n\ncolSums(count)/5000\n\n\n[1] 0.6710 0.4490 0.0104\n\nGibbs Sampling algorithm\nอัลกอริทึม Metropolis ที่กล่าวในหัวก่อนหน้านี้เป็นอัลกอริทึมที่มีประโยชน์มากสำหรับหาการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ที่ไม่สามารถพิสูจน์หรือหารูปแบบปิดได้ อย่างไรก็ตามอัลกอริทึมดังกล่าวอาจมีประสิทธิภาพต่ำในหลายกรณีดังจะเห็นในตัวอย่างก่อนหน้านี้ที่หลายกรณีมีการ reject ค่า proposed value จำนวนมากจน ตัวอย่างที่เหลืออาจมีปริมาณน้อยเกินไปจนไม่เพียงพอที่จะนำไปใช้อนุมานเกี่ยวกับพารามิเตอร์ที่ต้องการ\nปัจจัยสำคัญที่มีผลต่ออัตราการยอมรับหรือปฏิเสธค่า proposed values คือการแจงแจงโครงร่าง การกำหนดการแจกแจงโครงร่างที่มีขอบเขตแคบมากเกินไป ถึงแม้ว่าในกรณีนี้อัตราการยอมรับค่า proposed value จะมีสูง แต่จะเห็นว่าอัลกอริทึมต้องใช้จำนวนรอบการทวนซ้ำที่มากขึ้น เพื่อให้ได้ตัวอย่างของพารามิเตอร์ที่ครอบคลุมและเป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ\nในทางกลับกันหากกำหนดการแจกแจงความน่าจะเป็นโครงร่างที่มีขอบเขตกว้างมากเกินไป จะเห็นว่าอัตราการยอมรับ proposed value มีแนวโน้มต่ำลงมา ทั้งนี้เป็นเพราะมีโอกาสสูงขึ้นที่ proposed value ที่ได้จะถูกสุ่มมาแล้วอยู่นอกเหนือขอบเขตที่เป็นไปได้จริงของพารามิเตอร์ที่ต้องการประมาณ\nรูปด้านล่างแสดงการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\) ใน mean model \\(y_i=\\mu+\\epsilon_i\\) ภายใต้สถานการณ์ที่มีการกำหนดการแจกแจงโครงร่างแตกต่างกัน\n\n\n\nจากข้อจำกัดนี้จึงมีการพัฒนาอัลกอริทึมตัวอื่น ๆ ขึ้นมาเพิ่มเติม อัลกอริทึม Gibbs Sampling พัฒนาขึ้นโดย Geman และ Geman (1984) เป็นอัลกอริทึมหนึ่งที่มีจุดเด่นในการนำมาใช้ประมาณการแจกแจงความน่าจะเป็นภายหลังของโมเดลการวิเคราะห์ที่มีพารามิเตอร์จำนวนมาก\nGibbs sampling เป็นแนวเดินสุ่ม (random walk) ประเภทหนึ่งเหมือนกับอัลกอริทึม Metropolis ความแตกต่างระหว่าง Gibbs กับ Metropolis ของในแต่ละขั้นของการทวนซ้ำ Metropolis จะสุ่มตัวอย่างของพารามิเตอร์ทุกตัวขึ้นมาพร้อมกันจากการแจกแจงความน่าจะเป็นภายหลัง \\(p(\\theta_1, \\theta_2, \\theta_3,...,\\theta_k|D)\\)\nในขณะที่แต่ละรอบการทวนซ้ำของอัลกอริทึม Gibbs sampling จะแบ่งสุ่มพารามิเตอร์ทีละค่า จากการแจกแจงความน่าจะเป็นภายหลังแบบมีเงื่อนไข\n\\(p(\\theta_1|D,\\theta_2, \\theta_3, ...,\\theta_k)\\)\n\\(p(\\theta_2|D,\\theta_1, \\theta_3, ...,\\theta_k)\\)\n\\(p(\\theta_3|D,\\theta_1, \\theta_2, ...,\\theta_k)\\)\n…\n\\(p(\\theta_k|D,\\theta_1, \\theta_2, ...,\\theta_{k-1})\\)\nดังนั้นจะเห็นว่าอัลกอริทึม Gibbs sampling จะใช้เวลาในแต่ละรอบของการทวนซ้ำมากกว่าอัลกอริทึม Metropolis เพราะต้องเสียเวลาในการสุ่มพารามิเตอร์ในโมเดลทีละค่าจนครบก่อน และจึงเริ่มรอบการทวนซ้ำรอบต่อไป\nอัลกอริทึม Gibbs sampling เป็นอัลกอริทึมที่ดำเนินการได้ง่ายกว่า Metropolis ในทางปฏิบัติทั้งสองอัลกอริทึมจะไม่ทราบรูปแบบ (functional form) ของการแจกแจงความน่าจะเป็นร่วมภายหลังของพารามิเตอร์ทั้งหมดภายในโมเดล แต่อัลกอริทึม Gibbs sampling มีการระบุเงื่อนไขเพิ่มเติมคือจำเป็นจะต้องทราบต้องทราบรูปแบบของการแจกแจงความน่าจะเป็นแบบมีเงื่อนไขของพารามิเตอร์แต่ละตัว เมื่อกำหนดข้อมูลและพารามิเตอร์ตัวที่เหลือ การจำลองตัวอย่างพารามิเตอร์แต่ละตัวจากการแจกแจงความน่าจะเป็นแบบที่เงื่อนไขดังกล่าวด้วยจำนวนรอบทวนซ้ำที่มากเพียงพอ จะทำให้ผู้วิเคราะห์ได้ตัวอย่างจำลองที่ใช้เป็นตัวแทนการแจกแจงความน่าจะเป็นภายหลังร่วมที่ต้องการได้\nจากที่กล่าวในข้างต้นทำให้พอจะเห็นได้ว่า Gibbs sampling เป็นกรณีเฉพาะของอัลกอริทึม Metropolis โดยเป็นกรณีที่การแจกแจงโครงร่างเป็นฟังก์ชันที่ขึ้นกับปริภูมิของพารามิเตอร์ภายในโมเดล และค่าตัวอย่างของพารามิเตอร์อื่น ๆ ที่เหลือ กล่าวคือ การแจกแจงโครงร่างของพารามิเตอร์ \\(\\theta_j\\) คือการแจกแจงความน่าจะเป็นภายหลังแบบมีเงื่อนไขของพารามิเตอร์ \\(\\theta_j\\) เมื่อกำหนดข้อมูลตัวอย่าง และพารามิเตอร์ส่วนที่เหลือในโมเดล \\(p(\\theta_j|D,\\theta_1,\\theta_2,...,\\theta_{j-1},\\theta_{j+1},...,\\theta_k)\\)\nเนื่องจากการแจกแจงโครงร่างดังกล่าวเป็นการแจกแจงเดียวกันกับการแจกแจงความน่าจะเป็นภายหลังแบบมีเงื่อนไขของพารามิเตอร์ ดังนั้นอัตราการยอมรับในอัลกอริทึม Gibbs sampling จึงมีค่าเท่ากับ 100% เสมอ ดังนั้น Gibbs sampling จึงมีประสิทธิภาพสูงกว่า Metropolis ในแง่ความเร็วของการประมวลผล อย่างไรก็ตามในกรณีที่เงื่อนไขของ Gibbs sampling ไม่เป็นจริง อัลกอริทึม Metropolis ก็ยังมีความจำเป็นอยู่เช่นเดียวกัน\n\n\n{\"x\":{\"visdat\":{\"e73c152ea392\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"e73c152ea392\",\"attrs\":{\"e73c152ea392\":{\"z\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"surface\",\"showlegend\":false,\"inherit\":true}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"xaxis\":{\"title\":\"mu\"},\"yaxis\":{\"title\":\"sigma\"},\"hoverlabel\":{\"bgcolor\":\"#FFFFFF99\"},\"scene\":{\"zaxis\":{\"title\":\"res\"}},\"hovermode\":\"closest\",\"showlegend\":false},\"source\":\"A\",\"config\":{\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false,\"scrollZoom\":false},\"data\":[{\"colorbar\":{\"title\":\"res\",\"ticklen\":2},\"colorscale\":[[\"0\",\"rgba(68,1,84,1)\"],[\"0.0416666666666667\",\"rgba(70,19,97,1)\"],[\"0.0833333333333333\",\"rgba(72,32,111,1)\"],[\"0.125\",\"rgba(71,45,122,1)\"],[\"0.166666666666667\",\"rgba(68,58,128,1)\"],[\"0.208333333333333\",\"rgba(64,70,135,1)\"],[\"0.25\",\"rgba(60,82,138,1)\"],[\"0.291666666666667\",\"rgba(56,93,140,1)\"],[\"0.333333333333333\",\"rgba(49,104,142,1)\"],[\"0.375\",\"rgba(46,114,142,1)\"],[\"0.416666666666667\",\"rgba(42,123,142,1)\"],[\"0.458333333333333\",\"rgba(38,133,141,1)\"],[\"0.5\",\"rgba(37,144,140,1)\"],[\"0.541666666666667\",\"rgba(33,154,138,1)\"],[\"0.583333333333333\",\"rgba(39,164,133,1)\"],[\"0.625\",\"rgba(47,174,127,1)\"],[\"0.666666666666667\",\"rgba(53,183,121,1)\"],[\"0.708333333333333\",\"rgba(79,191,110,1)\"],[\"0.75\",\"rgba(98,199,98,1)\"],[\"0.791666666666667\",\"rgba(119,207,85,1)\"],[\"0.833333333333333\",\"rgba(147,214,70,1)\"],[\"0.875\",\"rgba(172,220,52,1)\"],[\"0.916666666666667\",\"rgba(199,225,42,1)\"],[\"0.958333333333333\",\"rgba(226,228,40,1)\"],[\"1\",\"rgba(253,231,37,1)\"]],\"showscale\":true,\"z\":[[3.21408403718971e-06,3.91752109822229e-06,4.74186872166605e-06,5.69995956449911e-06,6.80421596012514e-06,8.06619041339657e-06,9.49604833691972e-06,1.11020052764101e-05,1.28897355790431e-05,1.48617740170699e-05,1.70169359562755e-05,1.93497848991313e-05,2.18501782820052e-05,2.45029229422816e-05,2.72875704349673e-05,3.0178379202322e-05,3.3144465436485e-05,3.61501574149851e-05,3.91555593722571e-05,4.21173209837202e-05,4.49895978018586e-05,4.77251771200216e-05,5.0276733438604e-05,5.25981686758998e-05,5.4645985171118e-05,5.63806349465947e-05,5.77677870641453e-05,5.8779456476219e-05,5.93949425725652e-05,5.96015334692439e-05,5.93949425725652e-05,5.8779456476219e-05,5.77677870641453e-05,5.63806349465947e-05,5.4645985171118e-05,5.25981686758998e-05,5.0276733438604e-05,4.77251771200216e-05,4.49895978018586e-05,4.21173209837202e-05,3.91555593722571e-05,3.61501574149851e-05,3.3144465436485e-05,3.0178379202322e-05,2.72875704349673e-05,2.45029229422816e-05,2.18501782820052e-05,1.93497848991313e-05,1.70169359562755e-05,1.48617740170699e-05,1.28897355790431e-05,1.11020052764101e-05,9.49604833691972e-06,8.06619041339657e-06,6.80421596012514e-06,5.69995956449911e-06,4.74186872166605e-06,3.91752109822229e-06,3.21408403718971e-06,2.61870861989146e-06],[3.91752109822229e-06,4.77491296974167e-06,5.77967798824878e-06,6.94745737652323e-06,8.29339223001709e-06,9.83156344424305e-06,1.15743612423243e-05,1.35317992310307e-05,1.57107936498014e-05,1.81144340332153e-05,2.07412764770443e-05,2.35846946474647e-05,2.66323261710725e-05,2.98656526972564e-05,3.32597504176278e-05,3.67832439560669e-05,4.03984902492659e-05,4.40620104323993e-05,4.77251771200215e-05,5.13351523000597e-05,5.48360579717204e-05,5.81703484167626e-05,6.12803404380319e-05,6.41098468899587e-05,6.66058501781364e-05,6.87201468221651e-05,7.04108921866515e-05,7.16439763936501e-05,7.23941682804207e-05,7.26459738297078e-05,7.23941682804207e-05,7.16439763936501e-05,7.04108921866515e-05,6.87201468221651e-05,6.66058501781364e-05,6.41098468899587e-05,6.12803404380319e-05,5.81703484167626e-05,5.48360579717204e-05,5.13351523000597e-05,4.77251771200215e-05,4.40620104323993e-05,4.03984902492659e-05,3.67832439560669e-05,3.32597504176278e-05,2.98656526972564e-05,2.66323261710725e-05,2.35846946474647e-05,2.07412764770443e-05,1.81144340332153e-05,1.57107936498014e-05,1.35317992310307e-05,1.15743612423243e-05,9.83156344424305e-06,8.29339223001709e-06,6.94745737652323e-06,5.77967798824878e-06,4.77491296974167e-06,3.91752109822229e-06,3.19184133016366e-06],[4.74186872166605e-06,5.77967798824878e-06,6.99587151839852e-06,8.40938185215977e-06,1.00385361625421e-05,1.19003783291651e-05,1.40099057981198e-05,1.6379239297679e-05,1.90167504226969e-05,2.19261788256264e-05,2.51057767674959e-05,2.85475235626955e-05,3.22364554751534e-05,3.61501574149851e-05,4.02584609607684e-05,4.45233885468631e-05,4.88993760371714e-05,5.3333795490707e-05,5.77677870641453e-05,6.21373942629379e-05,6.63749809116695e-05,7.04108921866516e-05,7.41753068561679e-05,7.76002145479816e-05,8.06214413964487e-05,8.31806406638612e-05,8.52271625227473e-05,8.67197194958292e-05,8.76277711320385e-05,8.79325630726992e-05,8.76277711320385e-05,8.67197194958292e-05,8.52271625227473e-05,8.31806406638612e-05,8.06214413964487e-05,7.76002145479816e-05,7.41753068561679e-05,7.04108921866516e-05,6.63749809116695e-05,6.21373942629379e-05,5.77677870641453e-05,5.3333795490707e-05,4.88993760371714e-05,4.45233885468631e-05,4.02584609607684e-05,3.61501574149851e-05,3.22364554751534e-05,2.85475235626955e-05,2.51057767674959e-05,2.19261788256264e-05,1.90167504226969e-05,1.6379239297679e-05,1.40099057981198e-05,1.19003783291651e-05,1.00385361625421e-05,8.40938185215977e-06,6.99587151839852e-06,5.77967798824878e-06,4.74186872166605e-06,3.86348718706127e-06],[5.69995956449911e-06,6.94745737652323e-06,8.40938185215977e-06,1.01084908362672e-05,1.20668144927362e-05,1.43048404036478e-05,1.68405962372715e-05,1.96886517054869e-05,2.28590698772992e-05,2.6356345998996e-05,3.0178379202322e-05,3.43155282284531e-05,3.87498059302222e-05,4.3454268266477e-05,4.83926513099927e-05,5.35193041578842e-05,5.8779456476219e-05,6.41098468899587e-05,6.94397229707644e-05,7.46922058647048e-05,7.97859935603593e-05,8.46373575317392e-05,8.91623692222171e-05,9.32792768173774e-05,9.69109401725347e-05,9.99872236375526e-05,0.000102447243627186,0.00010424137056187,0.000105332893316438,0.000105699268228803,0.000105332893316438,0.00010424137056187,0.000102447243627186,9.99872236375526e-05,9.69109401725347e-05,9.32792768173774e-05,8.91623692222171e-05,8.46373575317392e-05,7.97859935603593e-05,7.46922058647048e-05,6.94397229707644e-05,6.41098468899587e-05,5.8779456476219e-05,5.35193041578842e-05,4.83926513099927e-05,4.3454268266477e-05,3.87498059302222e-05,3.43155282284531e-05,3.0178379202322e-05,2.6356345998996e-05,2.28590698772992e-05,1.96886517054869e-05,1.68405962372715e-05,1.43048404036478e-05,1.20668144927362e-05,1.01084908362672e-05,8.40938185215977e-06,6.94745737652323e-06,5.69995956449911e-06,4.64410173221167e-06],[6.80421596012514e-06,8.29339223001709e-06,1.00385361625421e-05,1.20668144927362e-05,1.44045253006211e-05,1.70761252391615e-05,2.01031344870138e-05,2.35029453545942e-05,2.72875704349673e-05,3.14623758410308e-05,3.60248537021319e-05,4.09634949529126e-05,4.62568277859949e-05,5.18726882758693e-05,5.77677870641453e-05,6.38876292726592e-05,7.01668338796569e-05,7.65298838480742e-05,8.28923198415467e-05,8.9162369222217e-05,9.5242979293932e-05,0.000101034200755928,0.000106435845524756,0.000111350323960676,0.000115685551515073,0.000119357805118574,0.000122294406174473,0.00012443611033664,0.000125739094412829,0.00012617644734453,0.000125739094412829,0.00012443611033664,0.000122294406174473,0.000119357805118574,0.000115685551515073,0.000111350323960676,0.000106435845524756,0.000101034200755928,9.5242979293932e-05,8.9162369222217e-05,8.28923198415467e-05,7.65298838480742e-05,7.01668338796569e-05,6.38876292726592e-05,5.77677870641453e-05,5.18726882758693e-05,4.62568277859949e-05,4.09634949529126e-05,3.60248537021319e-05,3.14623758410308e-05,2.72875704349673e-05,2.35029453545942e-05,2.01031344870138e-05,1.70761252391615e-05,1.44045253006211e-05,1.20668144927362e-05,1.00385361625421e-05,8.29339223001709e-06,6.80421596012514e-06,5.54380619181398e-06],[8.06619041339657e-06,9.83156344424305e-06,1.19003783291651e-05,1.43048404036478e-05,1.70761252391615e-05,2.02432254515847e-05,2.38316525561e-05,2.78620246060391e-05,3.23485821639572e-05,3.72976865929657e-05,4.27063648889249e-05,4.85609734060124e-05,5.48360579717205e-05,6.14934892337295e-05,6.84819489784938e-05,7.5736835190675e-05,8.31806406638612e-05,9.07238422547564e-05,9.8266315997088e-05,0.000105699268228803,0.000112907645939844,0.000119772962283764,0.00012617644734453,0.000132002411581847,0.000137141691572972,0.000141495036173689,0.00014497628712514,0.000147515212062625,0.000149059859928855,0.00014957832848506,0.000149059859928855,0.000147515212062625,0.00014497628712514,0.000141495036173689,0.000137141691572972,0.000132002411581847,0.00012617644734453,0.000119772962283764,0.000112907645939844,0.000105699268228803,9.8266315997088e-05,9.07238422547564e-05,8.31806406638612e-05,7.5736835190675e-05,6.84819489784938e-05,6.14934892337295e-05,5.48360579717205e-05,4.85609734060124e-05,4.27063648889249e-05,3.72976865929657e-05,3.23485821639572e-05,2.78620246060391e-05,2.38316525561e-05,2.02432254515847e-05,1.70761252391615e-05,1.43048404036478e-05,1.19003783291651e-05,9.83156344424305e-06,8.06619041339657e-06,6.57201309014831e-06],[9.49604833691972e-06,1.15743612423243e-05,1.40099057981198e-05,1.68405962372715e-05,2.01031344870138e-05,2.38316525561e-05,2.80561842732531e-05,3.2801002562991e-05,3.80828723494522e-05,4.3909282646471e-05,5.02767334386039e-05,5.71691625312361e-05,6.45566036032019e-05,7.23941682804207e-05,8.06214413964486e-05,8.9162369222217e-05,9.79257051914008e-05,0.000106806056788768,0.000115685551515073,0.00012443611033664,0.000132922285304829,0.000141004585933616,0.000148543188488892,0.000155401895656881,0.000161452193097372,0.000166577235854486,0.00017067559277562,0.000173664581715198,0.000175483042481617,0.000176093417667247,0.000175483042481617,0.000173664581715198,0.00017067559277562,0.000166577235854486,0.000161452193097372,0.000155401895656881,0.000148543188488892,0.000141004585933616,0.000132922285304829,0.00012443611033664,0.000115685551515073,0.000106806056788768,9.79257051914008e-05,8.9162369222217e-05,8.06214413964486e-05,7.23941682804207e-05,6.45566036032019e-05,5.71691625312361e-05,5.02767334386039e-05,4.3909282646471e-05,3.80828723494522e-05,3.2801002562991e-05,2.80561842732531e-05,2.38316525561e-05,2.01031344870138e-05,1.68405962372715e-05,1.40099057981198e-05,1.15743612423243e-05,9.49604833691972e-06,7.73700480356479e-06],[1.11020052764101e-05,1.35317992310307e-05,1.6379239297679e-05,1.96886517054869e-05,2.35029453545942e-05,2.78620246060391e-05,3.2801002562991e-05,3.8348257149246e-05,4.45233885468631e-05,5.13351523000598e-05,5.8779456476219e-05,6.68375224673307e-05,7.54743160945561e-05,8.46373575317391e-05,9.42560142933618e-05,0.00010424137056187,0.000114486748293424,0.000124868931154376,0.000135250112231564,0.000145480551964149,0.000155401895656881,0.000164851062409484,0.000173664581715198,0.000181683222782168,0.000188756737124659,0.000194748519149408,0.000199539983824892,0.000203034465929549,0.000205160461955206,0.000205874062843809,0.000205160461955206,0.000203034465929549,0.000199539983824892,0.000194748519149408,0.000188756737124659,0.000181683222782168,0.000173664581715198,0.000164851062409484,0.000155401895656881,0.000145480551964149,0.000135250112231564,0.000124868931154376,0.000114486748293424,0.00010424137056187,9.42560142933618e-05,8.46373575317391e-05,7.54743160945561e-05,6.68375224673307e-05,5.8779456476219e-05,5.13351523000598e-05,4.45233885468631e-05,3.8348257149246e-05,3.2801002562991e-05,2.78620246060391e-05,2.35029453545942e-05,1.96886517054869e-05,1.6379239297679e-05,1.35317992310307e-05,1.11020052764101e-05,9.04547503394966e-06],[1.28897355790431e-05,1.57107936498014e-05,1.90167504226969e-05,2.28590698772992e-05,2.72875704349673e-05,3.23485821639572e-05,3.80828723494522e-05,4.45233885468631e-05,5.16928871103578e-05,5.96015334692439e-05,6.82445767764334e-05,7.76002145479816e-05,8.76277711320385e-05,9.8266315997088e-05,0.000109433842871385,0.00012102711802836,0.000132922285304829,0.00014497628712514,0.000157029125846758,0.000168906949692739,0.000180425904476507,0.000191396648756564,0.000201629388747495,0.000210939253090302,0.000219151799132142,0.000226108423996155,0.00023167144717671,0.000235728637674578,0.000238196977936588,0.000239025488330347,0.000238196977936588,0.000235728637674578,0.00023167144717671,0.000226108423996155,0.000219151799132142,0.000210939253090302,0.000201629388747495,0.000191396648756564,0.000180425904476507,0.000168906949692739,0.000157029125846758,0.00014497628712514,0.000132922285304829,0.00012102711802836,0.000109433842871385,9.8266315997088e-05,8.76277711320385e-05,7.76002145479816e-05,6.82445767764334e-05,5.96015334692439e-05,5.16928871103578e-05,4.45233885468631e-05,3.80828723494522e-05,3.23485821639572e-05,2.72875704349673e-05,2.28590698772992e-05,1.90167504226969e-05,1.57107936498014e-05,1.28897355790431e-05,1.0502047015073e-05],[1.48617740170699e-05,1.81144340332153e-05,2.19261788256264e-05,2.6356345998996e-05,3.14623758410308e-05,3.72976865929657e-05,4.3909282646471e-05,5.13351523000598e-05,5.96015334692439e-05,6.87201468221652e-05,7.86855146657106e-05,8.94724988899932e-05,0.000101034200755928,0.00011330036779134,0.00012617644734453,0.00013954341165843,0.000153258455452311,0.000167156634352589,0.000181053472208294,0.000194748519149408,0.000208029792598302,0.000220678983211207,0.000232477260095017,0.000243211467879491,0.000252680475418874,0.000260701414717162,0.000267115541124499,0.00027179345309203,0.000274639431967723,0.000275594698595757,0.000274639431967723,0.00027179345309203,0.000267115541124499,0.000260701414717162,0.000252680475418874,0.000243211467879491,0.000232477260095017,0.000220678983211207,0.000208029792598302,0.000194748519149408,0.000181053472208294,0.000167156634352589,0.000153258455452311,0.00013954341165843,0.00012617644734453,0.00011330036779134,0.000101034200755928,8.94724988899932e-05,7.86855146657106e-05,6.87201468221652e-05,5.96015334692439e-05,5.13351523000598e-05,4.3909282646471e-05,3.72976865929657e-05,3.14623758410308e-05,2.6356345998996e-05,2.19261788256264e-05,1.81144340332153e-05,1.48617740170699e-05,1.21087859791647e-05],[1.70169359562755e-05,2.07412764770443e-05,2.51057767674959e-05,3.0178379202322e-05,3.60248537021319e-05,4.27063648889249e-05,5.02767334386039e-05,5.8779456476219e-05,6.82445767764334e-05,7.86855146657106e-05,9.00959981099861e-05,0.000102447243627186,0.000115685551515073,0.000129730481725344,0.000144473770169435,0.000159779128426005,0.000175483042481618,0.000191396648756564,0.000207308719517003,0.000222989736900759,0.000238196977936588,0.000252680475418874,0.000266189664960822,0.000278480480727496,0.000289322624786617,0.000298506710763929,0.000305850973848789,0.000311207247485378,0.000314465932498685,0.000315559725945668,0.000314465932498685,0.000311207247485378,0.000305850973848789,0.000298506710763929,0.000289322624786617,0.000278480480727496,0.000266189664960822,0.000252680475418874,0.000238196977936588,0.000222989736900759,0.000207308719517003,0.000191396648756564,0.000175483042481618,0.000159779128426005,0.000144473770169435,0.000129730481725344,0.000115685551515073,0.000102447243627186,9.00959981099861e-05,7.86855146657106e-05,6.82445767764334e-05,5.8779456476219e-05,5.02767334386039e-05,4.27063648889249e-05,3.60248537021319e-05,3.0178379202322e-05,2.51057767674959e-05,2.07412764770443e-05,1.70169359562755e-05,1.38647267330955e-05],[1.93497848991313e-05,2.35846946474647e-05,2.85475235626955e-05,3.43155282284531e-05,4.09634949529126e-05,4.85609734060124e-05,5.71691625312361e-05,6.68375224673307e-05,7.76002145479816e-05,8.94724988899932e-05,0.000102447243627186,0.000116491719354677,0.000131544864686908,0.000147515212062625,0.000164279655487224,0.000181683222782168,0.000199539983824891,0.000217635183758703,0.000235728637674578,0.000253559363144478,0.000270851362345075,0.000287320400107775,0.000302681562215334,0.000316657323887768,0.000328985815687258,0.000339428946496043,0.000347780033395578,0.000353870597701349,0.000357576015305525,0.000358819756715705,0.000357576015305525,0.000353870597701349,0.000347780033395578,0.000339428946496043,0.000328985815687258,0.000316657323887768,0.000302681562215334,0.000287320400107775,0.000270851362345075,0.000253559363144478,0.000235728637674578,0.000217635183758703,0.000199539983824891,0.000181683222782168,0.000164279655487224,0.000147515212062625,0.000131544864686908,0.000116491719354677,0.000102447243627186,8.94724988899932e-05,7.76002145479816e-05,6.68375224673307e-05,5.71691625312361e-05,4.85609734060124e-05,4.09634949529126e-05,3.43155282284531e-05,2.85475235626955e-05,2.35846946474647e-05,1.93497848991313e-05,1.57654398335851e-05],[2.18501782820052e-05,2.66323261710725e-05,3.22364554751534e-05,3.87498059302222e-05,4.62568277859949e-05,5.48360579717205e-05,6.45566036032019e-05,7.54743160945561e-05,8.76277711320385e-05,0.000101034200755928,0.000115685551515073,0.000131544864686908,0.000148543188488893,0.000166577235854486,0.000185507992942257,0.000205160461955206,0.000225324686744092,0.000245758161672284,0.000266189664960822,0.000286324489841087,0.000305850973848789,0.000324448152738576,0.00034179429546929,0.000357576015305525,0.000371497603848827,0.000383290203672741,0.000392720424140542,0.000399598015628657,0.000403782250010723,0.000405186708597256,0.000403782250010723,0.000399598015628657,0.000392720424140542,0.000383290203672741,0.000371497603848827,0.000357576015305525,0.00034179429546929,0.000324448152738576,0.000305850973848789,0.000286324489841087,0.000266189664960822,0.000245758161672284,0.000225324686744092,0.000205160461955206,0.000185507992942257,0.000166577235854486,0.000148543188488893,0.000131544864686908,0.000115685551515073,0.000101034200755928,8.76277711320385e-05,7.54743160945561e-05,6.45566036032019e-05,5.48360579717205e-05,4.62568277859949e-05,3.87498059302222e-05,3.22364554751534e-05,2.66323261710725e-05,2.18501782820052e-05,1.78026615207246e-05],[2.45029229422816e-05,2.98656526972564e-05,3.61501574149851e-05,4.3454268266477e-05,5.18726882758693e-05,6.14934892337295e-05,7.23941682804207e-05,8.46373575317391e-05,9.8266315997088e-05,0.00011330036779134,0.000129730481725344,0.000147515212062625,0.000166577235854486,0.000186800726355729,0.000208029792598302,0.000230068190987318,0.000252680475418874,0.000275594698595757,0.000298506710763929,0.00032108602595898,0.000342983143996156,0.000363838133616793,0.000383290203672741,0.000400987920371117,0.000416599674513718,0.000429823967745801,0.000440399074386536,0.000448111647349867,0.000452803873258186,0.000454378841667015,0.000452803873258186,0.000448111647349867,0.000440399074386536,0.000429823967745801,0.000416599674513718,0.000400987920371117,0.000383290203672741,0.000363838133616793,0.000342983143996156,0.00032108602595898,0.000298506710763929,0.000275594698595757,0.000252680475418874,0.000230068190987318,0.000208029792598302,0.000186800726355729,0.000166577235854486,0.000147515212062625,0.000129730481725344,0.00011330036779134,9.8266315997088e-05,8.46373575317391e-05,7.23941682804207e-05,6.14934892337295e-05,5.18726882758693e-05,4.3454268266477e-05,3.61501574149851e-05,2.98656526972564e-05,2.45029229422816e-05,1.99640130062044e-05],[2.72875704349673e-05,3.32597504176278e-05,4.02584609607684e-05,4.83926513099927e-05,5.77677870641453e-05,6.84819489784938e-05,8.06214413964486e-05,9.42560142933618e-05,0.000109433842871385,0.00012617644734453,0.000144473770169435,0.000164279655487224,0.000185507992942257,0.000208029792598302,0.00023167144717671,0.000256214410876621,0.000281396480198517,0.000306914802252365,0.00033243066202626,0.000357576015305525,0.000381961642774123,0.000405186708597256,0.00042684941932805,0.000446558402296434,0.000463944362403443,0.000478671537356126,0.000490448457521777,0.000499037529873165,0.000504263006248846,0.000506016962766197,0.000504263006248846,0.000499037529873165,0.000490448457521777,0.000478671537356126,0.000463944362403443,0.000446558402296434,0.00042684941932805,0.000405186708597256,0.000381961642774123,0.000357576015305525,0.00033243066202626,0.000306914802252365,0.000281396480198517,0.000256214410876621,0.00023167144717671,0.000208029792598302,0.000185507992942257,0.000164279655487224,0.000144473770169435,0.00012617644734453,0.000109433842871385,9.42560142933618e-05,8.06214413964486e-05,6.84819489784938e-05,5.77677870641453e-05,4.83926513099927e-05,4.02584609607684e-05,3.32597504176278e-05,2.72875704349673e-05,2.22328337053766e-05],[3.0178379202322e-05,3.67832439560669e-05,4.45233885468631e-05,5.35193041578842e-05,6.38876292726592e-05,7.5736835190675e-05,8.9162369222217e-05,0.00010424137056187,0.00012102711802836,0.00013954341165843,0.000159779128426005,0.000181683222782168,0.000205160461955206,0.000230068190987318,0.000256214410876621,0.000283357423371997,0.000311207247485378,0.000339428946496043,0.000367647922376107,0.000395457140798338,0.000422426149072188,0.000448111647349867,0.000472069276723363,0.000493866203024644,0.000513094008525181,0.000529381360723144,0.000542405912082214,0.00055190489928718,0.000557683955651099,0.000559623723979362,0.000557683955651099,0.00055190489928718,0.000542405912082214,0.000529381360723144,0.000513094008525181,0.000493866203024644,0.000472069276723363,0.000448111647349867,0.000422426149072188,0.000395457140798338,0.000367647922376107,0.000339428946496043,0.000311207247485378,0.000283357423371997,0.000256214410876621,0.000230068190987318,0.000205160461955206,0.000181683222782168,0.000159779128426005,0.00013954341165843,0.00012102711802836,0.00010424137056187,8.9162369222217e-05,7.5736835190675e-05,6.38876292726592e-05,5.35193041578842e-05,4.45233885468631e-05,3.67832439560669e-05,3.0178379202322e-05,2.45881504145653e-05],[3.3144465436485e-05,4.03984902492659e-05,4.88993760371714e-05,5.8779456476219e-05,7.01668338796569e-05,8.31806406638612e-05,9.79257051914008e-05,0.000114486748293424,0.000132922285304829,0.000153258455452311,0.000175483042481618,0.000199539983824891,0.000225324686744092,0.000252680475418874,0.000281396480198517,0.000311207247485378,0.00034179429546929,0.000372789768126945,0.000403782250010723,0.000434324701367435,0.000463944362403443,0.00049215436348322,0.000518466671821133,0.000542405912082214,0.000563523525144183,0.000581411682038166,0.000595716353255009,0.000606148949750197,0.000612496001479691,0.000614626420210262,0.000612496001479691,0.000606148949750197,0.000595716353255009,0.000581411682038166,0.000563523525144183,0.000542405912082214,0.000518466671821133,0.00049215436348322,0.000463944362403443,0.000434324701367435,0.000403782250010723,0.000372789768126945,0.00034179429546929,0.000311207247485378,0.000281396480198517,0.000252680475418874,0.000225324686744092,0.000199539983824891,0.000175483042481618,0.000153258455452311,0.000132922285304829,0.000114486748293424,9.79257051914008e-05,8.31806406638612e-05,7.01668338796569e-05,5.8779456476219e-05,4.88993760371714e-05,4.03984902492659e-05,3.3144465436485e-05,2.70048002279708e-05],[3.61501574149851e-05,4.40620104323993e-05,5.3333795490707e-05,6.41098468899587e-05,7.65298838480742e-05,9.07238422547564e-05,0.000106806056788768,0.000124868931154376,0.00014497628712514,0.000167156634352589,0.000191396648756564,0.000217635183758703,0.000245758161672284,0.000275594698595757,0.000306914802252365,0.000339428946496043,0.000372789768126945,0.000406596052252216,0.000440399074386536,0.00047371125516376,0.000506016962766197,0.000536785175989159,0.000565483604998067,0.000591593765244629,0.000614626420210262,0.000634136757126711,0.000649738641466932,0.00066111731360967,0.00066803994506927,0.00067036355993093,0.00066803994506927,0.00066111731360967,0.000649738641466932,0.000634136757126711,0.000614626420210262,0.000591593765244629,0.000565483604998067,0.000536785175989159,0.000506016962766197,0.00047371125516376,0.000440399074386536,0.000406596052252216,0.000372789768126945,0.000339428946496043,0.000306914802252365,0.000275594698595757,0.000245758161672284,0.000217635183758703,0.000191396648756564,0.000167156634352589,0.00014497628712514,0.000124868931154376,0.000106806056788768,9.07238422547564e-05,7.65298838480742e-05,6.41098468899587e-05,5.3333795490707e-05,4.40620104323993e-05,3.61501574149851e-05,2.94537192362364e-05],[3.91555593722571e-05,4.77251771200215e-05,5.77677870641453e-05,6.94397229707644e-05,8.28923198415467e-05,9.8266315997088e-05,0.000115685551515073,0.000135250112231564,0.000157029125846758,0.000181053472208294,0.000207308719517003,0.000235728637674578,0.000266189664960822,0.000298506710763929,0.00033243066202626,0.000367647922376107,0.000403782250010723,0.000440399074386536,0.000477012365580488,0.000513094008525181,0.00054808550351562,0.000581411682038166,0.000612496001479691,0.000640776872238212,0.000665724384323837,0.000686856744737517,0.000703755717032154,0.000716080373534971,0.000723578529186605,0.000726095321537729,0.000723578529186605,0.000716080373534971,0.000703755717032154,0.000686856744737517,0.000665724384323837,0.000640776872238212,0.000612496001479691,0.000581411682038166,0.00054808550351562,0.000513094008525181,0.000477012365580488,0.000440399074386536,0.000403782250010723,0.000367647922376107,0.00033243066202626,0.000298506710763929,0.000266189664960822,0.000235728637674578,0.000207308719517003,0.000181053472208294,0.000157029125846758,0.000135250112231564,0.000115685551515073,9.8266315997088e-05,8.28923198415467e-05,6.94397229707644e-05,5.77677870641453e-05,4.77251771200215e-05,3.91555593722571e-05,3.19024019466699e-05],[4.21173209837202e-05,5.13351523000597e-05,6.21373942629379e-05,7.46922058647048e-05,8.9162369222217e-05,0.000105699268228803,0.00012443611033664,0.000145480551964149,0.000168906949692739,0.000194748519149408,0.000222989736900759,0.000253559363144478,0.000286324489841087,0.00032108602595898,0.000357576015305525,0.000395457140798338,0.000434324701367435,0.00047371125516376,0.000513094008525181,0.00055190489928718,0.000589543182326414,0.000625390182867271,0.000658825748096529,0.000689245809271282,0.000716080373534971,0.000738811204634201,0.000756988430342091,0.000770245334911076,0.000778310657777834,0.000781017822558546,0.000778310657777834,0.000770245334911076,0.000756988430342091,0.000738811204634201,0.000716080373534971,0.000689245809271282,0.000658825748096529,0.000625390182867271,0.000589543182326414,0.00055190489928718,0.000513094008525181,0.00047371125516376,0.000434324701367435,0.000395457140798338,0.000357576015305525,0.00032108602595898,0.000286324489841087,0.000253559363144478,0.000222989736900759,0.000194748519149408,0.000168906949692739,0.000145480551964149,0.00012443611033664,0.000105699268228803,8.9162369222217e-05,7.46922058647048e-05,6.21373942629379e-05,5.13351523000597e-05,4.21173209837202e-05,3.4315528228453e-05],[4.49895978018586e-05,5.48360579717204e-05,6.63749809116695e-05,7.97859935603593e-05,9.5242979293932e-05,0.000112907645939844,0.000132922285304829,0.000155401895656881,0.000180425904476507,0.000208029792598302,0.000238196977936588,0.000270851362345075,0.000305850973848789,0.000342983143996156,0.000381961642774123,0.000422426149072188,0.000463944362403443,0.000506016962766197,0.00054808550351562,0.000589543182326414,0.00062974828503326,0.00066803994506927,0.000703755717032154,0.000736250336475995,0.000764914938715965,0.000789195945317777,0.000808612804098222,0.000822773790379538,0.000831389144429665,0.000834280929847704,0.000831389144429665,0.000822773790379538,0.000808612804098222,0.000789195945317777,0.000764914938715965,0.000736250336475995,0.000703755717032154,0.00066803994506927,0.00062974828503326,0.000589543182326414,0.00054808550351562,0.000506016962766197,0.000463944362403443,0.000422426149072188,0.000381961642774123,0.000342983143996156,0.000305850973848789,0.000270851362345075,0.000238196977936588,0.000208029792598302,0.000180425904476507,0.000155401895656881,0.000132922285304829,0.000112907645939844,9.5242979293932e-05,7.97859935603593e-05,6.63749809116695e-05,5.48360579717204e-05,4.49895978018586e-05,3.66557458379932e-05],[4.77251771200216e-05,5.81703484167626e-05,7.04108921866516e-05,8.46373575317392e-05,0.000101034200755928,0.000119772962283764,0.000141004585933616,0.000164851062409484,0.000191396648756564,0.000220678983211207,0.000252680475418874,0.000287320400107775,0.000324448152738576,0.000363838133616793,0.000405186708597256,0.000448111647349867,0.00049215436348322,0.000536785175989159,0.000581411682038166,0.000625390182867271,0.00066803994506927,0.000708659918279228,0.000746547377296177,0.000781017822558547,0.000811425367542667,0.000837182773639683,0.000857780268831626,0.000872802309736425,0.000881941517866377,0.000885009137449838,0.000881941517866377,0.000872802309736425,0.000857780268831626,0.000837182773639683,0.000811425367542667,0.000781017822558547,0.000746547377296177,0.000708659918279228,0.00066803994506927,0.000625390182867271,0.000581411682038166,0.000536785175989159,0.00049215436348322,0.000448111647349867,0.000405186708597256,0.000363838133616793,0.000324448152738576,0.000287320400107775,0.000252680475418874,0.000220678983211207,0.000191396648756564,0.000164851062409484,0.000141004585933616,0.000119772962283764,0.000101034200755928,8.46373575317392e-05,7.04108921866516e-05,5.81703484167626e-05,4.77251771200216e-05,3.88845877282426e-05],[5.0276733438604e-05,6.12803404380319e-05,7.41753068561679e-05,8.91623692222171e-05,0.000106435845524756,0.00012617644734453,0.000148543188488892,0.000173664581715198,0.000201629388747495,0.000232477260095017,0.000266189664960822,0.000302681562215334,0.00034179429546929,0.000383290203672741,0.00042684941932805,0.000472069276723363,0.000518466671821133,0.000565483604998067,0.000612496001479691,0.000658825748096529,0.000703755717032154,0.000746547377296177,0.000786460433519536,0.000822773790379538,0.000854807029980605,0.000881941517866376,0.000903640227808592,0.000919465400010154,0.000929093222445134,0.000932324847792503,0.000929093222445134,0.000919465400010154,0.000903640227808592,0.000881941517866376,0.000854807029980605,0.000822773790379538,0.000786460433519536,0.000746547377296177,0.000703755717032154,0.000658825748096529,0.000612496001479691,0.000565483604998067,0.000518466671821133,0.000472069276723363,0.00042684941932805,0.000383290203672741,0.00034179429546929,0.000302681562215334,0.000266189664960822,0.000232477260095017,0.000201629388747495,0.000173664581715198,0.000148543188488892,0.00012617644734453,0.000106435845524756,8.91623692222171e-05,7.41753068561679e-05,6.12803404380319e-05,5.0276733438604e-05,4.09634949529126e-05],[5.25981686758998e-05,6.41098468899587e-05,7.76002145479816e-05,9.32792768173774e-05,0.000111350323960676,0.000132002411581847,0.000155401895656881,0.000181683222782168,0.000210939253090302,0.000243211467879491,0.000278480480727496,0.000316657323887768,0.000357576015305525,0.000400987920371117,0.000446558402296434,0.000493866203024644,0.000542405912082214,0.000591593765244629,0.000640776872238212,0.000689245809271282,0.000736250336475995,0.000781017822558547,0.000822773790379538,0.00086076384937259,0.00089427616460345,0.000922663537313192,0.00094536414508008,0.000961920015357519,0.000971992384697803,0.000975373224372397,0.000971992384697803,0.000961920015357519,0.00094536414508008,0.000922663537313192,0.00089427616460345,0.00086076384937259,0.000822773790379538,0.000781017822558547,0.000736250336475995,0.000689245809271282,0.000640776872238212,0.000591593765244629,0.000542405912082214,0.000493866203024644,0.000446558402296434,0.000400987920371117,0.000357576015305525,0.000316657323887768,0.000278480480727496,0.000243211467879491,0.000210939253090302,0.000181683222782168,0.000155401895656881,0.000132002411581847,0.000111350323960676,9.32792768173774e-05,7.76002145479816e-05,6.41098468899587e-05,5.25981686758998e-05,4.28549086172989e-05],[5.4645985171118e-05,6.66058501781364e-05,8.06214413964487e-05,9.69109401725347e-05,0.000115685551515073,0.000137141691572972,0.000161452193097372,0.000188756737124659,0.000219151799132142,0.000252680475418874,0.000289322624786617,0.000328985815687258,0.000371497603848827,0.000416599674513718,0.000463944362403443,0.000513094008525181,0.000563523525144183,0.000614626420210262,0.000665724384323837,0.000716080373534971,0.000764914938715965,0.000811425367542667,0.000854807029980605,0.00089427616460345,0.000929093222445134,0.000958585807209864,0.000982170222915445,0.000999370666665693,0.00100983518585834,0.00101334765253493,0.00100983518585834,0.000999370666665693,0.000982170222915445,0.000958585807209864,0.000929093222445134,0.00089427616460345,0.000854807029980605,0.000811425367542667,0.000764914938715965,0.000716080373534971,0.000665724384323837,0.000614626420210262,0.000563523525144183,0.000513094008525181,0.000463944362403443,0.000416599674513718,0.000371497603848827,0.000328985815687258,0.000289322624786617,0.000252680475418874,0.000219151799132142,0.000188756737124659,0.000161452193097372,0.000137141691572972,0.000115685551515073,9.69109401725347e-05,8.06214413964487e-05,6.66058501781364e-05,5.4645985171118e-05,4.45233885468631e-05],[5.63806349465947e-05,6.87201468221651e-05,8.31806406638612e-05,9.99872236375526e-05,0.000119357805118574,0.000141495036173689,0.000166577235854486,0.000194748519149408,0.000226108423996155,0.000260701414717162,0.000298506710763929,0.000339428946496043,0.000383290203672741,0.000429823967745801,0.000478671537356126,0.000529381360723144,0.000581411682038166,0.000634136757126711,0.000686856744737517,0.000738811204634201,0.000789195945317777,0.000837182773639683,0.000881941517866376,0.000922663537313192,0.000958585807209864,0.000989014587110983,0.00101334765253493,0.00103109409698031,0.00104189079566998,0.00104551476000761,0.00104189079566998,0.00103109409698031,0.00101334765253493,0.000989014587110983,0.000958585807209864,0.000922663537313192,0.000881941517866376,0.000837182773639683,0.000789195945317777,0.000738811204634201,0.000686856744737517,0.000634136757126711,0.000581411682038166,0.000529381360723144,0.000478671537356126,0.000429823967745801,0.000383290203672741,0.000339428946496043,0.000298506710763929,0.000260701414717162,0.000226108423996155,0.000194748519149408,0.000166577235854486,0.000141495036173689,0.000119357805118574,9.99872236375526e-05,8.31806406638612e-05,6.87201468221651e-05,5.63806349465947e-05,4.59367126127471e-05],[5.77677870641453e-05,7.04108921866515e-05,8.52271625227473e-05,0.000102447243627186,0.000122294406174473,0.00014497628712514,0.00017067559277562,0.000199539983824892,0.00023167144717671,0.000267115541124499,0.000305850973848789,0.000347780033395578,0.000392720424140542,0.000440399074386536,0.000490448457521777,0.000542405912082214,0.000595716353255009,0.000649738641466932,0.000703755717032154,0.000756988430342091,0.000808612804098222,0.000857780268831626,0.000903640227808592,0.00094536414508008,0.000982170222915445,0.00101334765253493,0.00103827939272126,0.00105646245903184,0.00106752479260597,0.00107123791858233,0.00106752479260597,0.00105646245903184,0.00103827939272126,0.00101334765253493,0.000982170222915445,0.00094536414508008,0.000903640227808592,0.000857780268831626,0.000808612804098222,0.000756988430342091,0.000703755717032154,0.000649738641466932,0.000595716353255009,0.000542405912082214,0.000490448457521777,0.000440399074386536,0.000392720424140542,0.000347780033395578,0.000305850973848789,0.000267115541124499,0.00023167144717671,0.000199539983824892,0.00017067559277562,0.00014497628712514,0.000122294406174473,0.000102447243627186,8.52271625227473e-05,7.04108921866515e-05,5.77677870641453e-05,4.70669093236292e-05],[5.8779456476219e-05,7.16439763936501e-05,8.67197194958292e-05,0.00010424137056187,0.00012443611033664,0.000147515212062625,0.000173664581715198,0.000203034465929549,0.000235728637674578,0.00027179345309203,0.000311207247485378,0.000353870597701349,0.000399598015628657,0.000448111647349867,0.000499037529873165,0.00055190489928718,0.000606148949750197,0.00066111731360967,0.000716080373534971,0.000770245334911076,0.000822773790379538,0.000872802309736425,0.000919465400010154,0.000961920015357519,0.000999370666665693,0.00103109409698031,0.00105646245903184,0.00107496395976649,0.00108622002457167,0.00108999817737639,0.00108622002457167,0.00107496395976649,0.00105646245903184,0.00103109409698031,0.000999370666665693,0.000961920015357519,0.000919465400010154,0.000872802309736425,0.000822773790379538,0.000770245334911076,0.000716080373534971,0.00066111731360967,0.000606148949750197,0.00055190489928718,0.000499037529873165,0.000448111647349867,0.000399598015628657,0.000353870597701349,0.000311207247485378,0.00027179345309203,0.000235728637674578,0.000203034465929549,0.000173664581715198,0.000147515212062625,0.00012443611033664,0.00010424137056187,8.67197194958292e-05,7.16439763936501e-05,5.8779456476219e-05,4.78911775690215e-05],[5.93949425725652e-05,7.23941682804207e-05,8.76277711320385e-05,0.000105332893316438,0.000125739094412829,0.000149059859928855,0.000175483042481617,0.000205160461955206,0.000238196977936588,0.000274639431967723,0.000314465932498685,0.000357576015305525,0.000403782250010723,0.000452803873258186,0.000504263006248846,0.000557683955651099,0.000612496001479691,0.00066803994506927,0.000723578529186605,0.000778310657777834,0.000831389144429665,0.000881941517866377,0.000929093222445134,0.000971992384697803,0.00100983518585834,0.00104189079566998,0.00106752479260597,0.00108622002457167,0.00109759395285846,0.00110141166711305,0.00109759395285846,0.00108622002457167,0.00106752479260597,0.00104189079566998,0.00100983518585834,0.000971992384697803,0.000929093222445134,0.000881941517866377,0.000831389144429665,0.000778310657777834,0.000723578529186605,0.00066803994506927,0.000612496001479691,0.000557683955651099,0.000504263006248846,0.000452803873258186,0.000403782250010723,0.000357576015305525,0.000314465932498685,0.000274639431967723,0.000238196977936588,0.000205160461955206,0.000175483042481617,0.000149059859928855,0.000125739094412829,0.000105332893316438,8.76277711320385e-05,7.23941682804207e-05,5.93949425725652e-05,4.83926513099926e-05],[5.96015334692439e-05,7.26459738297078e-05,8.79325630726992e-05,0.000105699268228803,0.00012617644734453,0.00014957832848506,0.000176093417667247,0.000205874062843809,0.000239025488330347,0.000275594698595757,0.000315559725945668,0.000358819756715705,0.000405186708597256,0.000454378841667015,0.000506016962766197,0.000559623723979362,0.000614626420210262,0.00067036355993093,0.000726095321537729,0.000781017822558546,0.000834280929847704,0.000885009137449838,0.000932324847792503,0.000975373224372397,0.00101334765253493,0.00104551476000761,0.00107123791858233,0.00108999817737639,0.00110141166711305,0.00110524266036038,0.00110141166711305,0.00108999817737639,0.00107123791858233,0.00104551476000761,0.00101334765253493,0.000975373224372397,0.000932324847792503,0.000885009137449838,0.000834280929847704,0.000781017822558546,0.000726095321537729,0.00067036355993093,0.000614626420210262,0.000559623723979362,0.000506016962766197,0.000454378841667015,0.000405186708597256,0.000358819756715705,0.000315559725945668,0.000275594698595757,0.000239025488330347,0.000205874062843809,0.000176093417667247,0.00014957832848506,0.00012617644734453,0.000105699268228803,8.79325630726992e-05,7.26459738297078e-05,5.96015334692439e-05,4.85609734060124e-05],[5.93949425725652e-05,7.23941682804207e-05,8.76277711320385e-05,0.000105332893316438,0.000125739094412829,0.000149059859928855,0.000175483042481617,0.000205160461955206,0.000238196977936588,0.000274639431967723,0.000314465932498685,0.000357576015305525,0.000403782250010723,0.000452803873258186,0.000504263006248846,0.000557683955651099,0.000612496001479691,0.00066803994506927,0.000723578529186605,0.000778310657777834,0.000831389144429665,0.000881941517866377,0.000929093222445134,0.000971992384697803,0.00100983518585834,0.00104189079566998,0.00106752479260597,0.00108622002457167,0.00109759395285846,0.00110141166711305,0.00109759395285846,0.00108622002457167,0.00106752479260597,0.00104189079566998,0.00100983518585834,0.000971992384697803,0.000929093222445134,0.000881941517866377,0.000831389144429665,0.000778310657777834,0.000723578529186605,0.00066803994506927,0.000612496001479691,0.000557683955651099,0.000504263006248846,0.000452803873258186,0.000403782250010723,0.000357576015305525,0.000314465932498685,0.000274639431967723,0.000238196977936588,0.000205160461955206,0.000175483042481617,0.000149059859928855,0.000125739094412829,0.000105332893316438,8.76277711320385e-05,7.23941682804207e-05,5.93949425725652e-05,4.83926513099926e-05],[5.8779456476219e-05,7.16439763936501e-05,8.67197194958292e-05,0.00010424137056187,0.00012443611033664,0.000147515212062625,0.000173664581715198,0.000203034465929549,0.000235728637674578,0.00027179345309203,0.000311207247485378,0.000353870597701349,0.000399598015628657,0.000448111647349867,0.000499037529873165,0.00055190489928718,0.000606148949750197,0.00066111731360967,0.000716080373534971,0.000770245334911076,0.000822773790379538,0.000872802309736425,0.000919465400010154,0.000961920015357519,0.000999370666665693,0.00103109409698031,0.00105646245903184,0.00107496395976649,0.00108622002457167,0.00108999817737639,0.00108622002457167,0.00107496395976649,0.00105646245903184,0.00103109409698031,0.000999370666665693,0.000961920015357519,0.000919465400010154,0.000872802309736425,0.000822773790379538,0.000770245334911076,0.000716080373534971,0.00066111731360967,0.000606148949750197,0.00055190489928718,0.000499037529873165,0.000448111647349867,0.000399598015628657,0.000353870597701349,0.000311207247485378,0.00027179345309203,0.000235728637674578,0.000203034465929549,0.000173664581715198,0.000147515212062625,0.00012443611033664,0.00010424137056187,8.67197194958292e-05,7.16439763936501e-05,5.8779456476219e-05,4.78911775690215e-05],[5.77677870641453e-05,7.04108921866515e-05,8.52271625227473e-05,0.000102447243627186,0.000122294406174473,0.00014497628712514,0.00017067559277562,0.000199539983824892,0.00023167144717671,0.000267115541124499,0.000305850973848789,0.000347780033395578,0.000392720424140542,0.000440399074386536,0.000490448457521777,0.000542405912082214,0.000595716353255009,0.000649738641466932,0.000703755717032154,0.000756988430342091,0.000808612804098222,0.000857780268831626,0.000903640227808592,0.00094536414508008,0.000982170222915445,0.00101334765253493,0.00103827939272126,0.00105646245903184,0.00106752479260597,0.00107123791858233,0.00106752479260597,0.00105646245903184,0.00103827939272126,0.00101334765253493,0.000982170222915445,0.00094536414508008,0.000903640227808592,0.000857780268831626,0.000808612804098222,0.000756988430342091,0.000703755717032154,0.000649738641466932,0.000595716353255009,0.000542405912082214,0.000490448457521777,0.000440399074386536,0.000392720424140542,0.000347780033395578,0.000305850973848789,0.000267115541124499,0.00023167144717671,0.000199539983824892,0.00017067559277562,0.00014497628712514,0.000122294406174473,0.000102447243627186,8.52271625227473e-05,7.04108921866515e-05,5.77677870641453e-05,4.70669093236292e-05],[5.63806349465947e-05,6.87201468221651e-05,8.31806406638612e-05,9.99872236375526e-05,0.000119357805118574,0.000141495036173689,0.000166577235854486,0.000194748519149408,0.000226108423996155,0.000260701414717162,0.000298506710763929,0.000339428946496043,0.000383290203672741,0.000429823967745801,0.000478671537356126,0.000529381360723144,0.000581411682038166,0.000634136757126711,0.000686856744737517,0.000738811204634201,0.000789195945317777,0.000837182773639683,0.000881941517866376,0.000922663537313192,0.000958585807209864,0.000989014587110983,0.00101334765253493,0.00103109409698031,0.00104189079566998,0.00104551476000761,0.00104189079566998,0.00103109409698031,0.00101334765253493,0.000989014587110983,0.000958585807209864,0.000922663537313192,0.000881941517866376,0.000837182773639683,0.000789195945317777,0.000738811204634201,0.000686856744737517,0.000634136757126711,0.000581411682038166,0.000529381360723144,0.000478671537356126,0.000429823967745801,0.000383290203672741,0.000339428946496043,0.000298506710763929,0.000260701414717162,0.000226108423996155,0.000194748519149408,0.000166577235854486,0.000141495036173689,0.000119357805118574,9.99872236375526e-05,8.31806406638612e-05,6.87201468221651e-05,5.63806349465947e-05,4.59367126127471e-05],[5.4645985171118e-05,6.66058501781364e-05,8.06214413964487e-05,9.69109401725347e-05,0.000115685551515073,0.000137141691572972,0.000161452193097372,0.000188756737124659,0.000219151799132142,0.000252680475418874,0.000289322624786617,0.000328985815687258,0.000371497603848827,0.000416599674513718,0.000463944362403443,0.000513094008525181,0.000563523525144183,0.000614626420210262,0.000665724384323837,0.000716080373534971,0.000764914938715965,0.000811425367542667,0.000854807029980605,0.00089427616460345,0.000929093222445134,0.000958585807209864,0.000982170222915445,0.000999370666665693,0.00100983518585834,0.00101334765253493,0.00100983518585834,0.000999370666665693,0.000982170222915445,0.000958585807209864,0.000929093222445134,0.00089427616460345,0.000854807029980605,0.000811425367542667,0.000764914938715965,0.000716080373534971,0.000665724384323837,0.000614626420210262,0.000563523525144183,0.000513094008525181,0.000463944362403443,0.000416599674513718,0.000371497603848827,0.000328985815687258,0.000289322624786617,0.000252680475418874,0.000219151799132142,0.000188756737124659,0.000161452193097372,0.000137141691572972,0.000115685551515073,9.69109401725347e-05,8.06214413964487e-05,6.66058501781364e-05,5.4645985171118e-05,4.45233885468631e-05],[5.25981686758998e-05,6.41098468899587e-05,7.76002145479816e-05,9.32792768173774e-05,0.000111350323960676,0.000132002411581847,0.000155401895656881,0.000181683222782168,0.000210939253090302,0.000243211467879491,0.000278480480727496,0.000316657323887768,0.000357576015305525,0.000400987920371117,0.000446558402296434,0.000493866203024644,0.000542405912082214,0.000591593765244629,0.000640776872238212,0.000689245809271282,0.000736250336475995,0.000781017822558547,0.000822773790379538,0.00086076384937259,0.00089427616460345,0.000922663537313192,0.00094536414508008,0.000961920015357519,0.000971992384697803,0.000975373224372397,0.000971992384697803,0.000961920015357519,0.00094536414508008,0.000922663537313192,0.00089427616460345,0.00086076384937259,0.000822773790379538,0.000781017822558547,0.000736250336475995,0.000689245809271282,0.000640776872238212,0.000591593765244629,0.000542405912082214,0.000493866203024644,0.000446558402296434,0.000400987920371117,0.000357576015305525,0.000316657323887768,0.000278480480727496,0.000243211467879491,0.000210939253090302,0.000181683222782168,0.000155401895656881,0.000132002411581847,0.000111350323960676,9.32792768173774e-05,7.76002145479816e-05,6.41098468899587e-05,5.25981686758998e-05,4.28549086172989e-05],[5.0276733438604e-05,6.12803404380319e-05,7.41753068561679e-05,8.91623692222171e-05,0.000106435845524756,0.00012617644734453,0.000148543188488892,0.000173664581715198,0.000201629388747495,0.000232477260095017,0.000266189664960822,0.000302681562215334,0.00034179429546929,0.000383290203672741,0.00042684941932805,0.000472069276723363,0.000518466671821133,0.000565483604998067,0.000612496001479691,0.000658825748096529,0.000703755717032154,0.000746547377296177,0.000786460433519536,0.000822773790379538,0.000854807029980605,0.000881941517866376,0.000903640227808592,0.000919465400010154,0.000929093222445134,0.000932324847792503,0.000929093222445134,0.000919465400010154,0.000903640227808592,0.000881941517866376,0.000854807029980605,0.000822773790379538,0.000786460433519536,0.000746547377296177,0.000703755717032154,0.000658825748096529,0.000612496001479691,0.000565483604998067,0.000518466671821133,0.000472069276723363,0.00042684941932805,0.000383290203672741,0.00034179429546929,0.000302681562215334,0.000266189664960822,0.000232477260095017,0.000201629388747495,0.000173664581715198,0.000148543188488892,0.00012617644734453,0.000106435845524756,8.91623692222171e-05,7.41753068561679e-05,6.12803404380319e-05,5.0276733438604e-05,4.09634949529126e-05],[4.77251771200216e-05,5.81703484167626e-05,7.04108921866516e-05,8.46373575317392e-05,0.000101034200755928,0.000119772962283764,0.000141004585933616,0.000164851062409484,0.000191396648756564,0.000220678983211207,0.000252680475418874,0.000287320400107775,0.000324448152738576,0.000363838133616793,0.000405186708597256,0.000448111647349867,0.00049215436348322,0.000536785175989159,0.000581411682038166,0.000625390182867271,0.00066803994506927,0.000708659918279228,0.000746547377296177,0.000781017822558547,0.000811425367542667,0.000837182773639683,0.000857780268831626,0.000872802309736425,0.000881941517866377,0.000885009137449838,0.000881941517866377,0.000872802309736425,0.000857780268831626,0.000837182773639683,0.000811425367542667,0.000781017822558547,0.000746547377296177,0.000708659918279228,0.00066803994506927,0.000625390182867271,0.000581411682038166,0.000536785175989159,0.00049215436348322,0.000448111647349867,0.000405186708597256,0.000363838133616793,0.000324448152738576,0.000287320400107775,0.000252680475418874,0.000220678983211207,0.000191396648756564,0.000164851062409484,0.000141004585933616,0.000119772962283764,0.000101034200755928,8.46373575317392e-05,7.04108921866516e-05,5.81703484167626e-05,4.77251771200216e-05,3.88845877282426e-05],[4.49895978018586e-05,5.48360579717204e-05,6.63749809116695e-05,7.97859935603593e-05,9.5242979293932e-05,0.000112907645939844,0.000132922285304829,0.000155401895656881,0.000180425904476507,0.000208029792598302,0.000238196977936588,0.000270851362345075,0.000305850973848789,0.000342983143996156,0.000381961642774123,0.000422426149072188,0.000463944362403443,0.000506016962766197,0.00054808550351562,0.000589543182326414,0.00062974828503326,0.00066803994506927,0.000703755717032154,0.000736250336475995,0.000764914938715965,0.000789195945317777,0.000808612804098222,0.000822773790379538,0.000831389144429665,0.000834280929847704,0.000831389144429665,0.000822773790379538,0.000808612804098222,0.000789195945317777,0.000764914938715965,0.000736250336475995,0.000703755717032154,0.00066803994506927,0.00062974828503326,0.000589543182326414,0.00054808550351562,0.000506016962766197,0.000463944362403443,0.000422426149072188,0.000381961642774123,0.000342983143996156,0.000305850973848789,0.000270851362345075,0.000238196977936588,0.000208029792598302,0.000180425904476507,0.000155401895656881,0.000132922285304829,0.000112907645939844,9.5242979293932e-05,7.97859935603593e-05,6.63749809116695e-05,5.48360579717204e-05,4.49895978018586e-05,3.66557458379932e-05],[4.21173209837202e-05,5.13351523000597e-05,6.21373942629379e-05,7.46922058647048e-05,8.9162369222217e-05,0.000105699268228803,0.00012443611033664,0.000145480551964149,0.000168906949692739,0.000194748519149408,0.000222989736900759,0.000253559363144478,0.000286324489841087,0.00032108602595898,0.000357576015305525,0.000395457140798338,0.000434324701367435,0.00047371125516376,0.000513094008525181,0.00055190489928718,0.000589543182326414,0.000625390182867271,0.000658825748096529,0.000689245809271282,0.000716080373534971,0.000738811204634201,0.000756988430342091,0.000770245334911076,0.000778310657777834,0.000781017822558546,0.000778310657777834,0.000770245334911076,0.000756988430342091,0.000738811204634201,0.000716080373534971,0.000689245809271282,0.000658825748096529,0.000625390182867271,0.000589543182326414,0.00055190489928718,0.000513094008525181,0.00047371125516376,0.000434324701367435,0.000395457140798338,0.000357576015305525,0.00032108602595898,0.000286324489841087,0.000253559363144478,0.000222989736900759,0.000194748519149408,0.000168906949692739,0.000145480551964149,0.00012443611033664,0.000105699268228803,8.9162369222217e-05,7.46922058647048e-05,6.21373942629379e-05,5.13351523000597e-05,4.21173209837202e-05,3.4315528228453e-05],[3.91555593722571e-05,4.77251771200215e-05,5.77677870641453e-05,6.94397229707644e-05,8.28923198415467e-05,9.8266315997088e-05,0.000115685551515073,0.000135250112231564,0.000157029125846758,0.000181053472208294,0.000207308719517003,0.000235728637674578,0.000266189664960822,0.000298506710763929,0.00033243066202626,0.000367647922376107,0.000403782250010723,0.000440399074386536,0.000477012365580488,0.000513094008525181,0.00054808550351562,0.000581411682038166,0.000612496001479691,0.000640776872238212,0.000665724384323837,0.000686856744737517,0.000703755717032154,0.000716080373534971,0.000723578529186605,0.000726095321537729,0.000723578529186605,0.000716080373534971,0.000703755717032154,0.000686856744737517,0.000665724384323837,0.000640776872238212,0.000612496001479691,0.000581411682038166,0.00054808550351562,0.000513094008525181,0.000477012365580488,0.000440399074386536,0.000403782250010723,0.000367647922376107,0.00033243066202626,0.000298506710763929,0.000266189664960822,0.000235728637674578,0.000207308719517003,0.000181053472208294,0.000157029125846758,0.000135250112231564,0.000115685551515073,9.8266315997088e-05,8.28923198415467e-05,6.94397229707644e-05,5.77677870641453e-05,4.77251771200215e-05,3.91555593722571e-05,3.19024019466699e-05],[3.61501574149851e-05,4.40620104323993e-05,5.3333795490707e-05,6.41098468899587e-05,7.65298838480742e-05,9.07238422547564e-05,0.000106806056788768,0.000124868931154376,0.00014497628712514,0.000167156634352589,0.000191396648756564,0.000217635183758703,0.000245758161672284,0.000275594698595757,0.000306914802252365,0.000339428946496043,0.000372789768126945,0.000406596052252216,0.000440399074386536,0.00047371125516376,0.000506016962766197,0.000536785175989159,0.000565483604998067,0.000591593765244629,0.000614626420210262,0.000634136757126711,0.000649738641466932,0.00066111731360967,0.00066803994506927,0.00067036355993093,0.00066803994506927,0.00066111731360967,0.000649738641466932,0.000634136757126711,0.000614626420210262,0.000591593765244629,0.000565483604998067,0.000536785175989159,0.000506016962766197,0.00047371125516376,0.000440399074386536,0.000406596052252216,0.000372789768126945,0.000339428946496043,0.000306914802252365,0.000275594698595757,0.000245758161672284,0.000217635183758703,0.000191396648756564,0.000167156634352589,0.00014497628712514,0.000124868931154376,0.000106806056788768,9.07238422547564e-05,7.65298838480742e-05,6.41098468899587e-05,5.3333795490707e-05,4.40620104323993e-05,3.61501574149851e-05,2.94537192362364e-05],[3.3144465436485e-05,4.03984902492659e-05,4.88993760371714e-05,5.8779456476219e-05,7.01668338796569e-05,8.31806406638612e-05,9.79257051914008e-05,0.000114486748293424,0.000132922285304829,0.000153258455452311,0.000175483042481618,0.000199539983824891,0.000225324686744092,0.000252680475418874,0.000281396480198517,0.000311207247485378,0.00034179429546929,0.000372789768126945,0.000403782250010723,0.000434324701367435,0.000463944362403443,0.00049215436348322,0.000518466671821133,0.000542405912082214,0.000563523525144183,0.000581411682038166,0.000595716353255009,0.000606148949750197,0.000612496001479691,0.000614626420210262,0.000612496001479691,0.000606148949750197,0.000595716353255009,0.000581411682038166,0.000563523525144183,0.000542405912082214,0.000518466671821133,0.00049215436348322,0.000463944362403443,0.000434324701367435,0.000403782250010723,0.000372789768126945,0.00034179429546929,0.000311207247485378,0.000281396480198517,0.000252680475418874,0.000225324686744092,0.000199539983824891,0.000175483042481618,0.000153258455452311,0.000132922285304829,0.000114486748293424,9.79257051914008e-05,8.31806406638612e-05,7.01668338796569e-05,5.8779456476219e-05,4.88993760371714e-05,4.03984902492659e-05,3.3144465436485e-05,2.70048002279708e-05],[3.0178379202322e-05,3.67832439560669e-05,4.45233885468631e-05,5.35193041578842e-05,6.38876292726592e-05,7.5736835190675e-05,8.9162369222217e-05,0.00010424137056187,0.00012102711802836,0.00013954341165843,0.000159779128426005,0.000181683222782168,0.000205160461955206,0.000230068190987318,0.000256214410876621,0.000283357423371997,0.000311207247485378,0.000339428946496043,0.000367647922376107,0.000395457140798338,0.000422426149072188,0.000448111647349867,0.000472069276723363,0.000493866203024644,0.000513094008525181,0.000529381360723144,0.000542405912082214,0.00055190489928718,0.000557683955651099,0.000559623723979362,0.000557683955651099,0.00055190489928718,0.000542405912082214,0.000529381360723144,0.000513094008525181,0.000493866203024644,0.000472069276723363,0.000448111647349867,0.000422426149072188,0.000395457140798338,0.000367647922376107,0.000339428946496043,0.000311207247485378,0.000283357423371997,0.000256214410876621,0.000230068190987318,0.000205160461955206,0.000181683222782168,0.000159779128426005,0.00013954341165843,0.00012102711802836,0.00010424137056187,8.9162369222217e-05,7.5736835190675e-05,6.38876292726592e-05,5.35193041578842e-05,4.45233885468631e-05,3.67832439560669e-05,3.0178379202322e-05,2.45881504145653e-05],[2.72875704349673e-05,3.32597504176278e-05,4.02584609607684e-05,4.83926513099927e-05,5.77677870641453e-05,6.84819489784938e-05,8.06214413964486e-05,9.42560142933618e-05,0.000109433842871385,0.00012617644734453,0.000144473770169435,0.000164279655487224,0.000185507992942257,0.000208029792598302,0.00023167144717671,0.000256214410876621,0.000281396480198517,0.000306914802252365,0.00033243066202626,0.000357576015305525,0.000381961642774123,0.000405186708597256,0.00042684941932805,0.000446558402296434,0.000463944362403443,0.000478671537356126,0.000490448457521777,0.000499037529873165,0.000504263006248846,0.000506016962766197,0.000504263006248846,0.000499037529873165,0.000490448457521777,0.000478671537356126,0.000463944362403443,0.000446558402296434,0.00042684941932805,0.000405186708597256,0.000381961642774123,0.000357576015305525,0.00033243066202626,0.000306914802252365,0.000281396480198517,0.000256214410876621,0.00023167144717671,0.000208029792598302,0.000185507992942257,0.000164279655487224,0.000144473770169435,0.00012617644734453,0.000109433842871385,9.42560142933618e-05,8.06214413964486e-05,6.84819489784938e-05,5.77677870641453e-05,4.83926513099927e-05,4.02584609607684e-05,3.32597504176278e-05,2.72875704349673e-05,2.22328337053766e-05],[2.45029229422816e-05,2.98656526972564e-05,3.61501574149851e-05,4.3454268266477e-05,5.18726882758693e-05,6.14934892337295e-05,7.23941682804207e-05,8.46373575317391e-05,9.8266315997088e-05,0.00011330036779134,0.000129730481725344,0.000147515212062625,0.000166577235854486,0.000186800726355729,0.000208029792598302,0.000230068190987318,0.000252680475418874,0.000275594698595757,0.000298506710763929,0.00032108602595898,0.000342983143996156,0.000363838133616793,0.000383290203672741,0.000400987920371117,0.000416599674513718,0.000429823967745801,0.000440399074386536,0.000448111647349867,0.000452803873258186,0.000454378841667015,0.000452803873258186,0.000448111647349867,0.000440399074386536,0.000429823967745801,0.000416599674513718,0.000400987920371117,0.000383290203672741,0.000363838133616793,0.000342983143996156,0.00032108602595898,0.000298506710763929,0.000275594698595757,0.000252680475418874,0.000230068190987318,0.000208029792598302,0.000186800726355729,0.000166577235854486,0.000147515212062625,0.000129730481725344,0.00011330036779134,9.8266315997088e-05,8.46373575317391e-05,7.23941682804207e-05,6.14934892337295e-05,5.18726882758693e-05,4.3454268266477e-05,3.61501574149851e-05,2.98656526972564e-05,2.45029229422816e-05,1.99640130062044e-05],[2.18501782820052e-05,2.66323261710725e-05,3.22364554751534e-05,3.87498059302222e-05,4.62568277859949e-05,5.48360579717205e-05,6.45566036032019e-05,7.54743160945561e-05,8.76277711320385e-05,0.000101034200755928,0.000115685551515073,0.000131544864686908,0.000148543188488893,0.000166577235854486,0.000185507992942257,0.000205160461955206,0.000225324686744092,0.000245758161672284,0.000266189664960822,0.000286324489841087,0.000305850973848789,0.000324448152738576,0.00034179429546929,0.000357576015305525,0.000371497603848827,0.000383290203672741,0.000392720424140542,0.000399598015628657,0.000403782250010723,0.000405186708597256,0.000403782250010723,0.000399598015628657,0.000392720424140542,0.000383290203672741,0.000371497603848827,0.000357576015305525,0.00034179429546929,0.000324448152738576,0.000305850973848789,0.000286324489841087,0.000266189664960822,0.000245758161672284,0.000225324686744092,0.000205160461955206,0.000185507992942257,0.000166577235854486,0.000148543188488893,0.000131544864686908,0.000115685551515073,0.000101034200755928,8.76277711320385e-05,7.54743160945561e-05,6.45566036032019e-05,5.48360579717205e-05,4.62568277859949e-05,3.87498059302222e-05,3.22364554751534e-05,2.66323261710725e-05,2.18501782820052e-05,1.78026615207246e-05],[1.93497848991313e-05,2.35846946474647e-05,2.85475235626955e-05,3.43155282284531e-05,4.09634949529126e-05,4.85609734060124e-05,5.71691625312361e-05,6.68375224673307e-05,7.76002145479816e-05,8.94724988899932e-05,0.000102447243627186,0.000116491719354677,0.000131544864686908,0.000147515212062625,0.000164279655487224,0.000181683222782168,0.000199539983824891,0.000217635183758703,0.000235728637674578,0.000253559363144478,0.000270851362345075,0.000287320400107775,0.000302681562215334,0.000316657323887768,0.000328985815687258,0.000339428946496043,0.000347780033395578,0.000353870597701349,0.000357576015305525,0.000358819756715705,0.000357576015305525,0.000353870597701349,0.000347780033395578,0.000339428946496043,0.000328985815687258,0.000316657323887768,0.000302681562215334,0.000287320400107775,0.000270851362345075,0.000253559363144478,0.000235728637674578,0.000217635183758703,0.000199539983824891,0.000181683222782168,0.000164279655487224,0.000147515212062625,0.000131544864686908,0.000116491719354677,0.000102447243627186,8.94724988899932e-05,7.76002145479816e-05,6.68375224673307e-05,5.71691625312361e-05,4.85609734060124e-05,4.09634949529126e-05,3.43155282284531e-05,2.85475235626955e-05,2.35846946474647e-05,1.93497848991313e-05,1.57654398335851e-05],[1.70169359562755e-05,2.07412764770443e-05,2.51057767674959e-05,3.0178379202322e-05,3.60248537021319e-05,4.27063648889249e-05,5.02767334386039e-05,5.8779456476219e-05,6.82445767764334e-05,7.86855146657106e-05,9.00959981099861e-05,0.000102447243627186,0.000115685551515073,0.000129730481725344,0.000144473770169435,0.000159779128426005,0.000175483042481618,0.000191396648756564,0.000207308719517003,0.000222989736900759,0.000238196977936588,0.000252680475418874,0.000266189664960822,0.000278480480727496,0.000289322624786617,0.000298506710763929,0.000305850973848789,0.000311207247485378,0.000314465932498685,0.000315559725945668,0.000314465932498685,0.000311207247485378,0.000305850973848789,0.000298506710763929,0.000289322624786617,0.000278480480727496,0.000266189664960822,0.000252680475418874,0.000238196977936588,0.000222989736900759,0.000207308719517003,0.000191396648756564,0.000175483042481618,0.000159779128426005,0.000144473770169435,0.000129730481725344,0.000115685551515073,0.000102447243627186,9.00959981099861e-05,7.86855146657106e-05,6.82445767764334e-05,5.8779456476219e-05,5.02767334386039e-05,4.27063648889249e-05,3.60248537021319e-05,3.0178379202322e-05,2.51057767674959e-05,2.07412764770443e-05,1.70169359562755e-05,1.38647267330955e-05],[1.48617740170699e-05,1.81144340332153e-05,2.19261788256264e-05,2.6356345998996e-05,3.14623758410308e-05,3.72976865929657e-05,4.3909282646471e-05,5.13351523000598e-05,5.96015334692439e-05,6.87201468221652e-05,7.86855146657106e-05,8.94724988899932e-05,0.000101034200755928,0.00011330036779134,0.00012617644734453,0.00013954341165843,0.000153258455452311,0.000167156634352589,0.000181053472208294,0.000194748519149408,0.000208029792598302,0.000220678983211207,0.000232477260095017,0.000243211467879491,0.000252680475418874,0.000260701414717162,0.000267115541124499,0.00027179345309203,0.000274639431967723,0.000275594698595757,0.000274639431967723,0.00027179345309203,0.000267115541124499,0.000260701414717162,0.000252680475418874,0.000243211467879491,0.000232477260095017,0.000220678983211207,0.000208029792598302,0.000194748519149408,0.000181053472208294,0.000167156634352589,0.000153258455452311,0.00013954341165843,0.00012617644734453,0.00011330036779134,0.000101034200755928,8.94724988899932e-05,7.86855146657106e-05,6.87201468221652e-05,5.96015334692439e-05,5.13351523000598e-05,4.3909282646471e-05,3.72976865929657e-05,3.14623758410308e-05,2.6356345998996e-05,2.19261788256264e-05,1.81144340332153e-05,1.48617740170699e-05,1.21087859791647e-05],[1.28897355790431e-05,1.57107936498014e-05,1.90167504226969e-05,2.28590698772992e-05,2.72875704349673e-05,3.23485821639572e-05,3.80828723494522e-05,4.45233885468631e-05,5.16928871103578e-05,5.96015334692439e-05,6.82445767764334e-05,7.76002145479816e-05,8.76277711320385e-05,9.8266315997088e-05,0.000109433842871385,0.00012102711802836,0.000132922285304829,0.00014497628712514,0.000157029125846758,0.000168906949692739,0.000180425904476507,0.000191396648756564,0.000201629388747495,0.000210939253090302,0.000219151799132142,0.000226108423996155,0.00023167144717671,0.000235728637674578,0.000238196977936588,0.000239025488330347,0.000238196977936588,0.000235728637674578,0.00023167144717671,0.000226108423996155,0.000219151799132142,0.000210939253090302,0.000201629388747495,0.000191396648756564,0.000180425904476507,0.000168906949692739,0.000157029125846758,0.00014497628712514,0.000132922285304829,0.00012102711802836,0.000109433842871385,9.8266315997088e-05,8.76277711320385e-05,7.76002145479816e-05,6.82445767764334e-05,5.96015334692439e-05,5.16928871103578e-05,4.45233885468631e-05,3.80828723494522e-05,3.23485821639572e-05,2.72875704349673e-05,2.28590698772992e-05,1.90167504226969e-05,1.57107936498014e-05,1.28897355790431e-05,1.0502047015073e-05],[1.11020052764101e-05,1.35317992310307e-05,1.6379239297679e-05,1.96886517054869e-05,2.35029453545942e-05,2.78620246060391e-05,3.2801002562991e-05,3.8348257149246e-05,4.45233885468631e-05,5.13351523000598e-05,5.8779456476219e-05,6.68375224673307e-05,7.54743160945561e-05,8.46373575317391e-05,9.42560142933618e-05,0.00010424137056187,0.000114486748293424,0.000124868931154376,0.000135250112231564,0.000145480551964149,0.000155401895656881,0.000164851062409484,0.000173664581715198,0.000181683222782168,0.000188756737124659,0.000194748519149408,0.000199539983824892,0.000203034465929549,0.000205160461955206,0.000205874062843809,0.000205160461955206,0.000203034465929549,0.000199539983824892,0.000194748519149408,0.000188756737124659,0.000181683222782168,0.000173664581715198,0.000164851062409484,0.000155401895656881,0.000145480551964149,0.000135250112231564,0.000124868931154376,0.000114486748293424,0.00010424137056187,9.42560142933618e-05,8.46373575317391e-05,7.54743160945561e-05,6.68375224673307e-05,5.8779456476219e-05,5.13351523000598e-05,4.45233885468631e-05,3.8348257149246e-05,3.2801002562991e-05,2.78620246060391e-05,2.35029453545942e-05,1.96886517054869e-05,1.6379239297679e-05,1.35317992310307e-05,1.11020052764101e-05,9.04547503394966e-06],[9.49604833691972e-06,1.15743612423243e-05,1.40099057981198e-05,1.68405962372715e-05,2.01031344870138e-05,2.38316525561e-05,2.80561842732531e-05,3.2801002562991e-05,3.80828723494522e-05,4.3909282646471e-05,5.02767334386039e-05,5.71691625312361e-05,6.45566036032019e-05,7.23941682804207e-05,8.06214413964486e-05,8.9162369222217e-05,9.79257051914008e-05,0.000106806056788768,0.000115685551515073,0.00012443611033664,0.000132922285304829,0.000141004585933616,0.000148543188488892,0.000155401895656881,0.000161452193097372,0.000166577235854486,0.00017067559277562,0.000173664581715198,0.000175483042481617,0.000176093417667247,0.000175483042481617,0.000173664581715198,0.00017067559277562,0.000166577235854486,0.000161452193097372,0.000155401895656881,0.000148543188488892,0.000141004585933616,0.000132922285304829,0.00012443611033664,0.000115685551515073,0.000106806056788768,9.79257051914008e-05,8.9162369222217e-05,8.06214413964486e-05,7.23941682804207e-05,6.45566036032019e-05,5.71691625312361e-05,5.02767334386039e-05,4.3909282646471e-05,3.80828723494522e-05,3.2801002562991e-05,2.80561842732531e-05,2.38316525561e-05,2.01031344870138e-05,1.68405962372715e-05,1.40099057981198e-05,1.15743612423243e-05,9.49604833691972e-06,7.73700480356479e-06],[8.06619041339657e-06,9.83156344424305e-06,1.19003783291651e-05,1.43048404036478e-05,1.70761252391615e-05,2.02432254515847e-05,2.38316525561e-05,2.78620246060391e-05,3.23485821639572e-05,3.72976865929657e-05,4.27063648889249e-05,4.85609734060124e-05,5.48360579717205e-05,6.14934892337295e-05,6.84819489784938e-05,7.5736835190675e-05,8.31806406638612e-05,9.07238422547564e-05,9.8266315997088e-05,0.000105699268228803,0.000112907645939844,0.000119772962283764,0.00012617644734453,0.000132002411581847,0.000137141691572972,0.000141495036173689,0.00014497628712514,0.000147515212062625,0.000149059859928855,0.00014957832848506,0.000149059859928855,0.000147515212062625,0.00014497628712514,0.000141495036173689,0.000137141691572972,0.000132002411581847,0.00012617644734453,0.000119772962283764,0.000112907645939844,0.000105699268228803,9.8266315997088e-05,9.07238422547564e-05,8.31806406638612e-05,7.5736835190675e-05,6.84819489784938e-05,6.14934892337295e-05,5.48360579717205e-05,4.85609734060124e-05,4.27063648889249e-05,3.72976865929657e-05,3.23485821639572e-05,2.78620246060391e-05,2.38316525561e-05,2.02432254515847e-05,1.70761252391615e-05,1.43048404036478e-05,1.19003783291651e-05,9.83156344424305e-06,8.06619041339657e-06,6.57201309014831e-06],[6.80421596012514e-06,8.29339223001709e-06,1.00385361625421e-05,1.20668144927362e-05,1.44045253006211e-05,1.70761252391615e-05,2.01031344870138e-05,2.35029453545942e-05,2.72875704349673e-05,3.14623758410308e-05,3.60248537021319e-05,4.09634949529126e-05,4.62568277859949e-05,5.18726882758693e-05,5.77677870641453e-05,6.38876292726592e-05,7.01668338796569e-05,7.65298838480742e-05,8.28923198415467e-05,8.9162369222217e-05,9.5242979293932e-05,0.000101034200755928,0.000106435845524756,0.000111350323960676,0.000115685551515073,0.000119357805118574,0.000122294406174473,0.00012443611033664,0.000125739094412829,0.00012617644734453,0.000125739094412829,0.00012443611033664,0.000122294406174473,0.000119357805118574,0.000115685551515073,0.000111350323960676,0.000106435845524756,0.000101034200755928,9.5242979293932e-05,8.9162369222217e-05,8.28923198415467e-05,7.65298838480742e-05,7.01668338796569e-05,6.38876292726592e-05,5.77677870641453e-05,5.18726882758693e-05,4.62568277859949e-05,4.09634949529126e-05,3.60248537021319e-05,3.14623758410308e-05,2.72875704349673e-05,2.35029453545942e-05,2.01031344870138e-05,1.70761252391615e-05,1.44045253006211e-05,1.20668144927362e-05,1.00385361625421e-05,8.29339223001709e-06,6.80421596012514e-06,5.54380619181398e-06],[5.69995956449911e-06,6.94745737652323e-06,8.40938185215977e-06,1.01084908362672e-05,1.20668144927362e-05,1.43048404036478e-05,1.68405962372715e-05,1.96886517054869e-05,2.28590698772992e-05,2.6356345998996e-05,3.0178379202322e-05,3.43155282284531e-05,3.87498059302222e-05,4.3454268266477e-05,4.83926513099927e-05,5.35193041578842e-05,5.8779456476219e-05,6.41098468899587e-05,6.94397229707644e-05,7.46922058647048e-05,7.97859935603593e-05,8.46373575317392e-05,8.91623692222171e-05,9.32792768173774e-05,9.69109401725347e-05,9.99872236375526e-05,0.000102447243627186,0.00010424137056187,0.000105332893316438,0.000105699268228803,0.000105332893316438,0.00010424137056187,0.000102447243627186,9.99872236375526e-05,9.69109401725347e-05,9.32792768173774e-05,8.91623692222171e-05,8.46373575317392e-05,7.97859935603593e-05,7.46922058647048e-05,6.94397229707644e-05,6.41098468899587e-05,5.8779456476219e-05,5.35193041578842e-05,4.83926513099927e-05,4.3454268266477e-05,3.87498059302222e-05,3.43155282284531e-05,3.0178379202322e-05,2.6356345998996e-05,2.28590698772992e-05,1.96886517054869e-05,1.68405962372715e-05,1.43048404036478e-05,1.20668144927362e-05,1.01084908362672e-05,8.40938185215977e-06,6.94745737652323e-06,5.69995956449911e-06,4.64410173221167e-06],[4.74186872166605e-06,5.77967798824878e-06,6.99587151839852e-06,8.40938185215977e-06,1.00385361625421e-05,1.19003783291651e-05,1.40099057981198e-05,1.6379239297679e-05,1.90167504226969e-05,2.19261788256264e-05,2.51057767674959e-05,2.85475235626955e-05,3.22364554751534e-05,3.61501574149851e-05,4.02584609607684e-05,4.45233885468631e-05,4.88993760371714e-05,5.3333795490707e-05,5.77677870641453e-05,6.21373942629379e-05,6.63749809116695e-05,7.04108921866516e-05,7.41753068561679e-05,7.76002145479816e-05,8.06214413964487e-05,8.31806406638612e-05,8.52271625227473e-05,8.67197194958292e-05,8.76277711320385e-05,8.79325630726992e-05,8.76277711320385e-05,8.67197194958292e-05,8.52271625227473e-05,8.31806406638612e-05,8.06214413964487e-05,7.76002145479816e-05,7.41753068561679e-05,7.04108921866516e-05,6.63749809116695e-05,6.21373942629379e-05,5.77677870641453e-05,5.3333795490707e-05,4.88993760371714e-05,4.45233885468631e-05,4.02584609607684e-05,3.61501574149851e-05,3.22364554751534e-05,2.85475235626955e-05,2.51057767674959e-05,2.19261788256264e-05,1.90167504226969e-05,1.6379239297679e-05,1.40099057981198e-05,1.19003783291651e-05,1.00385361625421e-05,8.40938185215977e-06,6.99587151839852e-06,5.77967798824878e-06,4.74186872166605e-06,3.86348718706127e-06],[3.91752109822229e-06,4.77491296974167e-06,5.77967798824878e-06,6.94745737652323e-06,8.29339223001709e-06,9.83156344424305e-06,1.15743612423243e-05,1.35317992310307e-05,1.57107936498014e-05,1.81144340332153e-05,2.07412764770443e-05,2.35846946474647e-05,2.66323261710725e-05,2.98656526972564e-05,3.32597504176278e-05,3.67832439560669e-05,4.03984902492659e-05,4.40620104323993e-05,4.77251771200215e-05,5.13351523000597e-05,5.48360579717204e-05,5.81703484167626e-05,6.12803404380319e-05,6.41098468899587e-05,6.66058501781364e-05,6.87201468221651e-05,7.04108921866515e-05,7.16439763936501e-05,7.23941682804207e-05,7.26459738297078e-05,7.23941682804207e-05,7.16439763936501e-05,7.04108921866515e-05,6.87201468221651e-05,6.66058501781364e-05,6.41098468899587e-05,6.12803404380319e-05,5.81703484167626e-05,5.48360579717204e-05,5.13351523000597e-05,4.77251771200215e-05,4.40620104323993e-05,4.03984902492659e-05,3.67832439560669e-05,3.32597504176278e-05,2.98656526972564e-05,2.66323261710725e-05,2.35846946474647e-05,2.07412764770443e-05,1.81144340332153e-05,1.57107936498014e-05,1.35317992310307e-05,1.15743612423243e-05,9.83156344424305e-06,8.29339223001709e-06,6.94745737652323e-06,5.77967798824878e-06,4.77491296974167e-06,3.91752109822229e-06,3.19184133016366e-06],[3.21408403718971e-06,3.91752109822229e-06,4.74186872166605e-06,5.69995956449911e-06,6.80421596012514e-06,8.06619041339657e-06,9.49604833691972e-06,1.11020052764101e-05,1.28897355790431e-05,1.48617740170699e-05,1.70169359562755e-05,1.93497848991313e-05,2.18501782820052e-05,2.45029229422816e-05,2.72875704349673e-05,3.0178379202322e-05,3.3144465436485e-05,3.61501574149851e-05,3.91555593722571e-05,4.21173209837202e-05,4.49895978018586e-05,4.77251771200216e-05,5.0276733438604e-05,5.25981686758998e-05,5.4645985171118e-05,5.63806349465947e-05,5.77677870641453e-05,5.8779456476219e-05,5.93949425725652e-05,5.96015334692439e-05,5.93949425725652e-05,5.8779456476219e-05,5.77677870641453e-05,5.63806349465947e-05,5.4645985171118e-05,5.25981686758998e-05,5.0276733438604e-05,4.77251771200216e-05,4.49895978018586e-05,4.21173209837202e-05,3.91555593722571e-05,3.61501574149851e-05,3.3144465436485e-05,3.0178379202322e-05,2.72875704349673e-05,2.45029229422816e-05,2.18501782820052e-05,1.93497848991313e-05,1.70169359562755e-05,1.48617740170699e-05,1.28897355790431e-05,1.11020052764101e-05,9.49604833691972e-06,8.06619041339657e-06,6.80421596012514e-06,5.69995956449911e-06,4.74186872166605e-06,3.91752109822229e-06,3.21408403718971e-06,2.61870861989146e-06],[2.61870861989146e-06,3.19184133016366e-06,3.86348718706127e-06,4.64410173221167e-06,5.54380619181398e-06,6.57201309014831e-06,7.73700480356479e-06,9.04547503394966e-06,1.0502047015073e-05,1.21087859791647e-05,1.38647267330955e-05,1.57654398335851e-05,1.78026615207246e-05,1.99640130062044e-05,2.22328337053766e-05,2.45881504145653e-05,2.70048002279708e-05,2.94537192362364e-05,3.19024019466699e-05,3.4315528228453e-05,3.66557458379932e-05,3.88845877282426e-05,4.09634949529126e-05,4.28549086172989e-05,4.45233885468631e-05,4.59367126127471e-05,4.70669093236292e-05,4.78911775690215e-05,4.83926513099926e-05,4.85609734060124e-05,4.83926513099926e-05,4.78911775690215e-05,4.70669093236292e-05,4.59367126127471e-05,4.45233885468631e-05,4.28549086172989e-05,4.09634949529126e-05,3.88845877282426e-05,3.66557458379932e-05,3.4315528228453e-05,3.19024019466699e-05,2.94537192362364e-05,2.70048002279708e-05,2.45881504145653e-05,2.22328337053766e-05,1.99640130062044e-05,1.78026615207246e-05,1.57654398335851e-05,1.38647267330955e-05,1.21087859791647e-05,1.0502047015073e-05,9.04547503394966e-06,7.73700480356479e-06,6.57201309014831e-06,5.54380619181398e-06,4.64410173221167e-06,3.86348718706127e-06,3.19184133016366e-06,2.61870861989146e-06,2.13362026522802e-06]],\"type\":\"surface\",\"showlegend\":false,\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\nAssessing MCMC samples\nหัวข้อนี้จะกล่าวถึงการประเมินประสิทธิภาพของลูกโซ่มาร์คอฟที่จำลองขึ้นจากอัลกอริทึมในข้างต้นว่า มีคุณสมบัติที่ดีเพียงพอจะใช้เป็นตัวอย่างสำหรับอนุมานไปยังพารามิเตอร์ภายในโมเดลการวิเคราะห์ได้หรือไม่ การตรวจสอบในส่วนนี้เป็นการดำเนินงานที่จะไม่พบในการวิเคราะห์ข้อมูลด้วยสถิติแบบดั้งเดิม คำถามสำคัญที่ผู้วิเคราะห์ต้องการคำตอบในส่วนนี้คือ กระบวนการสุ่มที่สร้างจากอัลกอริทึม MCMC มีคุณสมบัติลู่เข้าสู่การแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์แล้วหรือไม่ หรือตัวอย่างพารามิเตอร์ที่จำลองขึ้นจากอัลกอริทึมดังกล่าว มีความเป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ดังกล่าวแล้วหรือไม่นั่นเอง\nการตรวจสอบดังกล่าวประกอบด้วยการตรวจสอบการลู่เข้า (convergence) อัตราการยอมรับ (acceptance rates) อัตสหสัมพันธ์ระหว่างลูกโซ่ (autocorrelation)\nConvergence\nการลู่เข้าของกระบวนการ MCMC คือการที่ตัวอย่างสุ่มของพารามิเตอร์ที่จำลองจากอัลกอริทึมอยู่ในสถานะที่ถูกสุ่่มจากการแจกแจงความน่าจะเป็นเป้าหมาย (target distribution) หรือการแจกแจงความน่าจะเป็นภายหลัง (posterior distribution) ที่ต้องการ การลู่เข้าดังกล่าวแตกต่างจากการลู่เข้าทั่ว ๆ ไป กล่าวคือแทนที่จะเป็นการลู่เข้าไปสู่คำตอบที่เป็นค่าคงที่ การลู่เข้าของกระบวนการ MCMC เป็นการลู่เข้าสู่การแจกแจงความน่าจะเป็น\nโดยธรรมชาติของกระบวนการ MCMC เมื่อกำหนดค่าเริ่มต้นแล้ว กระบวนการจะต้องการเวลาต้องดำเนินการทวนซ้ำไปจำนวนหนึ่ง ตัวอย่างที่สุ่มจากกระบวนการจึงจะถูกสุ่มจากการแจกแจงที่เป็นสถานะคงที่ของกระบวนการ การแจกแจงสถานะคงที่นี้อาจะเป็นการแจกแจงความน่าจะเป็นภายหลังหรือไม่ก็ได้ (ประเด็นนี้จะกล่าวถึงอีกครั้งภายหลัง)\nการตรวจสอบแนวโน้มการลู่เข้าด้วย Trace plot และ Density plot\nแผนภาพร่องรอย (trace plot) และแผนภาพโค้งความหนาแน่น (density plot) เป็นเครื่องมือพื้นฐานอย่างแรก ๆ ที่ผู้วิเคราะห์มักใช้พิจารณาแนวโน้มการลู่เข้าของกระบวนการสุ่มที่สร้างจากอัลกอริทึม MCMC รูปด้านล่างแสดงตัวอย่าง Trace plot ในลักษณะที่มีแนวโน้มลู่เข้าและไม่ลู่เข้าสู่การแจกแจงความน่าจะเป็นภายหลัง\n\n\n\nDensity plot (และ Histogram) เป็นทัศนภาพอีกประเภทหนึ่งที่ให้สารสนเทศคล้ายคลึงกับ trace plot จุดเด่นคือเป็นแผนภาพที่แสดงรูปทรงการแจกแจงของการแจกแจงความน่าจะเป็นภายหลังที่สร้างขึ้นจากกระบวนการสุ่มด้วย รูปด้านล่างแสดงตัวอย่าง density plot ของตัวอย่างสุ่มพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\)\n\n\n\nในโปรแกรม R มี package-coda ที่ช่วยอำนวยความสะดวกแก่ผู้วิเคราะห์ในการตรวจสอบ/วินิจฉัยการลู่เข้าของลูกโซ่มาร์คอฟที่สร้างขึ้นจากอัลกอริทึม MCMC\n\n\n\nหากตัวอย่างสุ่มของพารามิเตอร์ (ลูกโซ่มาร์คอฟ) ไม่ได้บันทึกไว้ในรูปแบบ mcmc object ผู้วิเคราะห์จำเป็นต้องเปลี่ยนตัวแปรที่บันทึกข้อมูลดังกล่าวให้อยู่ในรูปแบบดังกล่าวด้วยฟังก์ชัน mcmc(x, start=1, end=numeric(0), thin=1)\n\n\n\nอย่างที่กล่าวไว้ในข้างต้น แผนภาพร่องรอย และแผนภาพความหนาแน่น เป็นเครื่องมือที่ใช้สำหรับตรวจสอบพฤติกรรมของตัวอย่างหรือลูกโซ่มาร์คอฟที่จำลองขึ้นว่ามีแนวโน้มที่จะลู่เข้าไปสู่การแจกแจงสถานะคงที่หรือไม่ อย่างไรก็ตามเครื่องมือดังกล่าวไม่สามารถที่จะใช้ยืนยันได้ 100% ว่าการแจกแจงสถานะคงที่ดังกล่าวนั้นเป็นการแจกแจงความน่าจะเป็นภายหลังที่แท้จริงหรือไม่ การจะยืนยันหรือพิสูจน์ข้อสงสัยดังกล่าว ผู้วิเคราะห์จำเป็นต้องมีหลักฐานอื่น ๆ มาเพิ่มเติมเพื่อสร้างข้อสรุปในประเด็นดังกล่าว\nAutocorrelation\nกระบวนการสุ่มที่สร้างขึ้นจากอัลกอริทึม MCMC จะให้ตัวอย่างสุ่มที่มีความสัมพันธ์ระหว่างกัน ทั้งนี้เป็นเพราะตัวอย่างสุ่มที่สร้างขึ้นใหม่นั้น จะขึ้นกับตัวอย่างที่ถูกสร้างไว้ในรอบก่อนหน้าเสมอ ลักษณะดังกล่าวจึงทำให้เกิดอัตสหสัมพันธ์ขึ้นระหว่างตัวอย่างขึ้น ซึ่งมีมากน้อยต่างกันไปตามปัจจัยต่าง ๆ ที่เกี่ยวข้อง\nในการอนุมานเชิงสถิติต่าง ๆ เกี่ยวกับพารามิเตอร์ในโมเดล ผู้วิเคราะห์จะใช้ตัวอย่างสุ่มของพารามิเตอร์ที่จำลองขึ้นจากกระบวนการ MCMC ดังกล่าว เพื่อวิเคราะห์และสร้างข้อสรุปซึ่งการวิเคราะห์ต่าง ๆ นี้ต้องการความเป็นอิสระของตัวอย่างสุ่มเป็นเงื่อนไขจำเป็นในการวิเคราะห์ การเกิดอัตสหสัมพันธ์ดังกล่าวจึงอาจเป็นปัญหาในการขั้นตอนของการอนุมานเชิงสถิติได้\nนอกจากนี้หากกระบวนการสุ่มดังกล่าวมีอัตสหสัมพันธ์ที่สูงในช่วงที่กว้าง ตัวอย่างที่สุ่มได้ในแต่ละรอบของการทวนซ้ำจะมีความสัมพันธ์กันสูงและย่อมมีค่าอยู่ในบริเวณที่ใกล้เคียงกัน ส่งผลให้พฤติกรรมของกระบวนการสุ่มดังกล่าวมีแนวโน้มการเดินที่ช้าและใช้เวลานานกว่ากระบวนการดังกล่าวจะลู่เข้าไปสู่การแจกแจงสถานะคงตัว\nจากเหตุผลในข้างต้น ปัญหาอัตสหสัมพันธ์ของกระบวนการ MCMC จึงเป็นปัญหาที่ต้องตรวจสอบและแก้ไขก่อนที่จะนำตัวอย่างสุ่มดังกล่าวไปใช้ในขั้นการอนุมานเชิงสถิติ\nค่าอัตสหสัมพันธ์สามารถคำนวณได้โดยใช้สูตรเดียวกับสหสัมพันธ์ของเพียร์สัน โดยเป็นการหาสหสัมพันธ์ระหว่างข้อมูลสองชุด ชุดแรกคือตัวอย่างของพารามิเตอร์ \\(\\theta_m, \\theta_{m-1}, \\theta_{m-2}, ...,\\theta_{2}\\) และชุดที่สองคือตัวอย่างของพารามิเตอร์ที่มีการเหลื่อมค่า 1 ช่วงเวลา \\(\\theta_{m-1}, \\theta_{m-2},...,\\theta_{1}\\) สหสัมพันธ์ระหว่างชุดข้อมูลทั้งสองนี้เรียกว่า อัตสหสัมพันธ์อันดับที่ 1 (lag-1 autocorrelation)\nในทำนองเดียวกัน อัตสหสัมพันธ์ในอันดับที่สูงกว่า 1 สามารถหาได้โดยการเหลื่อมข้อมูลเพิ่มขึ้นเป็น 2, 3, 4 ,… ช่วงเวลา ข้อสังเกตคือยิ่งมีการเหลื่อมช่วงเวลามากขึ้น จำนวนตัวอย่างที่นำมาคำนวณค่าอัตสหสัมพันธ์ก็จะลดลงทีละ 1 หน่วยไปเรื่อย ๆ การวิเคราะห์อัตสหสัมพันธ์ของกระบวนการสุ่มสามารถทำได้สองลักษณะ ลักษณะแรกคือวิเคราะห์จากค่าสถิติโดยตรง และลักษณะที่สองคือใช้แผนภาพอัตสหสัมพันธ์ โดยทั้งสองแบบสามารถทำได้ในโปรแกรม R ด้วย package-coda โดยเขียนคำสั่งดังนี้\n\n       mu_sdpro1 sigma_sdpro1   mu_sdpro2 sigma_sdpro2 mu_sdpro3\nLag 0  1.0000000    1.0000000  1.00000000   1.00000000 1.0000000\nLag 1  0.9994292    0.9998234  0.82152505   0.72753970 0.9860251\nLag 5  0.9971468    0.9990995  0.39664748   0.18920770 0.9336869\nLag 10 0.9942847    0.9981647  0.17519306   0.04112503 0.8774738\nLag 50 0.9709985    0.9898665 -0.02851881  -0.02866540 0.5591402\n       sigma_sdpro3\nLag 0     1.0000000\nLag 1     0.9832460\nLag 5     0.9159518\nLag 10    0.8293820\nLag 50    0.4494689\n\n\nThining\nการแก้ปัญหาอัตสหสัมพันธ์สามารถทำได้โดยการกำหนดรอบการทวนซ้ำให้มากขึ้น เขียนแทนด้วย \\(\\theta_1, \\theta_2, \\theta_3, ...,\\theta_m\\) หาก \\(n_0\\) คือระยะห่าง (lag) ที่น้อยที่สุดระหว่างตัวอย่างที่มีค่าอัตสหสัมพันธ์เท่ากับหรือใกล้เคียง 0 ผู้วิเคราะห์จะเลือกเฉพาะตัวอย่าง \\(\\theta_{n_0}, \\theta_{2n_0}, \\theta_{3n_0},...,\\theta_{T}\\) ซึ่งมีแนวโน้มเป็นอิสระซึ่งกันและกัน ไปดำเนินการต่อในขั้นการอนุมานเชิงสถิติ เรียกการดำเนินการในข้างต้นว่า thinning\nEffective Sample Size (ESS)\nจากที่กล่าวในข้างต้นจะเห็นว่า ในสถานการณ์ที่กระบวนการสุ่มที่สร้างขึ้นมีอัตสหสัมพันธ์สูง ตัวอย่างสุ่มของพารามิเตอร์จะมีแนวโน้มซ้ำซ้อนกันมาก และทำให้การทวนซ้ำของกระบวนการสุ่มมีประสิทธิภาพต่ำกว่าจำนวนการทวนซ้ำที่กำหนดไว้ กล่าวคือจำนวนรอบทวนซ้ำที่กำหนดไว้อาจไม่เพียงพอที่จะนำไปประมาณการแจกแจงความน่าจะเป็นภายหลัง สถิติที่ช่วยวัดประสิทธิภาพในด้านนี้คือ effective sample size (ESS)\nกำหนดให้ \\(\\theta_1, \\theta_2, \\theta_3, ...,\\theta_m\\) เป็นตัวอย่างสุ่มของพารามิเตอร์ที่สร้างขึ้นจากอัลกอริทึม MCMC และ \\(n_0\\) เป็นระยะห่าง (lag) ที่น้อยที่สุดที่ตัวอย่างสุ่มของพารามิเตอร์มีอัตสหสัมพันธ์เท่ากับหรือใกล้เคียง 0 จากการกำหนดในข้างต้นจะได้ว่า ตัวอย่างสุ่มที่สร้างจากกระบวนการสุ่มข้างต้น และเป็นอิสระซึ่งกันและกันคือ\n\\(\\theta_{n_0}, \\theta_{2n_0}, \\theta_{3n_0},...,\\theta_{T}\\)\nจะเห็นว่าในกรณีที่เกิดอัตสหสัมพันธ์ขึ้น ตัวอย่างที่เป็นอิสระซึ่งกันและกันจะมีจำนวนน้อยกว่าจำนวนตัวอย่างรวม ค่า ESS จึงมีค่าเท่ากับ \\(m/n_0\\)\nการคำนวณค่า ESS ใน R สามารถทำได้โดยใช้ฟังก์ชัน effectiveSize()\n\n   mu_sdpro1 sigma_sdpro1    mu_sdpro2 sigma_sdpro2    mu_sdpro3 \n   1.4270665    0.4414857  489.8072701  788.4212271   28.6767087 \nsigma_sdpro3 \n  41.3083142 \n\nMonte Carlo Standard Error\n\n\nIterations = 1:5000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n               Mean      SD Naive SE Time-series SE\nmu_sdpro1    85.068 15.8021 0.223475      13.227925\nsigma_sdpro1 21.291 10.9451 0.154787      16.472555\nmu_sdpro2    99.119  0.1826 0.002582       0.008250\nsigma_sdpro2  9.944  0.1291 0.001825       0.004596\nmu_sdpro3    99.134  0.1512 0.002138       0.028234\nsigma_sdpro3  9.941  0.1132 0.001601       0.017609\n\n2. Quantiles for each variable:\n\n               2.5%    25%    50%   75% 97.5%\nmu_sdpro1    51.757 72.609 91.524 99.09 99.49\nsigma_sdpro1  9.753 10.005 19.253 33.43 36.84\nmu_sdpro2    98.770 99.002 99.116 99.25 99.47\nsigma_sdpro2  9.697  9.855  9.940 10.03 10.20\nmu_sdpro3    98.823 99.077 99.176 99.24 99.38\nsigma_sdpro3  9.693  9.879  9.948 10.01 10.15\n\n\\(SE_{naive}=\\sqrt{\\frac{Var(\\theta)}{m}}\\)\n\\(SE_{ts}=\\sqrt{\\frac{Var_{ts}(\\theta)}{m}}\\) โดยที่ \\(Var(\\theta)=\\frac{\\sigma^2}{(1-\\sum_{k=1}^K\\rho_k)^2}\\)\n\\(\\sigma^2\\) เป็นความแปรปรวนของความคลาดเคลื่อนสุ่มที่ประมาณจากโมเดล autoregressive (AR) อันดับที่ K ส่วน \\(\\rho_k\\) คือค่าสัมประสิทธิ์อัตสหสัมพันธ์อันดับที่ \\(k\\)\nPotential Scale Reduction (\\(\\hat{R}\\) หรือ RSRF)\nการตรวจสอบการลู่เข้าของลูกโซ่มาร์คอฟด้วยวิธีการที่กล่าวมา แม้จะได้ผลลัพธ์ว่ามีแนวโน้มที่ตัวอย่างลูกโซ่จะลู่เข้าไปสู่การแจกแจงใดการแจกแจงหนึ่ง แต่ก็ยังไม่สามารถยืนยันได้ว่าการแจกแจงดังกล่าวเป็นการแจกแจงเป้าหมายที่แท้จริงหรือไม่\nวิธีการหนึ่งที่ช่วยเพิ่มหลักฐานและเสริมความมั่นใจให้กับผู้วิเคราะห์ว่า ตัวอย่างลูกโซ่ที่สร้างขึ้นมีการแจกแจงที่ลู่เข้าไปหาการแจกแจงความน่าจะเป็นภายหลังที่ต้องการจริง ๆ คือ การสร้างตัวอย่างลูกโซ่หลาย ๆ ชุด โดยกำหนดค่าเริ่มต้นให้แตกต่างกัน จากนั้นสังเกตผลลัพธ์ที่ได้ หากตัวอย่างทุกชุดมีแนวโน้มที่ลู่เข้าไปหาการแจกแจงเดียวกัน ผู้วิเคราะห์จะมีหลักฐานที่สนับสนุนให้เชื่อได้ว่าตัวอย่างสุ่มที่สร้างขึ้นจากอัลกอริทึม MCMC ลู่เข้าไปหาการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ\nการวิเคราะห์การลู่เข้านี้สามารถวิเคราะห์ได้จากทั้ง trace plot และ density plot และใช้ค่าสถิติ potential scale reduction (\\(\\hat{R}\\)) สถิตินี้มีค่าเท่ากับอัตราส่วนระหว่างความแปรปรวนรวม (total variance) ของตัวอย่างลูกโซ่ต่อความแปรปรวนภายลูกโซ่ (within-chain variance) ดังนี้\n\\(\\hat{R}=\\sqrt{\\frac{Var(\\theta)}{W}}\\)\nโดยที่ \\(Var(\\theta)=(1-\\frac{1}{m}W+\\frac{1}{m}B)\\)\n\\(W=\\frac{1}{C}\\sum_{j=1}^CS^2_j\\)\n\\(S^2_j=\\frac{1}{n-1}\\sum_{i=1}^n(\\theta_{ij}-\\overline{\\theta}_{.j})^2\\)\n\\(B = \\frac{n}{C-n}\\sum_{j=1}^C(\\overline{\\theta}_j-\\overline{\\theta}_{..})\\)\nจากสูตรของ \\(\\hat{R}\\) ข้างต้นจะเห็นว่า ถ้า \\(\\hat{R} \\approx 1\\) นั่นหมายความว่าตัวอย่างลูกโซ่ที่สร้างขึ้นแต่ละชุด มีการแจกแจงที่ใกล้เคียงกัน กล่าวคือตัวอย่างลูกโซ่ที่สร้างขึ้นมีคุณสมบัติลู่เข้าไปยังการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ แต่ถ้าหาก \\(\\hat{R}>1\\) บ่งชี้ว่าตัวอย่างลูกโซ่ที่สร้างขึ้นมีการลู่ออก\nเกณฑ์การพิจารณา \\(\\hat{R}<1.1\\)\nนอกจากอัลกอริทึมที่กล่าวไว้ในบทเรียนนี้ยังมีอัลกอริทึม MCMC อีกหลายตัวที่สามารถใช้ประมาณการแจกแจงความน่าจะเป็นภายหลังได้ อีกอัลกอริทึมหนึ่งที่น่าสนใจคือ อัลกอริทึม Hamiltonial Monte Carlo ที่มีประสิทธิภาพสูงกว่า Metropilis และ Gibbs sampling ในแง่ของการลู่เข้าสู่การแจกแจงความน่าจะเป็นภายหลังที่ทำได้รวดเร็วกว่า ทำให้ไม่จำเป็นต้องใช้จำนวนรอบของการทวนซ้ำที่มากเท่ากับทั้งสองอัลกอริทึมข้างต้น แต่ก็มีข้อจำกัดคือในแต่ละรอบการทวนซ้ำอัลกอริทึม Hammiltoniam MCMC มีแนวโน้มที่จะใช้เวลาประมวลผลนานกว่าอัลกอริทึมทั้งสอง รายละเอียดของอัลกอริทึมนี้จะกล่าวในบทเรียนที่สอนการใช้งานโปรแกรม Stan\nบทเรียนต่อไปจะกล่าวถึงการใช้งานโปรแกรม JAGs ที่เป็นโปรแกรมสำเร็จรูปโปรแกรมหนึ่งที่ใช้สำหรับประมาณการแจกแจงความน่าจะเป็นภายหลังโดยอาศัยอัลกอริทึม Gibbs sampling ในข้างต้น\nnext –> Introduction to JAGs\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2022-02-03-mcmc-via-jags/mcmc-via-jags_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-02-21T22:51:00+07:00",
    "input_file": {}
  }
]
