[
  {
    "path": "posts/2022-02-08-priors/",
    "title": "Prior Distributions",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": {}
      }
    ],
    "date": "2022-02-07",
    "categories": [],
    "contents": "\n\nContents\nการระบุ priors\nDiffuse priors\nJeffrey’s prior\nConjugacy priors\nInformative priors\n\n\nการระบุ priors\nการระบุการแจกแจงความน่าจะเป็นก่อนหน้าในโมเดลการวิเคราะห์เป็นประเด็นสำคัญประเด็นหนึ่งสำหรับการวิเคราะห์ข้อมูลด้วยสถิติแบบเบส์ ทั้งนี้ในแต่ละการวิเคราะห์ ผู้วิเคราะห์จะต้องระบุการแจกแจงความน่าจะเป็นก่อนหน้าที่สารสนเทศของการแจกแจงสะท้อนความเชื่อเบื้องต้น (initial beliefs) ที่มีต่อค่าพารามิเตอร์แต่ละตัวภายในโมเดล หัวข้อนี้จะกล่าวถึง prior distribution ประเภทต่าง ๆ รายละเอียดมีดังนี้\nDiffuse priors\nหรืออาจเรียกว่า การแจกแจงความน่าจะเป็นก่อนหน้าแบบไม่มีสารสนเทศ (noninformative priors) หรือ flat priors การแจกแจงความน่าจะเป็นก่อนหน้าประเภทนี้มีลักษณะเด่นคือเป็นการแจกแจงที่ให้น้ำหนักกับความเป็นไปได้ต่าง ๆ ของค่าพารามิเตอร์ที่เท่าเทียมกัน กล่าวคือเป็น prior ที่มีฟังก์ชันความน่าจะเป็นอยู่ในรูปแบบ\n\\(p(\\theta)=Const.\\) เมื่อ \\(\\theta \\in A\\) โดยที่ \\(A\\) คือช่วงที่เป็นไปได้ของพารามิเตอร์ \\(\\theta\\)\nรูปต่อไปนี้แสดงตัวอย่างการแจกแจงของ diffuse priors\n\n\n\nจากรูปจะเห็นว่า diffuse priors เป็นการแจกแจงความน่าจะเป็นก่อนหน้าที่ ไม่ได้ให้น้ำหนักกับค่าพารามิเตอร์ค่าใด หรือช่วงใดช่วงหนึ่งเป็นพิเศษ​diffuse priors เป็น priors ที่มีความเป็นปรนัยสูง และส่งผลหรือมีอิทธิพลต่อการแจกแจงความน่าจะเป็นภายหลังน้อยที่สุด ทำให้การแจกแจงความน่าจะเป็นภายหลังที่คำนวณได้ถูกพัฒนาขึ้นจากสารสนเทศของข้อมูลเชิงประจักษ์แต่เพียงอย่างเดียว จากสมการด้านล่างจะเห็นว่า posterior distribution ที่ได้จะขึ้นอยู่กับส่วนของ likelihood function แต่เพียงอย่างเดียว\n\\(p(\\theta|D) = \\frac{p(D|\\theta)p(\\theta)}{p(D)} =\\frac{p(D|\\theta) \\times Const.}{P(D)}\\varpropto p(D|\\theta)\\)\nจากสมการในข้างต้นจะเห็นว่าการกำหนด prior ให้เป็น diffuse priors จะทำให้การแจกแจงความน่าจะเป็นภายหลังแปรผันตรงกับฟังก์ชันภาวะความควรจะเป็น ซึ่งทำให้ผลการวิเคราะห์เช่น ผลการประมาณค่าพารามิเตอร์ หรือการทำนายจะมีค่าที่เท่าหรือใกล้เคียงกับผลการวิเคราะห์ที่ได้จากการวิเคราะห์ข้อมูลแบบดั้งเดิม\nJeffrey’s prior\nพัฒนาขึ้นโดย Jeffrey (1961) การแจกแจงความน่าจะเป็นก่อนหน้านี้เป็นการแจกแจงแบบไม่มีสารสนเทศเช่นเดียวกับ diffuse prior ฟังก์ชันความน่าจะเป็นของการแจกแจงนี้แปรผันตรงกับรากที่สองของ determinant ของเมทริกซ์สารสนเทศของ Fisher (Fisher information matrix) ดังนี้\n\\(p(\\theta) \\varpropto |J(\\theta)|^{1/2}\\)\nเมื่อ \\(J(\\theta)\\) คือ Fisher information matrix ที่คำนวณได้จาก\n\\(J(\\theta)=Var(\\frac{\\partial}{\\partial \\theta}ln \\ p(\\theta|y))\\)\n\\(=E[-\\frac{\\partial^2 ln p(y|\\theta)}{\\partial \\theta^2}|\\theta]\\)\nจะเห็นว่า Fisher information ในข้างต้นเป็นดัชนีที่ใช้วัดสารสนเทศที่ข้อมูลตัวอย่างมีเกี่ยวกับพารามิเตอร์ต่าง ๆ ภายในโมเดล จากสูตรจะเห็นว่าดัชนีดังกล่าวคำนวณค่าสารสนเทศดังกล่าวโดยอิงกับค่าความแปรปรวน เนื่องจากในกรณีทั่วไปโมเดลการวิเคราะห์สามารถมีพารามิเตอร์ได้มากกว่าหนึ่งตัว ทำให้ Fisher information ดังกล่าวมีลักษณะเป็นเมทริกซ์ความแปรปรวนร่วม (covariance matrix) การสรุปสารสนเทศจากเมทริกซ์ดังกล่าวในเชิงของความแปรปรวน วิธีการหนึ่งคือการหาค่าความแปรปรวนทั่วไป (generalized variance) ด้วยการหา determinant ของเมทริกซ์ความแปรปรวนร่วมดังกล่าว\nจากมโนทัศน์ดังกล่าวจะเห็นว่า Jeffrey’s prior เป็นการแจกแจงความน่าจะเป็นก่อนหน้าที่อิงกับการแจกแจงความน่าจะเป็นของตัวอย่างสุ่มเป็นหลัก จึงจัดเป็น noninformative prior ตัวหนึ่งสำหรับโมเดลการวิเคราะห์แบบพาราเมทริกซ์\nตัวอย่างต่อไปนี้แสดงการแจกแจงความน่าจะเป็นก่อนหน้าแบบ Jeffrey สำหรับปัญหาการวิเคราะห์ความเที่ยงของของเหรียญ\nจากตัวอย่างการวิเคราะห์ความเที่ยงตรงของเหรียญ เนื่องจากฟังก์ชันภาวะความควรจะเป็นของพารามิเตอร์ความลำเอียงเมื่อกำหนดข้อมูลตัวอย่างคือ \\(p(D|\\theta)=\\theta^{\\sum y_i}(1-\\theta)^{n-\\sum y_i}\\) ดังนั้น log ของฟังก์ชันภาวะความควรจะเป็นดังกล่าวคือ\n\\(ln \\ p(D|theta) = \\sum y_i ln\\theta+(n-\\sum y_i)ln(1-\\theta)\\)\nและอนุพันธ์อันดับที่ 2 ของ \\(ln \\ p(D|theta)\\) มีค่าเท่ากับ\n\\(\\frac{\\partial^2 ln\\ p(D|\\theta)}{\\partial\\theta^2}=-\\frac{\\sum y_i}{\\theta^2}-\\frac{n-\\sum y_i}{(1-\\theta)^2}\\)\nดังนั้น Fisher Information ของพารามิเตอร์ \\(\\theta\\) ในโมเดลข้างต้นจึงมีค่าเท่ากับ\n\\(J(\\theta)=E[-\\frac{\\partial^2 ln p(y|\\theta)}{\\partial \\theta^2}|\\theta]=E[-(-\\frac{\\sum y_i}{\\theta^2}-\\frac{n-\\sum y_i}{(1-\\theta)^2})]=\\frac{n}{\\theta}+\\frac{n(1-\\theta)}{(1-\\theta)^2}\\)\nสมมุติว่าจากการเก็บรวบรวมข้อมูลพบว่า โยนเหรียญ 20 ครั้ง มีหน้าหัวเกิดขึ้น 7 ครั้ง แล้ว Jeffrey’s prior ของพารามิเตอร์ความลำเอียงคือ\n\\(p(\\theta)=|J(\\theta)|^{1/2}=|\\frac{20}{\\theta}+\\frac{20(1-\\theta)}{(1-\\theta)^2}|^{-1/2}\\)\n\n\npar(mar=c(5,5,1,1))\ntheta<-seq(0.01,0.99,0.01)\np.theta<-abs((20/theta+(20*(1-theta))/(1-theta)^2))^{0.5}\nplot(theta, p.theta, type=\"l\", col=\"#004D80\",xlab=expression(theta), ylab=\"Density\")\n\n\n\n\nหมายเหตุ ในปัญหาที่ใช้ฟังก์ชันภาวะความควรจะเป็นแบบ binomial จะได้ว่า Jeffrey’s prior จะมีการแจกแจงเทียบเท่ากับการแจกแจง beta ที่มีพารามิเตอร์ a = 0.5 และ b = 0.5\nจากการกำหนดข้างต้นจะได้ว่า ฟังก์ชันการแจกแจงความน่าจะเป็นภายหลังคือ\n\n\n\nคุณสมบัติเด่่นของ Jeffrey priors คือมีคุณสมบัติ invariant to transformation กล่าวคือ หาก \\(\\psi=f(\\theta)\\) จะได้ว่า \\(p(\\psi) \\varpropto |J(\\psi)|^{0.5}\\)\nConjugacy priors\nการแจกแจงความน่าจะเป็นก่อนหน้าจะเป็นการแจกแจงแบบ conjugacy prior ถ้าการแจกแจงความน่าจะเป็นก่อนหน้าและภายหลังเป็นการแจกแจงภายใน family เดียวกัน ด้วยคุณสมบัติดังกล่าวจึงทำให้การพิสูจน์หาสูตรหรือรูปแบบปิดของการแจกแจงความน่าจะเป็นภายหลังสามารถทำได้โดยที่ไม่ต้องหาเทอม \\(p(D)\\) ที่เป็นตัวส่วนใน Bayes’s rule\nตัวอย่างการแจกแจงก่อนหน้าแบบ conjugacy prior เช่น\nการแจกแจง beta คู่กับ binomial likelihood จะได้ posterior แบบ beta\nการแจกแจง normal คู่กับ normal likelihood จะได้ posterior แบบ normal\n\n\nInformative priors\ninformative prior หรือการแจกแจงความน่าจะเป็นก่อนหน้าแบบมีสารสนเทศ เป็นการแจกแจงความน่าจะเป็นก่อนหน้าที่รูปแบบของการแจกแจงไม่จำเป็นต้องขึ้นกับหรือเกี่ยวข้องกับฟังก์ชันภาวะความควรจะเป็น แต่ขึ้นกับสารสนเทศจากแหล่งอื่น ๆ นอกเหนือจากข้อมูลจริงที่ผู้วิเคราะห์มีเกี่ยวกับพารามิเตอร์ต่าง ๆ ภายในโมเดล สารสนเทศภายในการแจกแจงความน่าจะเป็นก่อนหน้าประเภทนี้อาจเรียกว่า ความรู้ก่อนหน้า (prior knowledge)\nการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าลักษณะนี้จึงมีผลโดยตรงต่อการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ ซึ่งอาจทำให้ผลการรวิเคราะห์ที่ได้มีความถูกต้องมากขึ้น หรืออาจทำให้ผลการวิเคราะห์ที่ได้มีความลำเอียงก็ได้ ขึ้นอยู่กับการออกแบบ informative prior ของผู้วิเคราะห์\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2022-02-08-priors/priors_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-02-08T01:17:45+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-05-jags/",
    "title": "Introduction to JAGS",
    "description": "การใช้งาน JAGS เบื้องต้น",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": {}
      }
    ],
    "date": "2022-02-04",
    "categories": [],
    "contents": "\n\nContents\nติดต้ังโปรแกรม\nการเขียนคำสั่งใน JAGS\nการนำเข้าและจัดการข้อมูล\nการระบุโมเดล\nโมเดลของค่าสังเกต\nการแจกแจงความน่าจะเป็นก่อนหน้า\nสภาพแวดล้อมของ JAGs\n\nการประมวลผล\nระบุ JAGs โมเดล\nสั่งประมวลผล\n\nการอนุมานเชิงสถิติแบบเบส์โดยใช้ตัวอย่างจาก MCMC algorithm\nการระบุ priors\nDiffuse priors\nJeffrey’s prior\nConjugacy priors\nInformative priors\n\n\n\nผู้อ่านได้ทำความเข้าใจมโนทัศน์เกี่ยวกับอัลกอริทึม MCMC แล้ว อย่างไรก็ตามจะเห็นว่าการเขียนอัลกอริทึมดังกล่าวค่อนข้างลำบาก และมีโอกาสสูงที่จะเกิดความผิดพลาด ปัจจุบันมีโปรแกรมสำเร็จรูปหลายตัวที่ช่วยให้ผู้วิเคราะห์สามารถประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ภายในโมเดลใด ๆ ได้อย่างสะดวกมากยิ่งขึ้น บทเรียนนี้จะกล่าวถึงโปรแกรม JAGS (Just Another Gibb Sampler) รายละเอียดมีดังนี้\nติดต้ังโปรแกรม\nนิสิตสามารถ เข้าไปดาวน์โหลดโปรแกรม JAGS (Just Another Gibb Sampler) ได้ที่\nhttps://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/\nการใช้งาน JAGS ในข้างต้นจะไม่ได้ใช้งานแบบ standard alone แต่จะใช้งานผ่านโปรแกรม R โดยผู้ใช้จำเป็นต้องดาวน์โหลด package เสริมอีก 2 ตัวได้แก่ rjags และ runjags ดังนี้\n\n\ninstall.packages(\"rjags\", dependencies = TRUE)\ninstall.packages(\"runjags\", dependencies = TRUE)\n\n\n\nก่อนใช้งาน package ทั้งสองผู้ใช้จำต้องเรียกใช้ package ดังกล่าวก่อนโดยพิมพ์คำสั่งดังนี้\n\n\nlibrary(rjags)\nlibrary(runjags)\n\n\n\nกระบวนการทำงานร่วมกันระหว่าง R กับ JAGSการเขียนคำสั่งใน JAGS\nการเขียนคำสั่งต่าง ๆ จะทำบนโปรแกรม R ทั้งหมด โดยอาจแบ่งขั้นตอนการดำเนินงานออกเป็น 4 ขั้นตอนได้แก่ การนำเข้าและจัดการข้อมูล การระบุโมเดล การประมวลผล และการตรวจสอบและวิเคราะห์ผลลัพธ์ที่ได้ รายละเอียดมีดังนี้\nการนำเข้าและจัดการข้อมูล\nข้อมูลตัวอย่างผลสัมฤทธิ์ทางการเรียนวิชา calculas ของนิสิตจำนวน 100 คน บันทึกอยู่ในไฟล์ชื่อ bayes_exam1.csv ทั้งนี้เมื่อดาวน์โหลดข้อมูลมาแล้วสามารถนำเข้าสู่ R ได้โดยเขียนคำสั่งดังนี้\n\n\nlibrary(dplyr)\ndat<-read.csv(\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/bayes_exam1.csv\")\nglimpse(dat)\n\n\nRows: 100\nColumns: 2\n$ id  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ CAL <dbl> 68.8, 89.8, 40.0, 61.2, 8.8, 59.0, 57.5, 65.8, 50.9, 79.…\n\nการระบุโมเดล\nวัตถุประสงค์ของการวิเคราะห์มี 2 ข้อ ได้แก่\nเพื่อวิเคราะห์ระดับผลสัมฤทธิ์ทางการเรียนวิชา calculas ของนิสิต\nเพื่อวิเคราะห์ว่าค่าเฉลี่ยผลสัมฤทธิ์วิชา calculas ของนิสิตมีค่าสูงกว่า 50 คะแนนหรือไม่\nจากวัตถุประสงค์การวิเคราะห์และข้อมูลค่าสังเกตที่มี สามารถระบุโมเดลการวิเคราะห์ได้ดังนี้\nโมเดลของค่าสังเกต\nกำหนดให้โมเดลของคะแนนผลสัมฤทธิ์ (\\(y_i\\)) มีการแจกแจงแบบปกติที่มีค่าเฉลี่ยและความแปรปรวนเท่ากับ \\(\\mu\\) และ \\(\\sigma^2\\) ตามลำดับ เขียนแทนด้วย \\(y_i \\sim N(\\mu,\\sigma^2)\\) อย่างไรก็ตามในโปรแกรม JAGS จะไม่ได้ใช้พารามิเตอร์ความแปรปรวนเป็นพารามิเตอร์ของการแจกแจงแบบปกติ แต่ละใช้พารามิเตอร์ความเที่ยงตรง (precision parameter) ซึ่งเป็นส่วนกลับของพารามิเตอร์ความแปรปรวนแทน ดังนั้นโมเดลค่าสังเกตในกรณีนี้สามารถเขียนได้ดังนี้\n\\(y_i \\sim N(\\mu, \\tau=1/\\sigma^2)\\)\nจากโมเดลค่าสังเกตข้างต้นจะได้ ฟังก์ชันภาวะความควรจะเป็น (likelihood function) เป็น\n\\(p(D|y)=\\Pi_{i=1}^nN(y_i|\\mu, \\tau=1/\\sigma^2)\\)\nการแจกแจงความน่าจะเป็นก่อนหน้า\nจากการระบุโมเดลค่าสังเกตข้างต้น พบว่ามีพารามิเตอร์ 2 ตัวได้แก่ พารามิเตอร์ค่าเฉลี่ย และความเที่ยงตรง จึงระบุการแจกแจงความน่าจะเป็นก่อนหน้าให้กับพารามิเตอร์ทั้งสองเป็นดังนี้\n\\(\\mu \\sim N(m, t=1/S^2)\\) และ \\(\\tau \\sim Uniform(a,b)\\)\nความสัมพันธ์ระหว่างค่าสังเกต โมเดลความน่าจะเป็น และการแจกแจงความน่าจะเป็นก่อนหน้าสภาพแวดล้อมของ JAGs\nเมื่อผู้วิเคราะห์ระบุโมเดลเชิงทฤษฎีในข้างต้นแล้ว ขั้นตอนถัดมาคือการระบุโมเดลสำหรับโปรแกรม JAGS การระบุโมเดลใน JAGs จำเป็นต้องมีความรู้เบื้องต้นเกี่ยวกับสภาพแวดล้อมของโปรแกรม JAGs ก่อน ประเด็นแรกคือเรื่องวัตถุหรือตัวแปรภายต่าง ๆ ภายในโปรแกรม JAGs จะเรียกว่า node จำแนกออกเป็น 3 ประเภทได้แก่\nค่าคงที่ (constant nodes)\nค่าตัวแปรสุ่ม (Stochastic nodes) เป็นตัวแปรที่มีการแจกแจงความน่าจะเป็นกำกับโดเมนหรือค่าของตัวแปรไว้ การนิยามตัวแปรประเภทนี้จะเขียนอยู่ในรูปแบบ variable ~ distribution_name(par1, par2, ...) ยกตัวอย่างเช่น ตัวอย่างข้างต้นกำหนดให้โมเดลของค่าสังเกต \\(y_i\\) มีการแจกแจงแบบปกติ สามารถนิยามตัวแปรนี้บน JAGs ได้เป็น y[i] ~ dnorm(mu, tau) ส่วนการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ \\(\\mu\\) และ \\(\\tau\\) สามารถระบุได้เป็น mu ~ dnorm(m,t) และ tau ~ dunif(a,b)\n\nฟังก์ชันเชิงคณิตศาสตร์ (Deterministic nodes) เป็นตัวแปรที่สร้างขึ้นจากฟังก์ชันหรือความสัมพันธ์เชิงคณิตศาสตร์กับ node อื่น ๆ เช่น mu[i] <- b0+b1*x[i]\nประเด็นที่สองเป็นเรื่องเกี่ยวกับโครงสร้างของตัวแปร และการระบุตำแหน่งของสมาชิกภายในโครงการของตัวแปร ตัวแปรอาจจำแนกโดยใช้โครงสร้างของตัวแปรออกได้เป็น 4 ประเภทหลัก ๆ ได้แก่ ค่าคงที่หรือสเกลาร์ เวกเตอร์ เมทริกซ์ และอาร์เรย์ที่มีมิติตั้งแต่ 3 มิติขึ้นไป การระบุตำแหน่งของสมาชิกภายในตัวแปรดังกล่าวทำได้ในวิธีเดียวกับในโปรแกรม R เช่น\ny[i] หมายถึงสมาชิกตัวที่ i ในเวกเตอร์ y\nmu.p[i,j] หมายถึงสมาชิกในแถวที่ i และคอลัมนท์ที่ j\nประเด็นที่สามเป็นเรื่องการดำเนินการทวนซ้ำ (repeated structures) ในโปรแกรม JAGs ผู้วิเคราะห์ไม่จำเป็นต้องพิสูจน์เพื่อหารูปแบบของฟังก์ชันภาวะความควรจะเป็นด้วยตัวเอง แต่สามารถสั่งให้โปรแกรมประมวลผลได้โดยกำหนดโมเดลของค่าสังเกตเอาไว้ภายใต้ loop เช่น ฟังก์ชันภาวะความควรจะเป็นในตัวอย่างข้างต้นสามารถระบุได้ดังนี้\n\n\nfor (i in 1:n)\n{\n  y[i]~dnorm(mu, tau)\n}\n\n\n\nประเด็นสุดท้ายเป็นโครงสร้างของชุดคำสั่งสำหรับระบุโมเดลทั้งหมด แต่ละโมเดลจะมีส่วนประกอบ 3 ส่วนได้แก่\nฟังก์ชันภาวะความควรจะเป็น (likelihood function) ระบุภายใต้ for loop ดังตัวอย่างด้านบน\nการแจกแจงความน่าจะเป็นก่อนหน้า (prior distributions) ของพารามิเตอร์ภายใต้โมเดลการวิเคราะห์\nส่วน deterministic function ที่ใช้สำหรับสร้างสารสนเทศที่ต้องการจากพารามิเตอร์ของโมเดล\nตัวอย่างด้านล่างแสดงโครงสร้างของชุดข้อมูลที่ใช้ระบุโมเดลในโปรแกรม JAGs\n\nmodel{\n  \n  # Likelihood\n  for (i in 1:n)\n  {\n    \n  }\n  \n  # Prior Distributions\n  \n  \n  \n  # Derived quantities \n  \n  \n\n  } #end of model\n\nการประมวลผล\nตัวอย่างต่อไปนี้แสดงขั้นตอนการสั่งให้ JAGs ประมวลผลเพื่อสร้างตัวอย่างสุ่มของลูกโซ่มาร์คอฟ\nระบุ JAGs โมเดล\n\n\nmean.model<-\"\nmodel{\n  \n  # Likelihood\n  for (i in 1:n)\n  {\n    y[i]~dnorm(mu, tau)\n  }\n  \n  # Prior Distributions\n  mu~dnorm(0,0.01)\n  tau~dunif(0,5)\n  \n  # Derived quantities \n  sigma2<-1/tau\n  \n  }\"\n# write mean.model to model1.txt\nwriteLines(mean.model, con=\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/model1.txt\") \n\n\n\nสั่งประมวลผล\n\n\nlibrary(rjags)\ndataList<-list(y=dat[,2], n=dim(dat)[1])\ninitsList<-list(mu=1, tau=1)\n\nmodel<-jags.model(file=\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/model1.txt\",\n                  data = dataList,\n                  inits = initsList,\n                  n.chains = 5)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 100\n   Unobserved stochastic nodes: 2\n   Total graph size: 108\n\nInitializing model\n\n\n\nupdate(model, n.iter=2000) #n.burnin\nsamples<-coda.samples(model,\n                      variable.names = c(\"mu\",\"sigma2\"),\n                      n.iter = 10000,\n                      thin = 3)\n\n\n\n\n\nhead(samples)\n\n\n[[1]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 57.95158 223.8532\n[2,] 53.78736 280.1578\n[3,] 60.48501 294.8803\n[4,] 57.28361 274.2334\n[5,] 57.75318 288.3812\n[6,] 57.73848 237.6426\n[7,] 54.65661 312.6450\n\n[[2]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 57.03782 293.7893\n[2,] 53.60036 333.3379\n[3,] 58.62952 302.7675\n[4,] 58.13502 290.7615\n[5,] 57.26114 299.0805\n[6,] 58.77689 300.0338\n[7,] 56.38106 292.4083\n\n[[3]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 57.52367 303.5255\n[2,] 56.67343 252.7015\n[3,] 58.98620 262.7514\n[4,] 57.52187 279.7626\n[5,] 55.21460 250.4274\n[6,] 57.26374 299.4826\n[7,] 56.26766 301.8792\n\n[[4]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 57.02077 258.2102\n[2,] 60.44737 337.9556\n[3,] 59.10201 264.4821\n[4,] 56.44789 295.0357\n[5,] 59.46504 266.5985\n[6,] 61.72859 327.5610\n[7,] 56.32689 373.2698\n\n[[5]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 59.56030 253.8588\n[2,] 59.51444 292.5767\n[3,] 55.63602 257.7063\n[4,] 56.02992 329.0299\n[5,] 55.12180 349.6111\n[6,] 59.11718 261.4610\n[7,] 57.98936 262.2221\n\nattr(,\"class\")\n[1] \"mcmc.list\"\n\nอีก package หนึ่งที่สามารถเรียก JAGS จาก R ได้คือ package-runjags ซึ่งมีจุดเด่นคือสามารถสั่งประมวลแบบคู่ขนาน (parallel) แยกตาม core ของ CPU ได้ในกรณีที่ผู้วิเคราะห์กำหนดให้สุ่มตัวอย่างจากลูกโซ่มาร์คอฟที่มีจำนวนมากกว่า 1 ลูกโซ่ ตัวอย่างคำสั่งเป็นดังนี้\n\n\nlibrary(runjags)\n\nmodel.runjags<-run.jags(method=\"parallel\",\n                        model=\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/model1.txt\",\n                        monitor=c(\"mu\",\"sigma2\"),\n                        data=dataList,\n                        inits=initsList,\n                        n.chains=3,\n                        burnin=1000,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE)\n\n\nCalling 3 simulations using the parallel method...\nFollowing the progress of chain 1 (the program will wait for\nall chains to finish before continuing):\nWelcome to JAGS 4.3.0 on Tue Feb  8 01:04:51 2022\nJAGS is free software and comes with ABSOLUTELY NO WARRANTY\nLoading module: basemod: ok\nLoading module: bugs: ok\n. . Reading data file data.txt\n. Compiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 100\n   Unobserved stochastic nodes: 2\n   Total graph size: 108\n. Reading parameter file inits1.txt\n. Initializing model\n. Adapting 1000\n-------------------------------------------------| 1000\n++++++++++++++++++++++++++++++++++++++++++++++++++ 100%\nAdaptation successful\n. Updating 1000\n-------------------------------------------------| 1000\n************************************************** 100%\n. . . Updating 30000\n-------------------------------------------------| 30000\n************************************************** 100%\n. . . . Updating 0\n. Deleting model\n. \nAll chains have finished\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nCalculating summary statistics...\nCalculating the Gelman-Rubin statistic for 2 variables....\nFinished running the simulation\n\nsamples2<-as.mcmc.list(model.runjags)\nhead(samples2)\n\n\n[[1]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 2001 \nEnd = 2019 \nThinning interval = 3 \n          mu  sigma2\n2001 54.2371 240.049\n2004 56.5241 335.668\n2007 55.5401 304.403\n2010 58.9008 300.230\n2013 58.1106 310.772\n2016 57.0254 285.352\n2019 58.2355 239.854\n\n[[2]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 2001 \nEnd = 2019 \nThinning interval = 3 \n          mu  sigma2\n2001 59.2309 292.842\n2004 57.8548 324.693\n2007 57.8617 358.349\n2010 56.2667 256.500\n2013 57.7341 315.282\n2016 56.5582 255.266\n2019 57.7516 267.690\n\n[[3]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 2001 \nEnd = 2019 \nThinning interval = 3 \n          mu  sigma2\n2001 56.3835 297.172\n2004 55.8723 289.803\n2007 52.9127 400.540\n2010 59.2212 326.777\n2013 55.3426 244.656\n2016 59.9937 283.527\n2019 59.6043 315.099\n\nattr(,\"class\")\n[1] \"mcmc.list\"\n\nการอนุมานเชิงสถิติแบบเบส์โดยใช้ตัวอย่างจาก MCMC algorithm\nการระบุ priors\nการระบุการแจกแจงความน่าจะเป็นก่อนหน้าในโมเดลการวิเคราะห์เป็นประเด็นสำคัญประเด็นหนึ่งสำหรับการวิเคราะห์ข้อมูลด้วยสถิติแบบเบส์ ทั้งนี้ในแต่ละการวิเคราะห์ ผู้วิเคราะห์จะต้องระบุการแจกแจงความน่าจะเป็นก่อนหน้าที่สารสนเทศของการแจกแจงสะท้อนความเชื่อเบื้องต้น (initial beliefs) ที่มีต่อค่าพารามิเตอร์แต่ละตัวภายในโมเดล หัวข้อนี้จะกล่าวถึง prior distribution ประเภทต่าง ๆ รายละเอียดมีดังนี้\nDiffuse priors\nหรืออาจเรียกว่า การแจกแจงความน่าจะเป็นก่อนหน้าแบบไม่มีสารสนเทศ (noninformative priors) หรือ flat priors การแจกแจงความน่าจะเป็นก่อนหน้าประเภทนี้มีลักษณะเด่นคือเป็นการแจกแจงที่ให้น้ำหนักกับความเป็นไปได้ต่าง ๆ ของค่าพารามิเตอร์ที่เท่าเทียมกัน กล่าวคือเป็น prior ที่มีฟังก์ชันความน่าจะเป็นอยู่ในรูปแบบ\n\\(p(\\theta)=Const.\\) เมื่อ \\(\\theta \\in A\\) โดยที่ \\(A\\) คือช่วงที่เป็นไปได้ของพารามิเตอร์ \\(\\theta\\)\nรูปต่อไปนี้แสดงตัวอย่างการแจกแจงของ diffuse priors\n\n\n\nจากรูปจะเห็นว่า diffuse priors เป็นการแจกแจงความน่าจะเป็นก่อนหน้าที่ ไม่ได้ให้น้ำหนักกับค่าพารามิเตอร์ค่าใด หรือช่วงใดช่วงหนึ่งเป็นพิเศษ​diffuse priors เป็น priors ที่มีความเป็นปรนัยสูง และส่งผลหรือมีอิทธิพลต่อการแจกแจงความน่าจะเป็นภายหลังน้อยที่สุด ทำให้การแจกแจงความน่าจะเป็นภายหลังที่คำนวณได้ถูกพัฒนาขึ้นจากสารสนเทศของข้อมูลเชิงประจักษ์แต่เพียงอย่างเดียว จากสมการด้านล่างจะเห็นว่า posterior distribution ที่ได้จะขึ้นอยู่กับส่วนของ likelihood function แต่เพียงอย่างเดียว\n\\(p(\\theta|D) = \\frac{p(D|\\theta)p(\\theta)}{p(D)} =\\frac{p(D|\\theta) \\times Const.}{P(D)}\\varpropto p(D|\\theta)\\)\nจากสมการในข้างต้นจะเห็นว่าการกำหนด prior ให้เป็น diffuse priors จะทำให้การแจกแจงความน่าจะเป็นภายหลังแปรผันตรงกับฟังก์ชันภาวะความควรจะเป็น ซึ่งทำให้ผลการวิเคราะห์เช่น ผลการประมาณค่าพารามิเตอร์ หรือการทำนายจะมีค่าที่เท่าหรือใกล้เคียงกับผลการวิเคราะห์ที่ได้จากการวิเคราะห์ข้อมูลแบบดั้งเดิม\nJeffrey’s prior\nพัฒนาขึ้นโดย Jeffrey (1961) การแจกแจงความน่าจะเป็นก่อนหน้านี้เป็นการแจกแจงแบบไม่มีสารสนเทศเช่นเดียวกับ diffuse prior ฟังก์ชันความน่าจะเป็นของการแจกแจงนี้แปรผันตรงกับรากที่สองของ determinant ของเมทริกซ์สารสนเทศของ Fisher (Fisher information matrix) ดังนี้\n\\(p(\\theta) \\varpropto |J(\\theta)|^{1/2}\\)\nเมื่อ \\(J(\\theta)\\) คือ Fisher information matrix ที่คำนวณได้จาก\n\\(J(\\theta)=Var(\\frac{\\partial}{\\partial \\theta}ln \\ p(\\theta|y))\\)\n\\(=E[-\\frac{\\partial^2 ln p(y|\\theta)}{\\partial \\theta^2}|\\theta]\\)\nจะเห็นว่า Fisher information ในข้างต้นเป็นดัชนีที่ใช้วัดสารสนเทศที่ข้อมูลตัวอย่างมีเกี่ยวกับพารามิเตอร์ต่าง ๆ ภายในโมเดล จากสูตรจะเห็นว่าดัชนีดังกล่าวคำนวณค่าสารสนเทศดังกล่าวโดยอิงกับค่าความแปรปรวน เนื่องจากในกรณีทั่วไปโมเดลการวิเคราะห์สามารถมีพารามิเตอร์ได้มากกว่าหนึ่งตัว ทำให้ Fisher information ดังกล่าวมีลักษณะเป็นเมทริกซ์ความแปรปรวนร่วม (covariance matrix) การสรุปสารสนเทศจากเมทริกซ์ดังกล่าวในเชิงของความแปรปรวน วิธีการหนึ่งคือการหาค่าความแปรปรวนทั่วไป (generalized variance) ด้วยการหา determinant ของเมทริกซ์ความแปรปรวนร่วมดังกล่าว\nจากมโนทัศน์ดังกล่าวจะเห็นว่า Jeffrey’s prior เป็นการแจกแจงความน่าจะเป็นก่อนหน้าที่อิงกับการแจกแจงความน่าจะเป็นของตัวอย่างสุ่มเป็นหลัก จึงจัดเป็น noninformative prior ตัวหนึ่งสำหรับโมเดลการวิเคราะห์แบบพาราเมทริกซ์\nตัวอย่างต่อไปนี้แสดงการแจกแจงความน่าจะเป็นก่อนหน้าแบบ Jeffrey สำหรับปัญหาการวิเคราะห์ความเที่ยงของของเหรียญ\nจากตัวอย่างการวิเคราะห์ความเที่ยงตรงของเหรียญ เนื่องจากฟังก์ชันภาวะความควรจะเป็นของพารามิเตอร์ความลำเอียงเมื่อกำหนดข้อมูลตัวอย่างคือ \\(p(D|\\theta)=\\theta^{\\sum y_i}(1-\\theta)^{n-\\sum y_i}\\) ดังนั้น log ของฟังก์ชันภาวะความควรจะเป็นดังกล่าวคือ\n\\(ln \\ p(D|theta) = \\sum y_i ln\\theta+(n-\\sum y_i)ln(1-\\theta)\\)\nและอนุพันธ์อันดับที่ 2 ของ \\(ln \\ p(D|theta)\\) มีค่าเท่ากับ\n\\(\\frac{\\partial^2 ln\\ p(D|\\theta)}{\\partial\\theta^2}=-\\frac{\\sum y_i}{\\theta^2}-\\frac{n-\\sum y_i}{(1-\\theta)^2}\\)\nดังนั้น Fisher Information ของพารามิเตอร์ \\(\\theta\\) ในโมเดลข้างต้นจึงมีค่าเท่ากับ\n\\(J(\\theta)=E[-\\frac{\\partial^2 ln p(y|\\theta)}{\\partial \\theta^2}|\\theta]=E[-(-\\frac{\\sum y_i}{\\theta^2}-\\frac{n-\\sum y_i}{(1-\\theta)^2})]=\\frac{n}{\\theta}+\\frac{n(1-\\theta)}{(1-\\theta)^2}\\)\nสมมุติว่าจากการเก็บรวบรวมข้อมูลพบว่า โยนเหรียญ 20 ครั้ง มีหน้าหัวเกิดขึ้น 7 ครั้ง แล้ว Jeffrey’s prior ของพารามิเตอร์ความลำเอียงคือ\n\\(p(\\theta)=|J(\\theta)|^{1/2}=|\\frac{20}{\\theta}+\\frac{20(1-\\theta)}{(1-\\theta)^2}|^{-1/2}\\)\n\n\npar(mar=c(5,5,1,1))\ntheta<-seq(0.01,0.99,0.01)\np.theta<-abs((20/theta+(20*(1-theta))/(1-theta)^2))^{0.5}\nplot(theta, p.theta, type=\"l\", col=\"#004D80\",xlab=expression(theta), ylab=\"Density\")\n\n\n\n\nหมายเหตุ ในปัญหาที่ใช้ฟังก์ชันภาวะความควรจะเป็นแบบ binomial จะได้ว่า Jeffrey’s prior จะมีการแจกแจงเทียบเท่ากับการแจกแจง beta ที่มีพารามิเตอร์ a = 0.5 และ b = 0.5\nจากการกำหนดข้างต้นจะได้ว่า ฟังก์ชันการแจกแจงความน่าจะเป็นภายหลังคือ\n\n\n\nคุณสมบัติเด่่นของ Jeffrey priors คือมีคุณสมบัติ invariant to transformation กล่าวคือ หาก \\(\\psi=f(\\theta)\\) จะได้ว่า \\(p(\\psi) \\varpropto |J(\\psi)|^{0.5}\\)\nConjugacy priors\nการแจกแจงความน่าจะเป็นก่อนหน้าจะเป็นการแจกแจงแบบ conjugacy prior ถ้าการแจกแจงความน่าจะเป็นก่อนหน้าและภายหลังเป็นการแจกแจงภายใน family เดียวกัน ด้วยคุณสมบัติดังกล่าวจึงทำให้การพิสูจน์หาสูตรหรือรูปแบบปิดของการแจกแจงความน่าจะเป็นภายหลังสามารถทำได้โดยที่ไม่ต้องหาเทอม \\(p(D)\\) ที่เป็นตัวส่วนใน Bayes’s rule\nตัวอย่างการแจกแจงก่อนหน้าแบบ conjugacy prior เช่น\nการแจกแจง beta คู่กับ binomial likelihood จะได้ posterior แบบ beta\nการแจกแจง normal คู่กับ normal likelihood จะได้ posterior แบบ normal\n\n\nInformative priors\ninformative prior หรือการแจกแจงความน่าจะเป็นก่อนหน้าแบบมีสารสนเทศ เป็นการแจกแจงความน่าจะเป็นก่อนหน้าที่รูปแบบของการแจกแจงไม่จำเป็นต้องขึ้นกับหรือเกี่ยวข้องกับฟังก์ชันภาวะความควรจะเป็น แต่ขึ้นกับสารสนเทศจากแหล่งอื่น ๆ นอกเหนือจากข้อมูลจริงที่ผู้วิเคราะห์มีเกี่ยวกับพารามิเตอร์ต่าง ๆ ภายในโมเดล สารสนเทศภายในการแจกแจงความน่าจะเป็นก่อนหน้าประเภทนี้อาจเรียกว่า ความรู้ก่อนหน้า (prior knowledge)\nการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าลักษณะนี้จึงมีผลโดยตรงต่อการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ ซึ่งอาจทำให้ผลการรวิเคราะห์ที่ได้มีความถูกต้องมากขึ้น หรืออาจทำให้ผลการวิเคราะห์ที่ได้มีความลำเอียงก็ได้ ขึ้นอยู่กับการออกแบบ informative prior ของผู้วิเคราะห์\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2022-02-05-jags/jags_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2022-02-08T01:04:54+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-03-mcmc-via-jags/",
    "title": "Markov Chain Monte Carlo (MCMC)",
    "description": "มโนทัศน์ของลูกโซ่มาร์คอฟมอนติคาร์โล",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\n\nContents\nMCMC algorithm\nMetropolis algorithm\nExample 1: Tossing coin\nExample 2: One-sample Mean and SD\n\nEfficiency\nการตรวจสอบแนวโน้มการลู่เข้าด้วย Trace plot และ Density plot\nAutocorrelation\nEffective Sample Size (ESS)\nMonte Carlo Standard Error\nPotential Scale Reduction (\\(\\hat{R}\\) หรือ RSRF)\n\n\nMCMC algorithm\nหัวข้อนี้จะกล่าวถึงมโนทัศน์ของลูกโซ่มาร์คอฟมอนติคาร์โล (Monte Carlo Markov Chain: MCMC) ที่เป็นเครื่องมือสำคัญสำหรับประมาณการแจกแจงความน่าจะเป็นภายหลัง (posterior distribution) สำหรับการวิเคราะห์ข้อมูลที่อาศัยแนวคิดแบบเบส์\nแนวคิดเกี่ยวกับ MCMC มีมาค่อนข้างยาวนานประมาณ 40 ปีแล้ว แต่ด้วยข้อจำกัดทั้งด้านโปรแกรมและประสิทธิภาพของคอมพิวเตอร์ทำให้การใช้งานอัลกอริทึม ในสมัยก่อนทำได้ยาก และเกือบจะเป็นไปไม่ได้ที่จะใช้งานอัลกอริทึม MCMC กับปัญหาทางสถิติที่มีความซับซ้อน แต่ด้วยความก้าวหน้าทางเทคโนโลยีในยุคปัจจุบันทำให้ข้อจำกัดดังกล่าวลดลงจนแทบไม่มีอีกต่อไป\nอัลกอริทึม MCMC เป็นอัลกอริทึมที่ใช้สำหรับประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ โดยใช้ตัวอย่างสุ่มที่สร้างจากเทคนิคการจำลองแบบมอนติคาร์โล แทนการพิสูจน์หรือการทดลองแทนค่าเพื่อหาค่าที่ดีที่สุดทางคณิตศาสตร์ คำตอบที่ได้จากอัลกอริทึม MCMC นี้จึงไม่ใช่สูตรหรือฟังก์ชันทางคณิตศาสตร์ แต่จะเป็นตัวอย่างสุ่มของพารามิเตอร์ที่สร้างขึ้น ตัวอย่างดังกล่าวหากมีจำนวนที่มากเพียงพอ จะสามารถใช้เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ และสามารถนำตัวอย่างดังกล่าวมาผ่านกระบวนการทางสถิติเพื่อสร้างข้อสรุปเกี่ยวกับพารามิเตอร์ในโมเดลได้โดยตรง กล่าวโดยสรุปได้ว่าอัลกอริทึม MCMC เป็นเทคนิคที่นำมาประยุกต์ใช้ในการวิเคราะห์ข้อมูลแบบเบส์ เพื่อประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ต่าง ๆ ภายในโมเดล ด้วยตัวอย่างสุ่มของพารามิเตอร์\nรูปต่อไปนี้แสดงการเปรียบเทียบระหว่างการแจกแจงความน่าจะเป็นเชิงทฤษฎี (theoretical/exact distribution) กับการแจกแจงความน่าจะเป็นที่ประมาณด้วยตัวอย่างสุ่มที่สร้างจากเทคนิคการจำลองแบบมอนติคาร์โล\nด้วยเทคนิคการจำลองแบบมอนติคาร์โล ผู้วิเคราะห์สามารถจำลองตัวอย่างสุ่มจากการแจกแจงความน่าจะเป็นใดก็ได้ แต่มีเงื่อนไขว่าต้องทราบฟังก์ชันความน่าจะเป็นของการแจกแจงดังกล่าวก่อน เงื่อนไขนี้เป็นข้อจำกัดที่ทำให้ไม่สามารถใช้เทคนิคการจำลองแบบมอนติคาร์โลแบบปกติได้โดยตรง ทั้งนี้เป็นเพราะในโมเดลที่มีความซับซ้อนระดับหนึ่ง เป็นการยากมากที่ผู้วิเคราะห์จะทราบรูปแบบหรือฟังก์ชันของการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ในโมเดลที่ต้องการใช้งาน\n\n\nShow code\n\nlibrary(scales)\nx<-seq(-3,3,0.01)\npar(mfrow=c(2,3), mar=c(1,5,6,5))\nplot(x, dnorm(x,0,1),type=\"l\", main=\"exact distribution N(0,1)\", xlab=\"X\")\nhist(rnorm(500,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=500\", xlab=\"X\")\nhist(rnorm(1000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=1000\", xlab=\"X\")\nhist(rnorm(5000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=5000\", xlab=\"X\")\nhist(rnorm(10000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=10000\", xlab=\"X\")\nhist(rnorm(50000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=50000\", xlab=\"X\")\n\n\n\n\nMetropolis algorithm\nMetropolis algorithm เป็นกระบวนการสุ่ม (random process/stochastic process) ประเภทหนึ่ง ตั้งชื่ออัลกอริทึมตามคณะผู้พัฒนาได้แก่ Metropolis, Rosenbluth, Rosenbluth, Teller & Teller (1953)\nอัลกอริทึมนี้สามารถนำมาประยุกต์ใช้เพื่อหาการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ โดยปริภูมิของพารามิเตอร์ (parameters space) ดังกล่าวนั้นเป็นไปได้ทั้งแบบไม่ต่อเนื่อง (discrete) และแบบต่อเนื่อง (continuous) และสามารถใช้ได้กับปริภูมิพารามิเตอร์ที่มีมิติตั้งแต่หนึ่งมิติ (unidimensional) ไปจนถึงหลายมิติ (multidimensional) อัลกอริทึม Metropolis มีลักษณะการทำงานแบบทวนซ้ำ (interative) มีรายละเอียดของขั้นตอนวิธีดังนี้\nกำหนดให้ \\(p(\\theta)\\) เป็นการแจกแจงความน่าจะเป็นภายหลังที่ต้องการประมาณ\nสุ่ม/เลือกค่าตั้งต้น (initial values) ของพารามิเตอร์ในการแจกแจงความน่าจะเป็นภายหลัง เขียนแทนด้วย \\(\\theta_0\\) ทั้งนี้ค่าพารามิเตอร์ที่สุ่มมามีเงื่อนไขคือต้องอยู่ภายใต้ปริภูมิของพารามิเตอร์ กล่าวคือ \\(p(\\theta_0)>0\\)\nสร้างค่า proposal jump เพื่อใช้เป็นตัวปรับค่าตั้งต้นของพารามิเตอร์ เขียนแทนด้วย \\(\\Delta\\theta\\) จากการแจกแจงความน่าจะเป็นโครงร่าง (proposal distribution) ที่กำหนดไว้ เช่นอาจกำหนดให้ \\(\\Delta\\theta \\sim N(0, \\sigma)\\) ซึ่งจะได้ proposed values ของพารามิเตอร์ค่าใหม่เขียนแทนด้วย \\(\\theta_{pro}\\) โดยที่ \\(\\theta_{pro}=\\theta_{i-1}+\\Delta\\theta\\) เมื่อ \\(i=1,2,3,...,m\\)\nคำนวณค่าความน่าจะเป็นในการเดิน/เปลี่ยนแปลงของ proposed values ดังนี้ \\(p_{move}=min(1,\\frac{p(\\theta_{pro})}{p(\\theta_{i-1})})\\) โดยที่ \\(p(\\theta_{pro})=p(D|\\theta_{pro}p(\\theta_{pro}))\\) และ \\(p(\\theta_{i-1})=p(D|\\theta_{i-1})p(\\theta_{i-1})\\) จากความน่าจะเป็นข้างต้น จะเห็นว่า ถ้า \\(\\theta_{pro}\\) มีค่าอยู่นอกเหนือค่าที่เป็นไปได้หรือค่าที่ควรจะเป็นของพารามิเตอร์ \\(\\theta\\) ในโมเดล ค่าความน่าจะเป็นก่อนหน้า \\(p(\\theta_{pro})\\) และ/หรือค่าของฟังก์ชันภาวะความควรจะเป็น \\(p(D|\\theta_{pro})\\) จะมีค่าเท่ากับ 0 ซึ่งทำให้ค่า \\(p_{move}=0\\)\nเกณฑ์การพิจารณายอมรับค่า proposed value \\(\\theta_{pro}\\) จะยอมรับด้วยความน่าจะเป็นเท่ากับ \\(p_{move}\\) ในทางปฏิบัติจะสุ่มเลขสุ่มจากการแจกแจงแบบ uniform [0,1] ขึ้นมา 1 ค่า เขียนแทนด้วย \\(u\\) หาก \\(u<p_{move}\\) จะยอมรับค่า \\(theta_{pro}\\) ดังกล่าว แต่ถ้าหาก \\(u > p_{move}\\) จะปฏิเสธค่า \\(\\theta_{pro}\\) ในกรณีนี้ค่าพารามิเตอร์ \\(\\theta_{i-1}\\) ก็จะไม่ได้มีการเปลี่ยนแปลงสถานะ\nอัลกอริทึมข้างต้นเป็นกระบวนการทวนซ้ำโดยจะดำเนินการทวนซ้ำในขั้นตอนที่ 2-4 จนกระทั่งตัวอย่างพารามิเตอร์ \\(\\theta\\) มีจำนวนเพียงพอ และมีคุณสมบัติที่เหมาะสม\nExample 1: Tossing coin\nจากตัวอย่างปัญหาการวิเคราะห์ความเที่ยงตรงของเหรียญ หากต้องการทำ MCMC เพื่อประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ความลำเอียง อาจดำเนินการดังนี้\nกำหนดให้ \\(y_i\\) คือค่าสังเกตของการโยนเหรียญ โดยที่ \\(i=1,2,3...,n\\) และโมเดลของค่าสังเกตดังกล่าวคือ \\(p(y_i|\\theta)=\\theta^y_i(1-\\theta)^{n-y_i}\\) จากการกำหนดนี้จะได้ฟังก์ชันภาวะความควรจะเป็นคือ\n\n\\(p(y|\\theta)=\\theta^{\\sum y_i}(1-\\theta)^{n-\\sum y_i}\\)\n\nและกำหนดให้พารามิเตอร์ \\(\\theta\\) มีการแจกแจงความน่าจะเป็นก่อนหน้าเป็น\n\n\\(p(\\theta)=Beta(\\theta|a,b)\\)\n\nการแจกแจงความน่าจะเป็นแบบ Beta มีธรรมชาติของการแจกแจงคือ ค่าที่เป็นไปได้ของโดเมนอยู่บนช่วง [0,1] ซึ่งสอดคล้องกับธรรมชาติของพารามิเตอร์ความลำเอียงในโมเดลค่าสังเกต\nKruschke, 2015ในกรณีนี้เลือกการแจกแจงความน่าจะเป็นก่อนหน้าเป็น \\(Beta(1,1)\\) ซึ่งจะเห็นว่าเทียบเท่ากับการแจกแจงแบบ uniform ที่หมายถึงผู้วิเคราะห์ไม่ได้มีสารสนเทศเบื้องต้นใด ๆ เกี่ยวกับความลำเอียงของเหรียญที่ทำการศึกษา นอกจากขอบเขตที่เป็นไปได้ของค่าพารามิเตอร์\nจากการกำหนดเงื่อนไขของการศึกษาในข้างต้น จะค่าความน่าจะเป็นในการเปลี่ยนแปลงสถานะหรือ \\(p_{move}\\) เป็น\n\\(p_{move}=min(1,\\frac{p(\\theta_{pro})}{p(\\theta{i-1})})\\)\n\\(=min(1, \\frac{[\\theta_{pro}^{\\sum y_i}(1-\\theta_{pro})^{n-\\sum y_i}] \\times Beta(\\theta_{pro}|1,1)}{[\\theta_{i-1}^{\\sum y_i}(1-\\theta_{i-1})^{n-\\sum y_i}] \\times Beta(\\theta_{i-1}|1,1)})\\)\nเนื่องจากการแจกแจงความน่าจะเป็นแบบ Beta มีฟังก์ชันความน่าจะเป็นคือ \\(p(\\theta|a,b)=\\frac{1}{B(a,b)} \\theta^{a-1}(1-\\theta)^{b-1}\\) โดยที่ \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) และ \\(\\Gamma(.)\\) คือฟังก์ชันแกมมา (Gamma function)\nดังนั้นความน่าจะเป็นในการเปลี่ยนสถานะของ proposed values จะมีค่าเท่ากับ\n\\(p_{move}=min(1,\\frac{\\theta_{pro}^{\\sum y_i+a-1}(1-\\theta_{pro})^{n-\\sum y_i+b-1}/B(a,b)}{\\theta_{i-1}^{\\sum y_i+a-1}(1-\\theta_{i-1})^{n-\\sum y_i+b-1}/B(a,b)})\\)\nสมมุติว่าผู้วิเคราะห์ทำการทดสอบโยนเหรียญ 20 ครั้ง และได้หน้าหัวเท่ากับ 7 ครั้ง\n\n\nShow code\n\ntheta<-0.99 #initial value\nm<-5000 #iteration number\ntheta.dat<-matrix(nrow=m,ncol=3)\nsd.pro<-c(0.02,0.2,2) #learning rate\ncount<-matrix(nrow=m, ncol=3)\n\nfor(j in 1:length(sd.pro))\n  {\n  for(i in 1:m)\n    {\ndelta.theta<-rnorm(1,0,sd.pro[j]) #proposal jump (change)\ntheta.pro<-theta+delta.theta #proposed bias parameter\n\nnom<-theta.pro^(7+1-1)*(1-theta.pro)^(20-7+1-1)\ndenom<-theta^(7+1-1)*(1-theta)^(20-7+1-1)\n\np.move<-min(1,nom/denom)\n\nif(runif(1,0,1)<p.move)\n{theta<-theta.pro\ncount[i,j]<-1\n}else{\n\ntheta<-theta  \ncount[i,j]<-0\n}\ntheta.dat[i,j]<-theta\n  } # end of m iteration\n} # end of sd loop\n\n\n\nจากการดำเนินอัลกอริทึมในข้างต้น พบว่าได้ผลการวิเคราะห์ดังต่อไปนี้\n\n\nShow code\n\npar(mfrow=c(3,3))\nhist(theta.dat[,1], nclass=30, col=alpha(\"#004D80\",0.7), main=\"m=5000, sd=0.02\",\n     xlab=expression(theta))\nhist(theta.dat[,2], nclass=30, col=alpha(\"#004D80\",0.7), main=\"m=5000, sd=0.2\",\n     xlab=expression(theta))\nhist(theta.dat[,3], nclass=30, col=alpha(\"#004D80\",0.7), main=\"m=5000, sd=2\",\n     xlab=expression(theta))\n\nplot(x=theta.dat[4800:5000,1], y=4800:5000, type=\"l\", col=alpha(\"#004D80\",0.7), xlab=expression(theta))\nplot(x=theta.dat[4800:5000,2], y=4800:5000, type=\"l\", col=alpha(\"#004D80\",0.7), xlab=expression(theta))\nplot(x=theta.dat[4800:5000,3], y=4800:5000, type=\"l\", col=alpha(\"#004D80\",0.7), xlab=expression(theta))\n\nplot(x=theta.dat[1:200,1], y=1:200, type=\"l\", col=alpha(\"#004D80\",0.7), xlab=expression(theta))\nplot(x=theta.dat[1:200,2], y=1:200, type=\"l\", col=alpha(\"#004D80\",0.7), xlab=expression(theta))\nplot(x=theta.dat[1:200,3], y=1:200, type=\"l\", col=alpha(\"#004D80\",0.7), xlab=expression(theta))\n\n\n\n\nเราอาจพิจารณาประสิทธิภาพของอัลกอริทึมในข้างต้นจากสัดส่วนของจำนวนค่าพารามิเตอร์ผ่านการยอมรับต่อจำนวน proposed values ของพารามิเตอร์ ซึ่งจะพบว่ามีค่าเท่ากับ\n\n\nShow code\n\ncolSums(count)/5000\n\n\n[1] 0.9348 0.4982 0.0648\n\nExample 2: One-sample Mean and SD\nสมมุตินักวิจัยต้องการประมาณค่าเฉลี่ย IQ ของนักเรียนในโรงเรียนสังกัด สพฐ. ว่ามีค่าสูงกว่าเกณฑ์มาตรฐานคือ 90 คะแนน หรือไม่ ในการวิจัยนักวิจัยได้สร้างแบบวัด IQ และนำไปเก็บรวบรวมข้อมูลจากนักเรียนดังกล่าวจำนวน 3000 คน พบว่ามีคะแนนดังนี้\n\n\nShow code\n\nset.seed(123)\niq<-rnorm(3000,99,10) #IQ sample data\nhist(iq, nclass=30, xlab=\"IQ score\",col=alpha(\"#004D80\",0.7))\n\n\n\n\nจากปัญหาในข้างต้น นักวิจัยได้กำหนดโมเดลของค่าสังเกตด้วยการแจกแจงความน่าจะเป็นแบบปกติ ดังนี้ \\(y_i \\sim N(\\mu,\\ \\sigma)\\) ที่มีฟังก์ชันความน่าจะเป็นคือ\n\\(p(y_i|\\mu,\\ \\sigma)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp\\{-\\frac{1}{2\\sigma^2}(y_i-\\mu)^2\\}\\)\nซึ่งทำให้ได้ว่าฟังก์ชันภาวะความควรจะเป็นของข้อมูลค่าสังเกตเมื่อกำหนดพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\) คือ\n\\(\\Pi_{i=1}^n p(y_i|\\mu,\\sigma)=(\\frac{1}{\\sqrt{2\\pi\\sigma^2}})^nexp\\{-\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\sum_{i=1}^n(y_i-\\mu)^2 \\}\\)\nเนื่องจากพารามิเตอร์ทั้งสองเป็นอิสระซึ่งกันและกัน การกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าให้กับพารามิเตอร์ดังกล่าวจึงสามารถกำหนดแยกจากการได้อย่างอิสระ โดยในตัวอย่างนี้จะกำหนดให้การแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ค่าเฉลี่ยมีการแจกแจงแบบปกติ ที่มีค่าเฉลี่ยเท่ากับ 90 และส่วนเเบี่ยงเบนมาตรฐานเท่ากับ 30 ดังนี้\n\\(p(\\mu|\\mu_p=90, \\sigma_p=30)=\\frac{1}{\\sqrt{2\\pi\\times30^2}}exp\\{-\\frac{1}{2\\times30^2}(\\mu-90)^2 \\}\\)\nและกำหนดให้พารามิเตอร์ความแปรปรวน (\\(\\sigma^2\\) ) มีการแจกแจงความน่าจะเป็นก่อนหน้าเป็นแบบ uniform บนช่วง [0,10000] ซึ่งมีฟังก์ชันความน่าจะเป็นดังนี้\n\\(p(\\sigma^2)=\\frac{1}{10000}\\)\nรูปด้านล่างแสดงโค้งความหนาแน่นของการแจกแจงความน่าจะเป็นก่อนหน้าของ \\(\\mu \\sim N(90,30)\\) และ \\(\\sigma^2 \\sim U(0,10000)\\)\n\n\nShow code\n\npar(mfrow=c(1,2), mar=c(5,5,3,5))\nplot(density(rnorm(100000,90,30)),main=\"\",xlab=expression(mu), col=alpha(\"#004D80\",0.7), lwd=2)\nplot(0:10000, dunif(0:10000,0,10000),main=\"\", xlab=expression(sigma^2), type=\"l\", ylab=\"Density\",\n     ylim=c(0,0.0002), col=alpha(\"#004D80\",0.7), lwd=2)\n\n\n\n\nจากการกำหนดในข้างต้นจะได้ว่าความน่าจะเป็นในการเปลี่ยนสถานะของพารามิเตอร์ทั้งสองมีค่าเท่ากับ\n\\(p.move=min(1,\\frac{p(y|\\mu_{pro},\\sigma_{pro})p(\\mu_{pro},\\sigma_{pro})}{p(y|mu_{i-1},\\sigma_{i-1})p(\\mu_{i-1},\\sigma_{i-1})})\\)\n\\(=min(1,\\frac{p(y|\\mu_{pro},\\sigma_{pro})\\times N(mu_{pro}|90,30) \\times (1/10000)}{p(y|\\mu_{i-1},\\sigma_{i-1})\\times N(mu_{i-1}|90,30) \\times (1/10000)})\\)\nอย่างไรก็ตามจะเห็นว่าความน่าจะเป็นข้างต้นมีสูตรค่อนข้างซับซ้อนและการคำนวณตรง ๆ อาจมีปัญหา ผู้วิเคราะห์จึง take log เข้าที่ความน่าจะเป็นดังกล่าวจึงทำให้เกณฑ์การพิจารณากลายเป็น\n\\(p.move = min(0, [lnp(y|\\mu_{pro},\\sigma_{pro})+lnN(mu_{pro}|90,30)+0]-[lnp(y|\\mu_{i-1},\\sigma_{i-1})+lnN(mu_{i-1}|90,30)+0]\\)\nจากเงื่อนไขข้างต้นสามารถเขียนอัลกอริทึม Metropolis เพื่อประมาณพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\) ได้ดังนี้\n\n\nShow code\n\n#initial value\nmu<-50\nsigma<-30\n\n#iteration number\nm<-5000 \ntheta.dat<-matrix(nrow=m,ncol=6)\nsd.pro<-c(0.05,0.2,2)\ncount<-matrix(nrow=m, ncol=3)\n\nfor(j in 1:length(sd.pro))\n  {\nfor(i in 1:m)\n{\n\ndelta.mu<-rnorm(1,0,sd.pro[j])\ndelta.sigma<-rnorm(1,0,sd.pro[j])\n\n#proposed values\nmu.pro<-mu+delta.mu \nsigma.pro<-sigma+delta.sigma\n\nnom<-sum(dnorm(iq,mean = mu.pro,sd = sigma.pro, log=TRUE))+dnorm(mu.pro,90,30, log=TRUE)\ndenom<-sum(dnorm(iq,mean = mu,sd = sigma, log=TRUE))+dnorm(mu,90,30, log=TRUE)\n\np.move<-min(1,exp(nom-denom))\n\nif(p.move==\"NaN\")\n{\nmu<-mu\nsigma<-sigma\ncount[i,j]<-0\n} else if (runif(1,0,1)<p.move)\n{\nmu<-mu.pro\nsigma<-sigma.pro\ncount[i,j]<-1\n}\nelse\n{\nmu<-mu\nsigma<-sigma\ncount[i,j]<-0\n}\n\ntheta.dat[i,2*j-1]<-mu\ntheta.dat[i,2*j]<-sigma\n  } # end of m iteration\n}#end of sd loop\n\ncolnames(theta.dat)<-c(\"mu_sdpro1\",\"sigma_sdpro1\",\"mu_sdpro2\",\"sigma_sdpro2\",\"mu_sdpro3\",\"sigma_sdpro3\")\n\n\n\nประสิทธิภาพในด้านการยอมรับ proposed value ในแต่ละเงื่อนไขเป็นดังนี้\n\n\nShow code\n\ncolSums(count)\n\n\n[1] 3355 2245   52\n\nการแจกแจงความน่าจะเป็นภายหลังที่ประมาณได้ในตัวอย่างนี้เป็นการแจกแจงความน่าจะเป็นร่วม (joint probability distribution) เนื่องจากมีพารามิเตอร์ 2 ตัวที่ต้องการประมาณค่า รูปต่อไปนี้แสดงการประมาณการแจกแจงความน่าจะเป็นภายหลังจากตัวอย่างสุ่มของพารามิเตอร์ทั้งสองที่สร้างจากอัลอริทึม Metropolis\n\n\nShow code\n\npar(mfrow=c(2,3))\nplot(theta.dat[,1],theta.dat[,2], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=0.005\")\nplot(theta.dat[,3],theta.dat[,4], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=0.02\")\nplot(theta.dat[,5],theta.dat[,6], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=2\")\n\nlibrary(MASS)\nden3d<-kde2d(theta.dat[1000:5000,1],theta.dat[1000:5000,2])\npersp(den3d, box=T,phi=20,theta=-30, xlab=\"mu\", ylab=expression(sigma))\n\nden3d<-kde2d(theta.dat[1000:5000,3],theta.dat[1000:5000,4])\npersp(den3d, box=T,phi=20,theta=50, xlab=expression(mu), ylab=expression(sigma))\n\nden3d<-kde2d(theta.dat[1000:5000,5],theta.dat[1000:5000,6])\npersp(den3d, box=T,phi=20,theta=50, xlab=expression(mu), ylab=expression(sigma))\n\n\n\n\nEfficiency\nจากตัวอย่างในข้างต้น ผู้อ่านจะเห็นว่าตัวอย่างที่สุ่มจากอัลกอริทึม Metropolis ข้างต้นมีลักษณะที่แตกต่างกันออกไปตามลักษณะของ proposal distribution ที่กำหนด\nถ้า proposal distribution มีลักษณะการกระจายที่แคบกว่าการแจกแจงความน่าจะเป็นภายหลัง/การแจกแจงเป้าหมาย ที่ต้องการประมาณมาก กระบวนการสุ่มที่สร้างขึ้นจากอัลกอริทึม Metropolis ในข้างต้นจะสร้างตัวอย่างสุ่มของพารามิเตอร์ที่เป็นตัวแทน ครอบคลุมการแจกแจงความน่าจะเป็นภายหลังที่ต้องการได้ช้า ภายใต้สถานการณ์ดังกล่าว ผู้วิเคราะห์จึงต้องใช้จำนวนการทวนซ้ำที่เพ่ิมจึ้นกว่าปกติเพื่อที่จะได้ตัวอย่างของพารามิเตอร์ที่เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังดังกล่าวได้ ในทางกลับกันหาก proposal distribution มีการกระจายที่กว้างเมื่อเปรียบเทียบกับการแจกแจงความน่าจะเป็นภายหลัง จะทำให้การพัฒนาค่าของพารามิเตอร์ในแต่ละรอบมีการเปลี่ยนแปลงมากเกินไป และอาจไม่สามารถลู่เข้าไปสู่การแจกแจงความน่าจะเป็นภายหลังที่ต้องการได้\nปัจจัยในข้างต้นส่งผลโดยตรงต่อประสิทธิภาพของอัลกอริทึม Metropolis การพิจารณาว่า proposal distribution ดังกล่าวมีความเหมาะสมแล้วหรือไม่ อาจพิจารณาได้จากอัตราส่วนการยอมรับ ซึ่งคำนวณได้จาก จำนวนพารามิเตอร์ที่ได้รับการยอมรับต่อจำนวนการทวนซ้ำทั้งหมด รูปต่อไปนี้แสดงการเปรียบเทียบกระบวนการสุ่มที่สร้างจากอัลกอริทึม MCMC ภายใต้สถานการณ์ที่มีการกำหนดการกระจายของ proposal distribution แตกต่างกัน\n\n\nShow code\n\npar(mfrow=c(1,3))\nplot(theta.dat[,1],theta.dat[,2], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=0.005\")\nplot(theta.dat[,3],theta.dat[,4], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=0.02\")\nplot(theta.dat[,5],theta.dat[,6], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=2\")\n\n\n\n\n\n\nShow code\n\ncolSums(count)/5000\n\n\n[1] 0.6710 0.4490 0.0104\n\nอีกปัจจัยหนึ่งที่ส่งผลกระทบต่อประสิทธิภาพของอัลกอริทึม MCMC คือค่าเริ่มต้น (initial values) ของพารามิเตอร์ กล่าวคือหากผู้วิเคราะห์กำหนดค่าเริ่มต้นที่มีตำแหน่งอยู่ห่างหรืออยู่นอกขอบเขตปกติของค่าพารามิเตอร์จริงในการแจกแจงความน่าจะเป็นภายหลัง จะทำให้กระบวนสุ่มที่สร้างขึ้นมีแนวเดินที่ช้าและใช้จำนวนรอบทวนซ้ำจำนวนมากเพื่อให้ได้ตัวอย่างที่เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ ปรากฏการณ์ดังกล่าวทำให้ตัวอย่างในช่วงแรก ๆ ของกระบวนการสุ่มนั้นยังไม่ใช้ตัวอย่างที่อยู่ภายใต้การแจกแจงความน่าจะเป็นภายหลังที่ต้องการ ในการวิเคราะห์จึงมักมีการตัดตัวอย่างของพารามิเตอร์ในส่วนแรกของการกระบวนการสุ่มออกไปจากการวิเคราะห์จำนวนหนึ่ง เรียกส่วนดังกล่าวว่า burn-in period\nนอกจากนี้ก่อนการนำตัวอย่างของพารามิเตอร์ที่สุ่มได้ไปใช้ในการอนุมานเชิงสถิติต่อไปนั้น ผู้วิเคราะห์จำเป็นต้องตรวจสอบก่อนว่าตัวอย่างดังกล่าวสร้างจากกระบวนการสุ่มที่ลู่เข้าไปสู่การแจกแจงความน่าจะเป็นภายหลังแล้วหรือไม่ การตรวจสอบการลู่เข้านี้มีหลายวิธีการ อย่างไรก็ตามการตรวจสอบดังกล่าวเป็นเพียงการตรวจสอบแนวโน้มการลู่เข้าของกระบวนการสุ่มเท่านั้น แต่ไม่ได้สามารถใช้ยืนยันได้ว่ากระบวนการสุ่มดังกล่าวมีการลู่เข้าไปสู่การแจกแจงความน่าจะเป็นภายหลังจริง ๆ แล้วหรือไม่ วิธีการตรวจสอบ เช่น\nการตรวจสอบแนวโน้มการลู่เข้าด้วย Trace plot และ Density plot\nแผนภาพร่องรอย (trace plot) และแผนภาพโค้งความหนาแน่น (density plot) เป็นเครื่องมือพื้นฐานอย่างแรก ๆ ที่ผู้วิเคราะห์มักใช้พิจารณาแนวโน้มการลู่เข้าของกระบวนการสุ่มที่สร้างจากอัลกอริทึม MCMC รูปด้านล่างแสดงตัวอย่าง Trace plot ในลักษณะที่มีแนวโน้มลู่เข้าและไม่ลู่เข้าสู่การแจกแจงความน่าจะเป็นภายหลัง\n\n\nShow code\n\npar(mfrow=c(3,2))\nplot(theta.dat[,1], type=\"l\", ylab=expression(mu))\nplot(theta.dat[,2], type=\"l\", ylab=expression(sigma))\n\nplot(theta.dat[,3], type=\"l\", ylab=expression(mu))\nplot(theta.dat[,4], type=\"l\", ylab=expression(sigma))\n\nplot(theta.dat[,5], type=\"l\", ylab=expression(mu))\nplot(theta.dat[,6], type=\"l\", ylab=expression(sigma))\n\n\n\n\nDensity plot (และ Histogram) เป็นทัศนภาพอีกประเภทหนึ่งที่ให้สารสนเทศคล้ายคลึงกับ trace plot จุดเด่นคือเป็นแผนภาพที่แสดงรูปทรงการแจกแจงของการแจกแจงความน่าจะเป็นภายหลังที่สร้างขึ้นจากกระบวนการสุ่มด้วย รูปด้านล่างแสดงตัวอย่าง density plot ของตัวอย่างสุ่มพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\)\n\n\nShow code\n\npar(mfrow=c(3,2))\nplot(density(theta.dat[,1]), type=\"l\", xlab=expression(mu), main=\"sd.pro=0.005\")\nplot(density(theta.dat[,2]), type=\"l\", xlab=expression(sigma), main=\"sd.pro=0.005\")\n\nplot(density(theta.dat[,3]), type=\"l\", xlab=expression(mu), main=\"sd.pro=0.02\")\nplot(density(theta.dat[,4]), type=\"l\", xlab=expression(sigma), main=\"sd.pro=0.02\")\n\nplot(density(theta.dat[,5]), type=\"l\", xlab=expression(mu), main=\"sd.pro=2\")\nplot(density(theta.dat[,6]), type=\"l\", xlab=expression(sigma), main=\"sd.pro=2\")\n\n\n\n\nในโปรแกรม R มี package-coda ที่ช่วยอำนวยความสะดวกแก่ผู้วิเคราะห์ในการตรวจสอบ/วินิจฉัยการลู่เข้าของลูกโซ่มาร์คอฟที่สร้างขึ้นจากอัลกอริทึม MCMC\n\n\nShow code\n\n#install.packages(\"coda\")\nlibrary(coda)\n\n\n\nหากตัวอย่างสุ่มของพารามิเตอร์ (ลูกโซ่มาร์คอฟ) ไม่ได้บันทึกไว้ในรูปแบบ mcmc object ผู้วิเคราะห์จำเป็นต้องเปลี่ยนตัวแปรที่บันทึกข้อมูลดังกล่าวให้อยู่ในรูปแบบดังกล่าวด้วยฟังก์ชัน mcmc(x, start=1, end=numeric(0), thin=1)\n\n\nShow code\n\nchain<-mcmc(theta.dat)\nplot(chain)\n\n\n\n\nAutocorrelation\nกระบวนการสุ่มที่สร้างขึ้นจากอัลกอริทึม MCMC จะให้ตัวอย่างสุ่มที่มีความสัมพันธ์ระหว่างกัน ทั้งนี้เป็นเพราะตัวอย่างสุ่มที่สร้างขึ้นใหม่นั้น จะขึ้นกับตัวอย่างที่ถูกสร้างไว้ในรอบก่อนหน้าเสมอ ลักษณะดังกล่าวจึงทำให้เกิดอัตสหสัมพันธ์ขึ้นระหว่างตัวอย่าง หากค่าอัตสหสัมพันธ์ดังกล่าวมีค่าสูงในช่วงที่กว้าง จะส่งผลให้การลู่เข้าของกระบวนการสุ่มทำได้ช้า และตัวอย่างที่สร้างขึ้นไม่สามารถใช้เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังที่ต้องการได้\nค่าอัตสหสัมพันธ์สามารถคำนวณได้โดยใช้สูตรเดียวกับสหสัมพันธ์ของเพียร์สัน โดยเป็นการหาสหสัมพันธ์ระหว่างข้อมูลสองชุด ชุดแรกคือตัวอย่างของพารามิเตอร์ \\(\\theta_m, \\theta_{m-1}, \\theta_{m-2}, ...,\\theta_{2}\\) และชุดที่สองคือตัวอย่างของพารามิเตอร์ที่มีการเหลื่อมค่า 1 ช่วงเวลา \\(\\theta_{m-1}, \\theta_{m-2},...,\\theta_{1}\\) สหสัมพันธ์ระหว่างชุดข้อมูลทั้งสองนี้เรียกว่า อัตสหสัมพันธ์อันดับที่ 1 (lag-1 autocorrelation)\nในทำนองเดียวกัน อัตสหสัมพันธ์ในอันดับที่สูงกว่า 1 สามารถหาได้โดยการเหลื่อมข้อมูลเพิ่มขึ้นเป็น 2, 3, 4 ,… ช่วงเวลา ข้อสังเกตคือยิ่งมีการเหลื่อมช่วงเวลามากขึ้น จำนวนตัวอย่างที่นำมาคำนวณค่าอัตสหสัมพันธ์ก็จะลดลงทีละ 1 หน่วยไปเรื่อย ๆ การวิเคราะห์อัตสหสัมพันธ์ของกระบวนการสุ่มสามารถทำได้สองลักษณะ ลักษณะแรกคือวิเคราะห์จากค่าสถิติโดยตรง และลักษณะที่สองคือใช้แผนภาพอัตสหสัมพันธ์ โดยทั้งสองแบบสามารถทำได้ในโปรแกรม R ด้วย package-coda โดยเขียนคำสั่งดังนี้\n\n\nShow code\n\nautocorr.diag(chain)\n\n\n       mu_sdpro1 sigma_sdpro1   mu_sdpro2 sigma_sdpro2 mu_sdpro3\nLag 0  1.0000000    1.0000000  1.00000000   1.00000000 1.0000000\nLag 1  0.9994292    0.9998234  0.82152505   0.72753970 0.9860251\nLag 5  0.9971468    0.9990995  0.39664748   0.18920770 0.9336869\nLag 10 0.9942847    0.9981647  0.17519306   0.04112503 0.8774738\nLag 50 0.9709985    0.9898665 -0.02851881  -0.02866540 0.5591402\n       sigma_sdpro3\nLag 0     1.0000000\nLag 1     0.9832460\nLag 5     0.9159518\nLag 10    0.8293820\nLag 50    0.4494689\n\nShow code\n\nautocorr.plot(chain)\n\n\n\n\nEffective Sample Size (ESS)\nจากที่กล่าวในข้างต้นจะเห็นว่า ในสถานการณ์ที่กระบวนการสุ่มที่สร้างขึ้นมีอัตสหสัมพันธ์สูง ตัวอย่างสุ่มของพารามิเตอร์จะมีแนวโน้มซ้ำซ้อนกันมาก และทำให้การทวนซ้ำของกระบวนการสุ่มมีประสิทธิภาพต่ำกว่าจำนวนการทวนซ้ำที่กำหนดไว้ กล่าวคือจำนวนรอบทวนซ้ำที่กำหนดไว้อาจไม่เพียงพอที่จะนำไปประมาณการแจกแจงความน่าจะเป็นภายหลัง สถิติที่ช่วยวัดประสิทธิภาพในด้านนี้คือ effective sample size (ESS)\nกำหนดให้ \\(\\theta_1, \\theta_2, \\theta_3, ...,\\theta_m\\) เป็นตัวอย่างสุ่มของพารามิเตอร์ที่สร้างขึ้นจากอัลกอริทึม MCMC และ \\(n_0\\) เป็นระยะห่าง (lag) ที่น้อยที่สุดที่ตัวอย่างสุ่มของพารามิเตอร์มีอัตสหสัมพันธ์เท่ากับหรือใกล้เคียง 0 จากการกำหนดในข้างต้นจะได้ว่า ตัวอย่างสุ่มที่สร้างจากกระบวนการสุ่มข้างต้น และเป็นอิสระซึ่งกันและกันคือ\n\\(\\theta_{n_0}, \\theta_{2n_0}, \\theta_{3n_0},...,\\theta_{T}\\)\nจะเห็นว่าในกรณีที่เกิดอัตสหสัมพันธ์ขึ้น ตัวอย่างที่เป็นอิสระซึ่งกันและกันจะมีจำนวนน้อยกว่าจำนวนตัวอย่างรวม ค่า ESS จึงมีค่าเท่ากับ \\(m/n_0\\)\nการคำนวณค่า ESS ใน R สามารถทำได้โดยใช้ฟังก์ชัน effectiveSize()\n\n\nShow code\n\neffectiveSize(chain)\n\n\n   mu_sdpro1 sigma_sdpro1    mu_sdpro2 sigma_sdpro2    mu_sdpro3 \n   1.4270665    0.4414857  489.8072701  788.4212271   28.6767087 \nsigma_sdpro3 \n  41.3083142 \n\nMonte Carlo Standard Error\n\n\nShow code\n\nsummary(chain)\n\n\n\nIterations = 1:5000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n               Mean      SD Naive SE Time-series SE\nmu_sdpro1    85.068 15.8021 0.223475      13.227925\nsigma_sdpro1 21.291 10.9451 0.154787      16.472555\nmu_sdpro2    99.119  0.1826 0.002582       0.008250\nsigma_sdpro2  9.944  0.1291 0.001825       0.004596\nmu_sdpro3    99.134  0.1512 0.002138       0.028234\nsigma_sdpro3  9.941  0.1132 0.001601       0.017609\n\n2. Quantiles for each variable:\n\n               2.5%    25%    50%   75% 97.5%\nmu_sdpro1    51.757 72.609 91.524 99.09 99.49\nsigma_sdpro1  9.753 10.005 19.253 33.43 36.84\nmu_sdpro2    98.770 99.002 99.116 99.25 99.47\nsigma_sdpro2  9.697  9.855  9.940 10.03 10.20\nmu_sdpro3    98.823 99.077 99.176 99.24 99.38\nsigma_sdpro3  9.693  9.879  9.948 10.01 10.15\n\n\\(SE_{naive}=\\sqrt{\\frac{Var(\\theta)}{m}}\\)\n\\(SE_{ts}=\\sqrt{\\frac{Var_{ts}(\\theta)}{m}}\\) โดยที่ \\(Var(\\theta)=\\frac{\\sigma^2}{(1-\\sum_{k=1}^K\\rho_k)^2}\\)\n\\(\\sigma^2\\) เป็นความแปรปรวนของความคลาดเคลื่อนสุ่มที่ประมาณจากโมเดล autoregressive (AR) อันดับที่ K ส่วน \\(\\rho_k\\) คือค่าสัมประสิทธิ์อัตสหสัมพันธ์อันดับที่ \\(k\\)\nPotential Scale Reduction (\\(\\hat{R}\\) หรือ RSRF)\nการตรวจสอบการลู่เข้าของลูกโซ่มาร์คอฟด้วยวิธีการที่กล่าวมา แม้จะได้ผลลัพธ์ว่ามีแนวโน้มที่ตัวอย่างลูกโซ่จะลู่เข้าไปสู่การแจกแจงใดการแจกแจงหนึ่ง แต่ก็ยังไม่สามารถยืนยันได้ว่าการแจกแจงดังกล่าวเป็นการแจกแจงเป้าหมายที่แท้จริงหรือไม่\nวิธีการหนึ่งที่ช่วยเพิ่มหลักฐานและเสริมความมั่นใจให้กับผู้วิเคราะห์ว่า ตัวอย่างลูกโซ่ที่สร้างขึ้นมีการแจกแจงที่ลู่เข้าไปหาการแจกแจงความน่าจะเป็นภายหลังที่ต้องการจริง ๆ คือ การสร้างตัวอย่างลูกโซ่หลาย ๆ ชุด โดยกำหนดค่าเริ่มต้นให้แตกต่างกัน จากนั้นสังเกตผลลัพธ์ที่ได้ หากตัวอย่างทุกชุดมีแนวโน้มที่ลู่เข้าไปหาการแจกแจงเดียวกัน ผู้วิเคราะห์จะมีหลักฐานที่สนับสนุนให้เชื่อได้ว่าตัวอย่างสุ่มที่สร้างขึ้นจากอัลกอริทึม MCMC ลู่เข้าไปหาการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ\nการวิเคราะห์การลู่เข้านี้สามารถวิเคราะห์ได้จากทั้ง trace plot และ density plot และใช้ค่าสถิติ potential scale reduction (\\(\\hat{R}\\)) สถิตินี้มีค่าเท่ากับอัตราส่วนระหว่างความแปรปรวนรวม (total variance) ของตัวอย่างลูกโซ่ต่อความแปรปรวนภายลูกโซ่ (within-chain variance) ดังนี้\n\\(\\hat{R}=\\sqrt{\\frac{Var(\\theta)}{W}}\\)\nโดยที่ \\(Var(\\theta)=(1-\\frac{1}{m}W+\\frac{1}{m}B)\\)\n\\(W=\\frac{1}{C}\\sum_{j=1}^CS^2_j\\)\n\\(S^2_j=\\frac{1}{n-1}\\sum_{i=1}^n(\\theta_{ij}-\\overline{\\theta}_{.j})^2\\)\n\\(B = \\frac{n}{C-n}\\sum_{j=1}^C(\\overline{\\theta}_j-\\overline{\\theta}_{..})\\)\nจากสูตรของ \\(\\hat{R}\\) ข้างต้นจะเห็นว่า ถ้า \\(\\hat{R} \\approx 1\\) นั่นหมายความว่าตัวอย่างลูกโซ่ที่สร้างขึ้นแต่ละชุด มีการแจกแจงที่ใกล้เคียงกัน กล่าวคือตัวอย่างลูกโซ่ที่สร้างขึ้นมีคุณสมบัติลู่เข้าไปยังการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ แต่ถ้าหาก \\(\\hat{R}>1\\) บ่งชี้ว่าตัวอย่างลูกโซ่ที่สร้างขึ้นมีการลู่ออก\nเกณฑ์การพิจารณา \\(\\hat{R}<1.1\\)\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2022-02-03-mcmc-via-jags/mcmc-via-jags_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-02-05T22:42:09+07:00",
    "input_file": {}
  }
]
