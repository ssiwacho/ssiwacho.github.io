---
title: "GLM1"
categories:
  - Bayesian Statistics
  - BGLM
description: |
  General Linear Modeling
author:
  - name: Siwachoat Srisuttiyakorn
    url: {}
date: 2022-02-19
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Bayesian alternative to t-test

กิจกรรมนี้จะกล่าวถึงการใช้สถิติแบบเบส์สำหรับการวิเคราะห์เพื่อเปรียบเทียบค่าเฉลี่ยสองกลุ่ม ผู้อ่านจะเห็นว่าการวิเคราะห์แบบเบส์เป็นวิธีการที่ให้สารสนเทศเกี่ยวกับความแตกต่างของค่าเฉลี่ยระหว่างตัวอย่างสองกลุ่มที่มากกว่าการทดสอบ t-test แบบดั้งเดิม

การเปรียบเทียบด้วยวิธีการแบบเบส์ทำให้ผู้วิเคราะห์สามารถประมาณการแจกแจงความน่าจะเป็นภายหลัง ซึ่งเป็นข้อมูลสำคัญสำหรับการคำนวณช่วงความน่าเชื่อถือ (credible intervals) ของพารามิเตอร์ต่าง ๆ ได้แก่ ค่าเฉลี่ย ส่วนเบี่ยงเบนมาตรฐาน รวมทั้งความแตกต่างระหว่างค่าเฉลี่ย ส่วนเบี่ยงเบนมาตรฐาน และขนาดอิทธิพล 

ผลการทดสอบเพื่อเปรียบเทียบความแตกต่างของค่าเฉลี่ยสามารถตัดสินใจได้ทั้ง การยอมรับสมมุติฐานหลัก (accept null hypothesis) และยอมรับสมมุติฐานทางเลือก (accept alternative hypothesis) ซึ่งแตกต่างและมีความยืดหยุ่นมากกว่าการทดสอบเพื่อเปรียบเทียบค่าเฉลี่ยแบบดั้งเดิมอย่างมาก

### Traditional Independent-sample t-test

สมมุติว่านักวิจัยต้องการเปรียบเทียบความแตกต่างของผลสัมฤทธิ์ทางการเรียนวิชาคณิตศาสตร์ และทักษะการแก้ปัญหา ระหว่างนักเรียนที่ได้รับการสอนแบบบรรยาย และแบบใช้ปัญหาเป็นฐาน ข้อมูลค่าสังเกตเป็นดังนี้

```{r echo=TRUE}
set.seed(1253)
dat<-data.frame(Ach=c(rnorm(50,50,5),rnorm(50,48,15)),
                Solve=c(rt(50,3,0)*5+50,rt(50,3,0)*10+70),
                Method=c(rep(1,50),rep(2,50)))
head(dat)
tail(dat)
summary(dat)
```

โดยที่ `Ach` และ `Solve` คือผลสัมฤทธ์และทักษะการแก้ปัญหาตามลำดับ ส่วน `TMethod = 1` คือกลุ่มนักเรียนที่ได้รับการสอนแบบบรรยาย และ `TMethod = 2` คือกลุ่มนักเรียนที่ได้รับการสอนแบบใช้ปัญหาเป็นฐาน

```{r layout="l-body-outset",fig.height=4, fig.width=9, echo=T}
par(mfrow=c(1,2))
plot(density(dat$Ach[1:50]),type="l", main="Ach", xlim=c(0,100), lty=1)
points(density(dat$Ach[51:100]),type="l", main="", lty=2)
legend(0,0.06, legend=c("LEC","PBL"),lty=c(1,2), bty="n")

plot(density(dat$Solve[1:50]),type="l", main="Solve", xlim=c(0,100), lty=1)
points(density(dat$Solve[51:100]),type="l", main="", lty=2)
legend(0,0.04, legend=c("LEC","PBL"),lty=c(1,2), bty="n")

```


หากทำการวิเคราะห์ด้วยสถิติทดสอบ t-test แบบดั้งเดิม พบว่าได้ผลการวิเคราะห์ดังนี้

```{r}
t.test(Ach~Method, data=dat)
t.test(Solve~Method, data=dat)
```

ผลการวิเคราะห์ที่ได้จาก t-test ข้างต้นให้สารสนเทศใดแก่ผู้วิเคราะห์บ้าง?


### Bayesian approach 1

การเปรียบเทียบค่าเฉลี่ยด้วยวิธีการแบบเบส์สามารถทำได้หลายวิธีการ วิธีการหนึ่งที่สามารถทำได้อาจกำหนดโมเดลดังรูปด้านล่าง


![](/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-19-glm1/model1.png)


จากรูปจะเห็นว่ามีการกำหนดโมเดลให้กับค่าสังเกตในแต่ละกลุ่มเป็นการแจกแจงแบบปกติที่มีค่าเฉลี่ยเท่ากับ $\mu_1$ และ $\mu2$ และพารามิเตอร์ความเที่ยงตรงเท่ากับ $\tau_1$ และ $\tau_2$ ตามลำดับ และได้มีการกำหนดการแจกแจงความน่าจะเป็นเบื้องต้นให้กับพารามิเตอร์ต่าง ๆ ของโมเดลค่าสังเกต โดยพารามิเตอร์ค่าเฉลี่ยมีการแจกแจงความน่าจะเป็นเบื้องต้นเป็นการแจกแจงแบบปกติ ส่วนพารามิเตอร์ความเที่ยงตรงมีการแจกแจงความน่าจะเป็นเบื้องต้นเป็นแบบแกมมา (Gamma distribution)


การแจกแจงแบบแกมมา มีพารามิเตอร์กำกับการแจกแจง 2 ตัวได้แก่ shape และ rate parameters ซึ่งเขียนแทนด้วยสัญลักษณ์ $\alpha>0$ และ $\beta >0$ และมีฟังก์ชันความน่าจะเป็นดังนี้

$p(\theta)=\frac{\beta^{\alpha}}{\Gamma(\alpha)}\theta^{\alpha-1}exp\{-\beta \theta \}$ โดยที่ $\theta>0$

รูปต่อไปนี้แสดงตัวอย่างการแจกแจงความน่าจะเป็นแบบแกมมา เมื่อกำหนดพารามิเตอร์เป็นค่าต่าง ๆ 

```{r layout="l-body-outset",fig.height=4, fig.width=9, echo=T}
par(mfrow=c(1,2), mar=c(5,5,1,1))
theta<-seq(0,5,0.01)
plot(theta, dgamma(theta,1,1), type="l", col=2, ylab="Density", xlab=expression(tau))
points(theta, dgamma(theta,2,1), type="l", col=3)
points(theta, dgamma(theta,3,1), type="l", col=4)
points(theta, dgamma(theta,5,1), type="l", col=5)

plot(theta, dgamma(theta,1,2), type="l", col=2, ylab="Density", xlab=expression(tau))
points(theta, dgamma(theta,1,4), type="l", col=3)
points(theta, dgamma(theta,1,6), type="l", col=4)
points(theta, dgamma(theta,1,10), type="l", col=5)
```

แนวทางการกำหนดค่าพารามิเตอร์ในการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ความเที่ยงตรง ($\tau$) การทำได้สองลักษณะ ลักษณะแรกคือ noninformative prior อาจกำหนดให้พารามิเตอร์ $\alpha$ และ $\beta$ มีค่าน้อย ๆ เช่น `dgamma(0.01,0.01)` หรือ `dgamma(0.001,0.001)` รูปด้านล่างแสดงตัวอย่างของการแจกแจงดังกล่าว

```{r}
theta<-seq(0,5,0.01)
plot(theta, dgamma(theta,0.01,0.01), type="l", col=2, ylab="Density", xlab=expression(tau))

```

อีกลักษณะหนึ่งคือการกำหนดให้มีสารสนเทศในการแจกแจงความน่าจะเป็นก่อนหน้า โดยอาจมองว่าพารามิเตอร์ $\alpha$ มีค่าเท่ากับฐานนิยมของ $\tau$ และ $\beta$ มีค่าเท่ากับส่วนเบี่ยงเบนมาตรฐานของ $\tau$ (Kruschke, 2012)

### กิจกรรม 1

ดำเนินการวิเคราะห์ข้อมูลเพื่อเปรียบเทียบค่าเฉลี่ยผลสัมฤทธิ์และทักษะการแก้ปัญหาทางคณิตศาสตร์ ระหว่างกลุ่มนักเรียนที่ได้รับการสอนแบบบรรยายและใช้ปัญหาเป็นฐาน ด้วยวิธีการแบบเบส์ โดยใช้การกำหนดโมเดลข้างต้น แล้วตอบคำถามต่อไปนี้

- ตัวอย่างพารามิเตอร์ที่จำลองจากอัลกอริทึม MCMC มีคุณสมบัติที่เหมาะสมสำหรับนำไปวิเคราะห์เพื่อตอบคำถามข้างต้นหรือไม่ เพราะเหตุใด

- ผลการวิเคราะห์เพื่อเปรียบเทียบความแตกต่างของผลสัมฤทธิ์และทักษะการแก้ปัญหาทางคณิตศาสตร์ระหว่างกลุ่มนักเรียนทั้งสองกลุ่มเป็นอย่างไร?

- สารสนเทศที่ได้จากการวิเคราะห์ด้วยสถิติแบบเบส์ กับสถิติแบบดั้งเดิมมีความแตกต่างกันอย่างไร

### Bayesian approach 2

การกำหนดโมเดลสำหรับวิเคราะห์ข้อมูลด้วยสถิติแบบเบส์สามารถกำหนดได้อย่างหลากหลาย กล่าวคือในปัญหาเดียวกันหากผู้วิเคราะห์มีมุมมองหรือกรอบแนวคิดที่แตกต่างกันก็สามารถกำหนดโมเดลการวิเคราะห์ที่แตกต่างกันได้ รูปด้านล่างแสดงการกำหนดโมเดลสำหรับเปรียบเทียบค่าเฉลี่ยสองกลุ่มในอีกลักษณะหนึ่ง


![](/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-19-glm1/model2.png)
เมื่อเปรียบเทียบกับโมเดลที่ 1 ที่ได้ดำเนินการวิเคราะห์ไปแล้ว นิสิตคิดว่าโมเดลนี้มีความเหมือนและแตกต่างไปจากเดิมอย่างไรบ้าง?

ทั้งนี้การแจกแจงความน่าจะเป็นแบบทีดังกล่าวเป็นอีก version หนึ่งเรียกว่า Generalized student's t distribution ซึ่งมีพารามิเตอร์กำกับการแจกแจง 3 ตัวได้แก่ ค่าเฉลี่ย ส่วนเบี่ยงเบนมาตรฐาน และองศาความเป็นอิสระ ($\nu>0$) และมีฟังก์ชันความน่าจะเป็นดังนี้

$p(y|\mu, \sigma, \nu)=\frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})\sqrt{\pi\nu}\sigma}(1+\frac{1}{\nu}(\frac{y-\mu}{\sigma})^2)^{-\frac{\nu+1}{2}}$

การเลิือกใช้การแจกแจงแบบทีเป็นโมเดลค่าสังเกตมีข้อดีกว่าการแจกแจงแบบปกติคือ การแจกแจงแบบทีเป็นการแจกแจงที่มีส่วนปลาย (หาง) ของการแจกแจงที่หนากว่าการแจกแจงแบบปกติ ซึ่งทำให้โมเดลของค่าสังเกตมีความแกร่งต่อการเกิดค่าผิดปกติ (outlier) มากกว่าโมเดลที่ใช้การแจกแจงแบบปกติ ความหนา ณ ส่วนปลายของการแจกแจงแบบทีสามารถกำหนดผ่านค่าพารามิเตอร์องศาความเป็นอิสระ ($\nu$) โดยถ้า $\nu$ ยิ่งมีค่าน้อย การแจกแจงทีจะยิ่งมีส่วนปลายที่หนาขึ้น ในทางกลับกันหาก $\nu$ มีค่ามาก การแจกแจงทีดังกล่าวจะลู่เข้าหาการแจกแจงแบบปกติ กล่าวได้ว่าโมเดลนี้เป็นกรณีทั่วไปของ model 1 ที่ได้กล่าวไว้ก่อนหน้านี้นั่นเอง รูปต่อไปนี้แสดงฟังก์ชันความหนาแน่นของการแจกแจงความน่าจะเป็นแบบที เมื่อมีองศาความเป็นอิสระต่าง ๆ กัน


```{r echo=TRUE}
par(mar=c(5,5,1,1))
x<-seq(-6,6,0.01)
plot(x, dnorm(x,0,1), type="l", lty=1, ylab="Density")
points(x, dt(x,1), type="l",lty=2)
points(x, dt(x,2), type="l",lty=3)
points(x, dt(x,3), type="l",lty=4)
points(x, dt(x,5), type="l",lty=5)
points(x, dt(x,10), type="l",lty=6)

text(0,0.1, "t-Distribution")
text(2, 0.38, "Normal Distriibution")
```

นอกจากการกำหนดโมเดลการวิเคราะห์ทั้งสอง ผู้วิเคราะห์ยังสามารถกำหนดโมเดลการวิเคราะห์อื่น ๆ ได้อย่างหลากหลาย ทั้งนี้ต้องคำนึงถึงธรรมชาติของข้อมูลและพารามิเตอร์ภายในโมเดลการวิเคราะห์ เช่น หากผู้วิเคราะห์สำรวจข้อมูลแล้วพบว่าข้อมูลคะแนนค่าสังเกตที่ต้องการนำมาวิเคราะห์มีการแจกแจงที่เบ้ขวา (positively skewed) ผู้วิเคราะห์อาจกำหนดโมเดลของค่าสังเกตเป็นการแจกแจงแบบ log-normal โดยอาจเขียนคำสั่งดังนี้


```{r echo=T, eval=F}
model{
  for(i in 1:n)
  {
    #log-normal likelihood
    y[i]~dlnorm(log(mu[x[i]]),tau[x[i]])
  }
  
  for(j in 1:2)
  {
    mu[j]~dnorm(m,t)
    tau[j]~dgamma(a,b)
  }
}

```


### กิจกรรม 2

ดำเนินการวิเคราะห์ข้อมูลเพื่อเปรียบเทียบค่าเฉลี่ยผลสัมฤทธิ์และทักษะการแก้ปัญหาทางคณิตศาสตร์ ระหว่างกลุ่มนักเรียนที่ได้รับการสอนแบบบรรยายและใช้ปัญหาเป็นฐาน ด้วยวิธีการแบบเบส์ โดยใช้การกำหนดโมเดลข้างต้น แล้วตอบคำถามต่อไปนี้

- ตัวอย่างพารามิเตอร์ที่จำลองจากอัลกอริทึม MCMC มีคุณสมบัติที่เหมาะสมสำหรับนำไปวิเคราะห์เพื่อตอบคำถามข้างต้นหรือไม่ เพราะเหตุใด

- ผลการวิเคราะห์เพื่อเปรียบเทียบความแตกต่างของผลสัมฤทธิ์และทักษะการแก้ปัญหาทางคณิตศาสตร์ระหว่างกลุ่มนักเรียนทั้งสองกลุ่มเป็นอย่างไร?

- ระหว่างโมเดล 1 กับโมเดล 2 โมเดลใดเป็นโมเดลที่เหมาะสมมากกว่า เพราะเหตุใด

## Posterior Predictive Check

posteior predictve check เป็นการตรวจสอบความสอดคล้องเชิงประจักษ์ของโมเดลการวิเคราะห์ ด้วยการเปรียบเทียบกันระหว่างค่าทำนายของตัวแปรตามที่ได้จากโมเดลกับค่าสังเกตจริงจากข้อมูลตัวอย่าง 



```{r echo=TRUE}
twosamples=
"model{
  #likelihood function
  for(i in 1:n)
  {
    y[i]~dnorm(mu[x[i]],tau[x[i]])
  }
  
  for (j in 1:2)
  {
  #prior distribution
  mu[j]~dnorm(0,0.01)
  tau[j]~dgamma(0.01,0.01)
  
  #deterministic nodes
  sigma[j]<-sqrt(1/tau[j])
  }
  
}"
library(rjags)
library(runjags)
library(coda)
dataList<-list(y=dat$Ach, x=dat$Method, n=dim(dat)[1])
fit<-run.jags(method="rjparallel",
                        model=twosamples,
                        monitor=c("mu","sigma"),
                        data=dataList,
                        n.chains=3,
                        sample = 10000,
                        thin=3,
                        summarise=TRUE,
                        plots=FALSE,
                        keep.jags.files = FALSE)

```

ขั้นตอนต่อไปนี้แสดงการสร้าง predictive value จาก posterior distribution โดยสุ่มเลือกค่าพารามิเตอร์ขึ้นมา 1000 ชุด เพื่อสร้าง posterior predictive distribution จำนวน 1000 ชุด โดยที่แต่ละชุดมีค่าสังเกตผลสัมฤทธิ์ทางการเรียนจำนวน 100 ค่า เหมือนกับข้อมูลตัวอย่างตั้งต้น

```{r layout="l-body-outset",fig.height=4, fig.width=9, echo=T}
sample<-as.mcmc.list(fit)
sample<-as.matrix(sample)
dim(sample)
param.id<-sample(1:30000,1000)
sample<-sample[param.id,]

y.rep<-matrix(nrow=100,ncol=1000)
for(i in 1:1000)
{
y1<-rnorm(50, sample[,1], sample[,3])
y2<-rnorm(50, sample[,2], sample[,4])
y.rep[,i]<-c(y1,y2)
}

### example of posterior predictive distribution

par(mfrow=c(4,4), mar=c(1,1,1,1))
for(i in 1:16)
{
  hist(y.rep[,i], col="skyblue", border="white", main="", nclass=30)
}
```

การใช้งาน posterior predictive distribution คือการพิจารณาว่าการแจกแจง predictive ดังกล่าวมีความลำเอียงไปจากการแจกแจงของข้อมูลค่าสังเกตอย่างมีนัยสำคัญหรือไม่ รูปต่อไปนี้แสดงการเปรียบเทียบระหว่าง posterior predictive ที่สร้างขึ้นกับข้อมูลจริง


```{r}
hist(dat$Ach, col="skyblue", border="white", main="", nclass=30, xlab="Ach", freq=F)
for (i in 1:10)
{
  points(density(y.rep[,i]), type="l", lty=2, cex=0.5, col="black")
}
```

นอกจากการตรวจสอบด้วย visualization ในข้างต้นแล้ว ยังสามารถเปรียบเทียบ posterior predictve กับข้อมูลจริงด้วยค่าสถิติ เช่น


### Posterior Predictive P-value (PPP)

bayesian p-value เป็นวิธีการหนึ่งที่ใช้นำเสนอความแตกต่างระหว่างค่าสังเกตจริงกับค่าทำนายของโมเดล การคำนวณค่า bayesian p-value สามารถทำได้หลายลักษณะขึ้นอยู่กับค่าสถิติที่เลือกใช้ นิยามของค่า PPP เป็นดังนี้

$PPP = P(T(y^{rep}) \geq T(y))$

เมื่อ $T(.)$ คือ discrepancy measures หรือ test quantiles ที่จะใช้เป็นตัวเปรียบเทียบระหว่างการแจกแจงของ posterior predictive กับ observed value การกำหนด test quantile ดังกล่าวสามารถทำได้หลายลักษณะและไม่ได้มีกฎเกณฑ์ตายตัว ขึ้นอยู่กับว่าผู้วิเคราะห์ต้องการสารสนเทศในเชิงการเปรียบเทียบแบบใด ค่า test quantile ที่มักใช้ได้แก่ ค่าต่ำสุด ค่าสูงสุด ค่าเฉลี่ย และส่วนเบี่ยงเบนมาตรฐาน ตัวอย่างต่อไปนี้แสดงการคำนวณค่า PPP ข้างต้น

```{r}
library(dplyr)
Tmax.y<-max(dat$Ach)
Tmax.yrep<-apply(y.rep,2,max)
hist(Tmax.yrep, col="skyblue", xlab="max Y.rep", border="white", nclass=30)
abline(v=Tmax.y, col="red", lty=1)

ppp<-table(Tmax.yrep>Tmax.y)%>%prop.table()
ppp[2] #PPP value
```


```{r}
Tmin.y<-min(dat$Ach)
Tmin.yrep<-apply(y.rep,2,min)
hist(Tmin.yrep, col="skyblue", xlab="max Y.rep", border="white", nclass=30)
abline(v=Tmin.y, col="red", lty=1)

ppp<-table(Tmin.yrep>Tmin.y)%>%prop.table()
ppp[2] #PPP value
```

จากนิยามของ PPP ข้างต้นจะเห็นว่าหาก PPP มีค่าเข้าใกล้ 0 หรือ 1 นั่นหมายความว่าโมเดลการวิเคราะห์สร้าง predictive value ที่มีความแตกต่าง/ลำเอียง ไปจากข้อมูลจริงอย่างมาก ดังนั้น PPP = 0.5 จึงหมายความว่าโมเดลมีความสอดคล้องกับข้อมูลจริงอย่างสมบูรณ์  ในทางปฏิบัติไม่ได้มีการกำหนด cut-off ไว้แน่นอน แต่ค่า cut-off ที่มักใช้กันคือ PPP<0.05,0.1 หรือ PPP>0.90,0.95 


## Bayesian Alternative to ANOVA

นักวิจัยทดลองใช้วิธีการสอน 4 วิธี กับนักเรียนจำนวน 4 กลุ่มที่มีการวิเคราะห์แล้วว่ามีพื้นฐานใกล้เคียงกัน เมื่อสอนจบตามแผนแล้วมีการวัดผลการเรียนรู้ภายหลัง ได้ผลดังนี้

```{r}
library(kableExtra)
lec<-c(5,6,7,3,7,5,2,4)
pbl<-c(11,8,7,7,9,7,8,10)
cop<-c(6,9,8,5,4,4,7,6)
dem<-c(3,4,1,1,4,5,2,3)

dat<-data.frame(lec, pbl, cop ,dem)
kable(dat)
```

โมเดลการวิเคราะห์ความแปรรปวนทางเดียวสามารถเขียนได้สองลักษณะ ลักษณะแรกเรียกว่า mean model เขียนได้ดังนี้

$y_{ij}=\mu_j+\epsilon_{ij}$ 

อีกลักษณะหนึ่งคือ effect model

$y_{ij}=\mu+\alpha_j+\epsilon_{ij}$ เมื่อ $\sum_{j=1}^J\alpha_j=0$ 

รูปด้านล่างแสดงโมเดลค่าสังเกตแบบ effect model 

![](/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-19-glm1/bnova.png){width=40%}
### กิจกรรม 3

- วิเคราะห์ ANOVA เพื่อเปรียบเทียบค่าเฉลี่ยของชุดข้อมูลข้างต้น

- วิเคราะห์ BANOVA เพื่อเปรียบเทียบค่าเฉลี่ยของชุดข้อมูลข้างต้น

- ผลการวิเคราะห์จากทั้งสองวิธีให้สารสนเทศที่เหมือนหรือแตกต่างกันอย่างไร?


## Multiple Regression




---


Distill is a publication format for scientific and technical writing, native to the web.

Learn more about using Distill at <https://rstudio.github.io/distill>.


