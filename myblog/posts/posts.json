[
  {
    "path": "posts/2022-02-05-jags/",
    "title": "Introduction to JAGS",
    "description": "การใช้งาน JAGS เบื้องต้น",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": {}
      }
    ],
    "date": "2022-02-04",
    "categories": [],
    "contents": "\n\nContents\nติดต้ังโปรแกรม\nการเขียนคำสั่งใน JAGS\nการนำเข้าและจัดการข้อมูล\nการระบุโมเดล\nโมเดลของค่าสังเกต\nการแจกแจงความน่าจะเป็นก่อนหน้า\nสภาพแวดล้อมของ JAGs\n\nการประมวลผล\nระบุ JAGs โมเดล\nสั่งประมวลผล\n\n\n\nผู้อ่านได้ทำความเข้าใจมโนทัศน์เกี่ยวกับอัลกอริทึม MCMC แล้ว อย่างไรก็ตามจะเห็นว่าการเขียนอัลกอริทึมดังกล่าวค่อนข้างลำบาก และมีโอกาสสูงที่จะเกิดความผิดพลาด ปัจจุบันมีโปรแกรมสำเร็จรูปหลายตัวที่ช่วยให้ผู้วิเคราะห์สามารถประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ภายในโมเดลใด ๆ ได้อย่างสะดวกมากยิ่งขึ้น บทเรียนนี้จะกล่าวถึงโปรแกรม JAGS (Just Another Gibb Sampler) รายละเอียดมีดังนี้\nติดต้ังโปรแกรม\nนิสิตสามารถ เข้าไปดาวน์โหลดโปรแกรม JAGS (Just Another Gibb Sampler) ได้ที่\nhttps://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/\nการใช้งาน JAGS ในข้างต้นจะไม่ได้ใช้งานแบบ standard alone แต่จะใช้งานผ่านโปรแกรม R โดยผู้ใช้จำเป็นต้องดาวน์โหลด package เสริมอีก 2 ตัวได้แก่ rjags และ runjags ดังนี้\n\n\ninstall.packages(\"rjags\", dependencies = TRUE)\ninstall.packages(\"runjags\", dependencies = TRUE)\n\n\n\nก่อนใช้งาน package ทั้งสองผู้ใช้จำต้องเรียกใช้ package ดังกล่าวก่อนโดยพิมพ์คำสั่งดังนี้\n\n\nlibrary(rjags)\nlibrary(runjags)\n\n\n\nกระบวนการทำงานร่วมกันระหว่าง R กับ JAGSการเขียนคำสั่งใน JAGS\nการเขียนคำสั่งต่าง ๆ จะทำบนโปรแกรม R ทั้งหมด โดยอาจแบ่งขั้นตอนการดำเนินงานออกเป็น 4 ขั้นตอนได้แก่ การนำเข้าและจัดการข้อมูล การระบุโมเดล การประมวลผล และการตรวจสอบและวิเคราะห์ผลลัพธ์ที่ได้ รายละเอียดมีดังนี้\nการนำเข้าและจัดการข้อมูล\nข้อมูลตัวอย่างผลสัมฤทธิ์ทางการเรียนวิชา calculas ของนิสิตจำนวน 100 คน บันทึกอยู่ในไฟล์ชื่อ bayes_exam1.csv ทั้งนี้เมื่อดาวน์โหลดข้อมูลมาแล้วสามารถนำเข้าสู่ R ได้โดยเขียนคำสั่งดังนี้\n\n\nlibrary(dplyr)\ndat<-read.csv(\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/bayes_exam1.csv\")\nglimpse(dat)\n\n\nRows: 100\nColumns: 2\n$ id  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ CAL <dbl> 68.8, 89.8, 40.0, 61.2, 8.8, 59.0, 57.5, 65.8, 50.9, 79.…\n\nการระบุโมเดล\nวัตถุประสงค์ของการวิเคราะห์มี 2 ข้อ ได้แก่\nเพื่อวิเคราะห์ระดับผลสัมฤทธิ์ทางการเรียนวิชา calculas ของนิสิต\nเพื่อวิเคราะห์ว่าค่าเฉลี่ยผลสัมฤทธิ์วิชา calculas ของนิสิตมีค่าสูงกว่า 50 คะแนนหรือไม่\nจากวัตถุประสงค์การวิเคราะห์และข้อมูลค่าสังเกตที่มี สามารถระบุโมเดลการวิเคราะห์ได้ดังนี้\nโมเดลของค่าสังเกต\nกำหนดให้โมเดลของคะแนนผลสัมฤทธิ์ (\\(y_i\\)) มีการแจกแจงแบบปกติที่มีค่าเฉลี่ยและความแปรปรวนเท่ากับ \\(\\mu\\) และ \\(\\sigma^2\\) ตามลำดับ เขียนแทนด้วย \\(y_i \\sim N(\\mu,\\sigma^2)\\) อย่างไรก็ตามในโปรแกรม JAGS จะไม่ได้ใช้พารามิเตอร์ความแปรปรวนเป็นพารามิเตอร์ของการแจกแจงแบบปกติ แต่ละใช้พารามิเตอร์ความเที่ยงตรง (precision parameter) ซึ่งเป็นส่วนกลับของพารามิเตอร์ความแปรปรวนแทน ดังนั้นโมเดลค่าสังเกตในกรณีนี้สามารถเขียนได้ดังนี้\n\\(y_i \\sim N(\\mu, \\tau=1/\\sigma^2)\\)\nจากโมเดลค่าสังเกตข้างต้นจะได้ ฟังก์ชันภาวะความควรจะเป็น (likelihood function) เป็น\n\\(p(D|y)=\\Pi_{i=1}^nN(y_i|\\mu, \\tau=1/\\sigma^2)\\)\nการแจกแจงความน่าจะเป็นก่อนหน้า\nจากการระบุโมเดลค่าสังเกตข้างต้น พบว่ามีพารามิเตอร์ 2 ตัวได้แก่ พารามิเตอร์ค่าเฉลี่ย และความเที่ยงตรง จึงระบุการแจกแจงความน่าจะเป็นก่อนหน้าให้กับพารามิเตอร์ทั้งสองเป็นดังนี้\n\\(\\mu \\sim N(m, t=1/S^2)\\) และ \\(\\tau \\sim Uniform(a,b)\\)\nความสัมพันธ์ระหว่างค่าสังเกต โมเดลความน่าจะเป็น และการแจกแจงความน่าจะเป็นก่อนหน้าสภาพแวดล้อมของ JAGs\nเมื่อผู้วิเคราะห์ระบุโมเดลเชิงทฤษฎีในข้างต้นแล้ว ขั้นตอนถัดมาคือการระบุโมเดลสำหรับโปรแกรม JAGS การระบุโมเดลใน JAGs จำเป็นต้องมีความรู้เบื้องต้นเกี่ยวกับสภาพแวดล้อมของโปรแกรม JAGs ก่อน ประเด็นแรกคือเรื่องวัตถุหรือตัวแปรภายต่าง ๆ ภายในโปรแกรม JAGs จะเรียกว่า node จำแนกออกเป็น 3 ประเภทได้แก่\nค่าคงที่ (constant nodes)\nค่าตัวแปรสุ่ม (Stochastic nodes) เป็นตัวแปรที่มีการแจกแจงความน่าจะเป็นกำกับโดเมนหรือค่าของตัวแปรไว้ การนิยามตัวแปรประเภทนี้จะเขียนอยู่ในรูปแบบ variable ~ distribution_name(par1, par2, ...) ยกตัวอย่างเช่น ตัวอย่างข้างต้นกำหนดให้โมเดลของค่าสังเกต \\(y_i\\) มีการแจกแจงแบบปกติ สามารถนิยามตัวแปรนี้บน JAGs ได้เป็น y[i] ~ dnorm(mu, tau) ส่วนการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ \\(\\mu\\) และ \\(\\tau\\) สามารถระบุได้เป็น mu ~ dnorm(m,t) และ tau ~ dunif(a,b)\n\nฟังก์ชันเชิงคณิตศาสตร์ (Deterministic nodes) เป็นตัวแปรที่สร้างขึ้นจากฟังก์ชันหรือความสัมพันธ์เชิงคณิตศาสตร์กับ node อื่น ๆ เช่น mu[i] <- b0+b1*x[i]\nประเด็นที่สองเป็นเรื่องเกี่ยวกับโครงสร้างของตัวแปร และการระบุตำแหน่งของสมาชิกภายในโครงการของตัวแปร ตัวแปรอาจจำแนกโดยใช้โครงสร้างของตัวแปรออกได้เป็น 4 ประเภทหลัก ๆ ได้แก่ ค่าคงที่หรือสเกลาร์ เวกเตอร์ เมทริกซ์ และอาร์เรย์ที่มีมิติตั้งแต่ 3 มิติขึ้นไป การระบุตำแหน่งของสมาชิกภายในตัวแปรดังกล่าวทำได้ในวิธีเดียวกับในโปรแกรม R เช่น\ny[i] หมายถึงสมาชิกตัวที่ i ในเวกเตอร์ y\nmu.p[i,j] หมายถึงสมาชิกในแถวที่ i และคอลัมนท์ที่ j\nประเด็นที่สามเป็นเรื่องการดำเนินการทวนซ้ำ (repeated structures) ในโปรแกรม JAGs ผู้วิเคราะห์ไม่จำเป็นต้องพิสูจน์เพื่อหารูปแบบของฟังก์ชันภาวะความควรจะเป็นด้วยตัวเอง แต่สามารถสั่งให้โปรแกรมประมวลผลได้โดยกำหนดโมเดลของค่าสังเกตเอาไว้ภายใต้ loop เช่น ฟังก์ชันภาวะความควรจะเป็นในตัวอย่างข้างต้นสามารถระบุได้ดังนี้\n\n\nfor (i in 1:n)\n{\n  y[i]~dnorm(mu, tau)\n}\n\n\n\nประเด็นทีสุดท้ายเป็นโครงสร้างของชุดคำสั่งสำหรับระบุโมเดลทั้งหมด อยู่ในรูปแบบต่อไปนี้\n\nmodel{\n  \n  # Likelihood\n  for (i in 1:n)\n  {\n    \n  }\n  \n  # Prior Distributions\n  \n  \n  \n  # Derived quantities \n  \n  \n\n  } #end of model\n\nการประมวลผล\nตัวอย่างต่อไปนี้แสดงขั้นตอนการสั่งให้ JAGs ประมวลผลเพื่อสร้างตัวอย่างสุ่มของลูกโซ่มาร์คอฟ\nระบุ JAGs โมเดล\n\n\nmean.model<-\"\nmodel{\n  \n  # Likelihood\n  for (i in 1:n)\n  {\n    y[i]~dnorm(mu, tau)\n  }\n  \n  # Prior Distributions\n  mu~dnorm(0,0.01)\n  tau~dunif(0,5)\n  \n  # Derived quantities \n  sigma2<-1/tau\n  \n  }\"\n# write mean.model to model1.txt\nwriteLines(mean.model, con=\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/model1.txt\") \n\n\n\nสั่งประมวลผล\n\n\nlibrary(rjags)\ndataList<-list(y=dat[,2], n=dim(dat)[1])\ninitsList<-list(mu=1, tau=1)\n\nmodel<-jags.model(file=\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/model1.txt\",\n                  data = dataList,\n                  inits = initsList,\n                  n.chains = 5)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 100\n   Unobserved stochastic nodes: 2\n   Total graph size: 108\n\nInitializing model\n\n\n\nupdate(model, n.iter=2000) #n.burnin\nsamples<-coda.samples(model,\n                      variable.names = c(\"mu\",\"sigma2\"),\n                      n.iter = 10000,\n                      thin = 3)\n\n\n\n\n\nhead(samples)\n\n\n[[1]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 56.99971 374.6275\n[2,] 56.44537 360.5707\n[3,] 60.10607 341.6982\n[4,] 58.41318 298.6663\n[5,] 58.00507 330.1300\n[6,] 58.92663 289.2211\n[7,] 56.92002 292.0860\n\n[[2]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 57.34576 183.7835\n[2,] 59.76683 311.2835\n[3,] 58.53668 320.1921\n[4,] 56.76741 333.4995\n[5,] 56.50524 392.9627\n[6,] 58.86800 322.1584\n[7,] 59.48805 285.5446\n\n[[3]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 57.13504 352.4318\n[2,] 56.91797 305.4816\n[3,] 52.81955 375.1034\n[4,] 58.19032 280.6818\n[5,] 56.76507 239.3729\n[6,] 58.36171 299.0031\n[7,] 56.31038 231.2000\n\n[[4]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 58.78134 413.3986\n[2,] 58.23346 292.0792\n[3,] 58.19950 269.7477\n[4,] 55.53937 290.0780\n[5,] 59.99713 319.8648\n[6,] 57.20760 276.2841\n[7,] 55.65076 262.7342\n\n[[5]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 3003 \nEnd = 3021 \nThinning interval = 3 \n           mu   sigma2\n[1,] 57.81675 325.0818\n[2,] 57.55347 435.7781\n[3,] 58.44531 270.6316\n[4,] 57.01873 256.9196\n[5,] 58.57841 253.1785\n[6,] 59.33593 262.4037\n[7,] 55.80985 259.3874\n\nattr(,\"class\")\n[1] \"mcmc.list\"\n\nอีก package หนึ่งที่สามารถเรียก JAGS จาก R ได้คือ package-runjags ซึ่งมีจุดเด่นคือสามารถสั่งประมวลแบบคู่ขนาน (parallel) แยกตาม core ของ CPU ได้ในกรณีที่ผู้วิเคราะห์กำหนดให้สุ่มตัวอย่างจากลูกโซ่มาร์คอฟที่มีจำนวนมากกว่า 1 ลูกโซ่ ตัวอย่างคำสั่งเป็นดังนี้\n\n\nlibrary(runjags)\n\nmodel.runjags<-run.jags(method=\"parallel\",\n                        model=\"/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-05-jags/model1.txt\",\n                        monitor=c(\"mu\",\"sigma2\"),\n                        data=dataList,\n                        inits=initsList,\n                        n.chains=3,\n                        burnin=1000,\n                        sample = 10000,\n                        thin=3,\n                        summarise=TRUE,\n                        plots=FALSE)\n\n\nCalling 3 simulations using the parallel method...\nFollowing the progress of chain 1 (the program will wait for\nall chains to finish before continuing):\nWelcome to JAGS 4.3.0 on Sat Feb  5 12:19:11 2022\nJAGS is free software and comes with ABSOLUTELY NO WARRANTY\nLoading module: basemod: ok\nLoading module: bugs: ok\n. . Reading data file data.txt\n. Compiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 100\n   Unobserved stochastic nodes: 2\n   Total graph size: 108\n. Reading parameter file inits1.txt\n. Initializing model\n. Adapting 1000\n-------------------------------------------------| 1000\n++++++++++++++++++++++++++++++++++++++++++++++++++ 100%\nAdaptation successful\n. Updating 1000\n-------------------------------------------------| 1000\n************************************************** 100%\n. . . Updating 30000\n-------------------------------------------------| 30000\n************************************************** 100%\n. . . . Updating 0\n. Deleting model\n. \nAll chains have finished\nSimulation complete.  Reading coda files...\nCoda files loaded successfully\nCalculating summary statistics...\nCalculating the Gelman-Rubin statistic for 2 variables....\nFinished running the simulation\n\nsamples2<-as.mcmc.list(model.runjags)\nhead(samples2)\n\n\n[[1]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 2001 \nEnd = 2019 \nThinning interval = 3 \n          mu  sigma2\n2001 58.0463 402.698\n2004 56.5786 267.789\n2007 57.6551 391.168\n2010 55.1093 338.961\n2013 58.2510 323.903\n2016 57.7452 238.788\n2019 57.0253 313.849\n\n[[2]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 2001 \nEnd = 2019 \nThinning interval = 3 \n          mu  sigma2\n2001 58.5314 307.193\n2004 56.4717 326.653\n2007 56.0200 245.936\n2010 57.9875 388.426\n2013 57.6854 375.313\n2016 59.9974 291.242\n2019 58.4714 247.513\n\n[[3]]\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 2001 \nEnd = 2019 \nThinning interval = 3 \n          mu  sigma2\n2001 55.3906 265.183\n2004 57.3552 335.762\n2007 58.9153 251.260\n2010 56.5096 360.693\n2013 56.9245 299.327\n2016 58.1920 263.130\n2019 56.2094 387.258\n\nattr(,\"class\")\n[1] \"mcmc.list\"\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-05T12:19:13+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-03-mcmc-via-jags/",
    "title": "Markov Chain Monte Carlo (MCMC)",
    "description": "มโนทัศน์ของลูกโซ่มาร์คอฟมอนติคาร์โล",
    "author": [
      {
        "name": "Siwachoat Srisuttiyakorn",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\n\nContents\nMCMC algorithm\nMetropolis algorithm\nExample 1: Tossing coin\nExample 2: One-sample Mean and SD\n\nEfficiency\nการตรวจสอบแนวโน้มการลู่เข้าด้วย Trace plot และ Density plot\nAutocorrelation\nEffective Sample Size (ESS)\nMonte Carlo Standard Error\nPotential Scale Reduction (\\(\\hat{R}\\) หรือ RSRF)\n\nการอนุมานเชิงสถิติด้วย posterior distribution ที่สร้างจากอัลกอริทึม MCMC\nการประมาณค่า\n\n\nMCMC algorithm\nหัวข้อนี้จะกล่าวถึงมโนทัศน์ของลูกโซ่มาร์คอฟมอนติคาร์โล (Monte Carlo Markov Chain: MCMC) ที่เป็นเครื่องมือสำคัญสำหรับประมาณการแจกแจงความน่าจะเป็นภายหลัง (posterior distribution) สำหรับการวิเคราะห์ข้อมูลที่อาศัยแนวคิดแบบเบส์\nแนวคิดเกี่ยวกับ MCMC มีมาค่อนข้างยาวนานประมาณ 40 ปีแล้ว แต่ด้วยข้อจำกัดทั้งด้านโปรแกรมและประสิทธิภาพของคอมพิวเตอร์ทำให้การใช้งานอัลกอริทึม ในสมัยก่อนทำได้ยาก และเกือบจะเป็นไปไม่ได้ที่จะใช้งานอัลกอริทึม MCMC กับปัญหาทางสถิติที่มีความซับซ้อน แต่ด้วยความก้าวหน้าทางเทคโนโลยีในยุคปัจจุบันทำให้ข้อจำกัดดังกล่าวลดลงจนแทบไม่มีอีกต่อไป\nอัลกอริทึม MCMC เป็นอัลกอริทึมที่ใช้สำหรับประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ โดยใช้ตัวอย่างสุ่มที่สร้างจากเทคนิคการจำลองแบบมอนติคาร์โล แทนการพิสูจน์หรือการทดลองแทนค่าเพื่อหาค่าที่ดีที่สุดทางคณิตศาสตร์ คำตอบที่ได้จากอัลกอริทึม MCMC นี้จึงไม่ใช่สูตรหรือฟังก์ชันทางคณิตศาสตร์ แต่จะเป็นตัวอย่างสุ่มของพารามิเตอร์ที่สร้างขึ้น ตัวอย่างดังกล่าวหากมีจำนวนที่มากเพียงพอ จะสามารถใช้เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ และสามารถนำตัวอย่างดังกล่าวมาผ่านกระบวนการทางสถิติเพื่อสร้างข้อสรุปเกี่ยวกับพารามิเตอร์ในโมเดลได้โดยตรง กล่าวโดยสรุปได้ว่าอัลกอริทึม MCMC เป็นเทคนิคที่นำมาประยุกต์ใช้ในการวิเคราะห์ข้อมูลแบบเบส์ เพื่อประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ต่าง ๆ ภายในโมเดล ด้วยตัวอย่างสุ่มของพารามิเตอร์\nรูปต่อไปนี้แสดงการเปรียบเทียบระหว่างการแจกแจงความน่าจะเป็นเชิงทฤษฎี (theoretical/exact distribution) กับการแจกแจงความน่าจะเป็นที่ประมาณด้วยตัวอย่างสุ่มที่สร้างจากเทคนิคการจำลองแบบมอนติคาร์โล\nด้วยเทคนิคการจำลองแบบมอนติคาร์โล ผู้วิเคราะห์สามารถจำลองตัวอย่างสุ่มจากการแจกแจงความน่าจะเป็นใดก็ได้ แต่มีเงื่อนไขว่าต้องทราบฟังก์ชันความน่าจะเป็นของการแจกแจงดังกล่าวก่อน เงื่อนไขนี้เป็นข้อจำกัดที่ทำให้ไม่สามารถใช้เทคนิคการจำลองแบบมอนติคาร์โลแบบปกติได้โดยตรง ทั้งนี้เป็นเพราะในโมเดลที่มีความซับซ้อนระดับหนึ่ง เป็นการยากมากที่ผู้วิเคราะห์จะทราบรูปแบบหรือฟังก์ชันของการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ในโมเดลที่ต้องการใช้งาน\n\n\nlibrary(scales)\nx<-seq(-3,3,0.01)\npar(mfrow=c(2,3), mar=c(1,5,6,5))\nplot(x, dnorm(x,0,1),type=\"l\", main=\"exact distribution N(0,1)\", xlab=\"X\")\nhist(rnorm(500,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=500\", xlab=\"X\")\nhist(rnorm(1000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=1000\", xlab=\"X\")\nhist(rnorm(5000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=5000\", xlab=\"X\")\nhist(rnorm(10000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=10000\", xlab=\"X\")\nhist(rnorm(50000,0,1), freq=F, nclass=30, col=alpha(\"#004D80\",0.7),\n     main=\"sample distribution n=50000\", xlab=\"X\")\n\n\n\n\nMetropolis algorithm\nMetropolis algorithm เป็นกระบวนการสุ่ม (random process/stochastic process) ประเภทหนึ่ง ตั้งชื่ออัลกอริทึมตามคณะผู้พัฒนาได้แก่ Metropolis, Rosenbluth, Rosenbluth, Teller & Teller (1953)\nอัลกอริทึมนี้สามารถนำมาประยุกต์ใช้เพื่อหาการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ โดยปริภูมิของพารามิเตอร์ (parameters space) ดังกล่าวนั้นเป็นไปได้ทั้งแบบไม่ต่อเนื่อง (discrete) และแบบต่อเนื่อง (continuous) และสามารถใช้ได้กับปริภูมิพารามิเตอร์ที่มีมิติตั้งแต่หนึ่งมิติ (unidimensional) ไปจนถึงหลายมิติ (multidimensional) อัลกอริทึม Metropolis มีลักษณะการทำงานแบบทวนซ้ำ (interative) มีรายละเอียดของขั้นตอนวิธีดังนี้\nกำหนดให้ \\(p(\\theta)\\) เป็นการแจกแจงความน่าจะเป็นภายหลังที่ต้องการประมาณ\nสุ่ม/เลือกค่าตั้งต้น (initial values) ของพารามิเตอร์ในการแจกแจงความน่าจะเป็นภายหลัง เขียนแทนด้วย \\(\\theta_0\\) ทั้งนี้ค่าพารามิเตอร์ที่สุ่มมามีเงื่อนไขคือต้องอยู่ภายใต้ปริภูมิของพารามิเตอร์ กล่าวคือ \\(p(\\theta_0)>0\\)\nสร้างค่า proposal jump เพื่อใช้เป็นตัวปรับค่าตั้งต้นของพารามิเตอร์ เขียนแทนด้วย \\(\\Delta\\theta\\) จากการแจกแจงความน่าจะเป็นโครงร่าง (proposal distribution) ที่กำหนดไว้ เช่นอาจกำหนดให้ \\(\\Delta\\theta \\sim N(0, \\sigma)\\) ซึ่งจะได้ proposed values ของพารามิเตอร์ค่าใหม่เขียนแทนด้วย \\(\\theta_{pro}\\) โดยที่ \\(\\theta_{pro}=\\theta_{i-1}+\\Delta\\theta\\) เมื่อ \\(i=1,2,3,...,m\\)\nคำนวณค่าความน่าจะเป็นในการเดิน/เปลี่ยนแปลงของ proposed values ดังนี้ \\(p_{move}=min(1,\\frac{p(\\theta_{pro})}{p(\\theta_{i-1})})\\) โดยที่ \\(p(\\theta_{pro})=p(D|\\theta_{pro}p(\\theta_{pro}))\\) และ \\(p(\\theta_{i-1})=p(D|\\theta_{i-1})p(\\theta_{i-1})\\) จากความน่าจะเป็นข้างต้น จะเห็นว่า ถ้า \\(\\theta_{pro}\\) มีค่าอยู่นอกเหนือค่าที่เป็นไปได้หรือค่าที่ควรจะเป็นของพารามิเตอร์ \\(\\theta\\) ในโมเดล ค่าความน่าจะเป็นก่อนหน้า \\(p(\\theta_{pro})\\) และ/หรือค่าของฟังก์ชันภาวะความควรจะเป็น \\(p(D|\\theta_{pro})\\) จะมีค่าเท่ากับ 0 ซึ่งทำให้ค่า \\(p_{move}=0\\)\nเกณฑ์การพิจารณายอมรับค่า proposed value \\(\\theta_{pro}\\) จะยอมรับด้วยความน่าจะเป็นเท่ากับ \\(p_{move}\\) ในทางปฏิบัติจะสุ่มเลขสุ่มจากการแจกแจงแบบ uniform [0,1] ขึ้นมา 1 ค่า เขียนแทนด้วย \\(u\\) หาก \\(u<p_{move}\\) จะยอมรับค่า \\(theta_{pro}\\) ดังกล่าว แต่ถ้าหาก \\(u > p_{move}\\) จะปฏิเสธค่า \\(\\theta_{pro}\\) ในกรณีนี้ค่าพารามิเตอร์ \\(\\theta_{i-1}\\) ก็จะไม่ได้มีการเปลี่ยนแปลงสถานะ\nอัลกอริทึมข้างต้นเป็นกระบวนการทวนซ้ำโดยจะดำเนินการทวนซ้ำในขั้นตอนที่ 2-4 จนกระทั่งตัวอย่างพารามิเตอร์ \\(\\theta\\) มีจำนวนเพียงพอ และมีคุณสมบัติที่เหมาะสม\nExample 1: Tossing coin\nจากตัวอย่างปัญหาการวิเคราะห์ความเที่ยงตรงของเหรียญ หากต้องการทำ MCMC เพื่อประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ความลำเอียง อาจดำเนินการดังนี้\nกำหนดให้ \\(y_i\\) คือค่าสังเกตของการโยนเหรียญ โดยที่ \\(i=1,2,3...,n\\) และโมเดลของค่าสังเกตดังกล่าวคือ \\(p(y_i|\\theta)=\\theta^y_i(1-\\theta)^{n-y_i}\\) จากการกำหนดนี้จะได้ฟังก์ชันภาวะความควรจะเป็นคือ\n\n\\(p(y|\\theta)=\\theta^{\\sum y_i}(1-\\theta)^{n-\\sum y_i}\\)\n\nและกำหนดให้พารามิเตอร์ \\(\\theta\\) มีการแจกแจงความน่าจะเป็นก่อนหน้าเป็น\n\n\\(p(\\theta)=Beta(\\theta|a,b)\\)\n\nการแจกแจงความน่าจะเป็นแบบ Beta มีธรรมชาติของการแจกแจงคือ ค่าที่เป็นไปได้ของโดเมนอยู่บนช่วง [0,1] ซึ่งสอดคล้องกับธรรมชาติของพารามิเตอร์ความลำเอียงในโมเดลค่าสังเกต\nKruschke, 2015ในกรณีนี้เลือกการแจกแจงความน่าจะเป็นก่อนหน้าเป็น \\(Beta(1,1)\\) ซึ่งจะเห็นว่าเทียบเท่ากับการแจกแจงแบบ uniform ที่หมายถึงผู้วิเคราะห์ไม่ได้มีสารสนเทศเบื้องต้นใด ๆ เกี่ยวกับความลำเอียงของเหรียญที่ทำการศึกษา นอกจากขอบเขตที่เป็นไปได้ของค่าพารามิเตอร์\nจากการกำหนดเงื่อนไขของการศึกษาในข้างต้น จะค่าความน่าจะเป็นในการเปลี่ยนแปลงสถานะหรือ \\(p_{move}\\) เป็น\n\\(p_{move}=min(1,\\frac{p(\\theta_{pro})}{p(\\theta{i-1})})\\)\n\\(=min(1, \\frac{[\\theta_{pro}^{\\sum y_i}(1-\\theta_{pro})^{n-\\sum y_i}] \\times Beta(\\theta_{pro}|1,1)}{[\\theta_{i-1}^{\\sum y_i}(1-\\theta_{i-1})^{n-\\sum y_i}] \\times Beta(\\theta_{i-1}|1,1)})\\)\nเนื่องจากการแจกแจงความน่าจะเป็นแบบ Beta มีฟังก์ชันความน่าจะเป็นคือ \\(p(\\theta|a,b)=\\frac{1}{B(a,b)} \\theta^{a-1}(1-\\theta)^{b-1}\\) โดยที่ \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) และ \\(\\Gamma(.)\\) คือฟังก์ชันแกมมา (Gamma function)\nดังนั้นความน่าจะเป็นในการเปลี่ยนสถานะของ proposed values จะมีค่าเท่ากับ\n\\(p_{move}=min(1,\\frac{\\theta_{pro}^{\\sum y_i+a-1}(1-\\theta_{pro})^{n-\\sum y_i+b-1}/B(a,b)}{\\theta_{i-1}^{\\sum y_i+a-1}(1-\\theta_{i-1})^{n-\\sum y_i+b-1}/B(a,b)})\\)\nสมมุติว่าผู้วิเคราะห์ทำการทดสอบโยนเหรียญ 20 ครั้ง และได้หน้าหัวเท่ากับ 7 ครั้ง\n\n\ntheta<-0.99 #initial value\nm<-5000 #iteration number\ntheta.dat<-matrix(nrow=m,ncol=3)\nsd.pro<-c(0.02,0.2,2)\ncount<-matrix(nrow=m, ncol=3)\n\nfor(j in 1:length(sd.pro))\n  {\n  for(i in 1:m)\n    {\ndelta.theta<-rnorm(1,0,sd.pro[j])\ntheta.pro<-theta+delta.theta #proposed bias parameter\n\nnom<-theta.pro^(7+1-1)*(1-theta.pro)^(20-7+1-1)\ndenom<-theta^(7+1-1)*(1-theta)^(20-7+1-1)\n\np.move<-min(1,nom/denom)\n\nif(runif(1,0,1)<p.move)\n{theta<-theta.pro\ncount[i,j]<-1\n}else{\n\ntheta<-theta  \ncount[i,j]<-0\n}\ntheta.dat[i,j]<-theta\n  } # end of m iteration\n} # end of sd loop\n\n\n\nจากการดำเนินอัลกอริทึมในข้างต้น พบว่าได้ผลการวิเคราะห์ดังต่อไปนี้\n\n\n\nเราอาจพิจารณาประสิทธิภาพของอัลกอริทึมในข้างต้นจากสัดส่วนของจำนวนค่าพารามิเตอร์ผ่านการยอมรับต่อจำนวน proposed values ของพารามิเตอร์ ซึ่งจะพบว่ามีค่าเท่ากับ\n\n\ncolSums(count)/5000\n\n\n[1] 0.9424 0.5082 0.0646\n\nExample 2: One-sample Mean and SD\nสมมุตินักวิจัยต้องการประมาณค่าเฉลี่ย IQ ของนักเรียนในโรงเรียนสังกัด สพฐ. ว่ามีค่าสูงกว่าเกณฑ์มาตรฐานคือ 90 คะแนน หรือไม่ ในการวิจัยนักวิจัยได้สร้างแบบวัด IQ และนำไปเก็บรวบรวมข้อมูลจากนักเรียนดังกล่าวจำนวน 3000 คน พบว่ามีคะแนนดังนี้\n\n\nset.seed(123)\niq<-rnorm(3000,99,10) #IQ sample data\nhist(iq, nclass=30, xlab=\"IQ score\",col=alpha(\"#004D80\",0.7))\n\n\n\n\nจากปัญหาในข้างต้น นักวิจัยได้กำหนดโมเดลของค่าสังเกตด้วยการแจกแจงความน่าจะเป็นแบบปกติ ดังนี้ \\(y_i \\sim N(\\mu,\\ \\sigma)\\) ที่มีฟังก์ชันความน่าจะเป็นคือ\n\\(p(y_i|\\mu,\\ \\sigma)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp\\{-\\frac{1}{2\\sigma^2}(y_i-\\mu)^2\\}\\)\nซึ่งทำให้ได้ว่าฟังก์ชันภาวะความควรจะเป็นของข้อมูลค่าสังเกตเมื่อกำหนดพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\) คือ\n\\(\\Pi_{i=1}^n p(y_i|\\mu,\\sigma)=(\\frac{1}{\\sqrt{2\\pi\\sigma^2}})^nexp\\{-\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\sum_{i=1}^n(y_i-\\mu)^2 \\}\\)\nเนื่องจากพารามิเตอร์ทั้งสองเป็นอิสระซึ่งกันและกัน การกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าให้กับพารามิเตอร์ดังกล่าวจึงสามารถกำหนดแยกจากการได้อย่างอิสระ โดยในตัวอย่างนี้จะกำหนดให้การแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ค่าเฉลี่ยมีการแจกแจงแบบปกติ ที่มีค่าเฉลี่ยเท่ากับ 90 และส่วนเเบี่ยงเบนมาตรฐานเท่ากับ 30 ดังนี้\n\\(p(\\mu|\\mu_p=90, \\sigma_p=30)=\\frac{1}{\\sqrt{2\\pi\\times30^2}}exp\\{-\\frac{1}{2\\times30^2}(\\mu-90)^2 \\}\\)\nและกำหนดให้พารามิเตอร์ความแปรปรวน (\\(\\sigma^2\\) ) มีการแจกแจงความน่าจะเป็นก่อนหน้าเป็นแบบ uniform บนช่วง [0,10000] ซึ่งมีฟังก์ชันความน่าจะเป็นดังนี้\n\\(p(\\sigma^2)=\\frac{1}{10000}\\)\nรูปด้านล่างแสดงโค้งความหนาแน่นของการแจกแจงความน่าจะเป็นก่อนหน้าของ \\(\\mu \\sim N(90,30)\\) และ \\(\\sigma^2 \\sim U(0,10000)\\)\n\n\n\nจากการกำหนดในข้างต้นจะได้ว่าความน่าจะเป็นในการเปลี่ยนสถานะของพารามิเตอร์ทั้งสองมีค่าเท่ากับ\n\\(p.move=min(1,\\frac{p(y|\\mu_{pro},\\sigma_{pro})p(\\mu_{pro},\\sigma_{pro})}{p(y|mu_{i-1},\\sigma_{i-1})p(\\mu_{i-1},\\sigma_{i-1})})\\)\n\\(=min(1,\\frac{p(y|\\mu_{pro},\\sigma_{pro})\\times N(mu_{pro}|90,30) \\times (1/10000)}{p(y|\\mu_{i-1},\\sigma_{i-1})\\times N(mu_{i-1}|90,30) \\times (1/10000)})\\)\nอย่างไรก็ตามจะเห็นว่าความน่าจะเป็นข้างต้นมีสูตรค่อนข้างซับซ้อนและการคำนวณตรง ๆ อาจมีปัญหา ผู้วิเคราะห์จึง take log เข้าที่ความน่าจะเป็นดังกล่าวจึงทำให้เกณฑ์การพิจารณากลายเป็น\n\\(p.move = min(0, [lnp(y|\\mu_{pro},\\sigma_{pro})+lnN(mu_{pro}|90,30)+0]-[lnp(y|\\mu_{i-1},\\sigma_{i-1})+lnN(mu_{i-1}|90,30)+0]\\)\nจากเงื่อนไขข้างต้นสามารถเขียนอัลกอริทึม Metropolis เพื่อประมาณพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\) ได้ดังนี้\n\n\n#initial value\nmu<-50\nsigma<-30\n\n#iteration number\nm<-5000 \ntheta.dat<-matrix(nrow=m,ncol=6)\nsd.pro<-c(0.05,0.2,2)\ncount<-matrix(nrow=m, ncol=3)\n\nfor(j in 1:length(sd.pro))\n  {\nfor(i in 1:m)\n{\n\ndelta.mu<-rnorm(1,0,sd.pro[j])\ndelta.sigma<-rnorm(1,0,sd.pro[j])\n\n#proposed values\nmu.pro<-mu+delta.mu \nsigma.pro<-sigma+delta.sigma\n\nnom<-sum(dnorm(iq,mean = mu.pro,sd = sigma.pro, log=TRUE))+dnorm(mu.pro,90,30, log=TRUE)\ndenom<-sum(dnorm(iq,mean = mu,sd = sigma, log=TRUE))+dnorm(mu,90,30, log=TRUE)\n\np.move<-min(1,exp(nom-denom))\n\nif(p.move==\"NaN\")\n{\nmu<-mu\nsigma<-sigma\ncount[i,j]<-0\n} else if (runif(1,0,1)<p.move)\n{\nmu<-mu.pro\nsigma<-sigma.pro\ncount[i,j]<-1\n}\nelse\n{\nmu<-mu\nsigma<-sigma\ncount[i,j]<-0\n}\n\ntheta.dat[i,2*j-1]<-mu\ntheta.dat[i,2*j]<-sigma\n  } # end of m iteration\n}#end of sd loop\n\ncolnames(theta.dat)<-c(\"mu_sdpro1\",\"sigma_sdpro1\",\"mu_sdpro2\",\"sigma_sdpro2\",\"mu_sdpro3\",\"sigma_sdpro3\")\n\n\n\nประสิทธิภาพในด้านการยอมรับ proposed value ในแต่ละเงื่อนไขเป็นดังนี้\n\n\ncolSums(count)\n\n\n[1] 3355 2245   52\n\nการแจกแจงความน่าจะเป็นภายหลังที่ประมาณได้ในตัวอย่างนี้เป็นการแจกแจงความน่าจะเป็นร่วม (joint probability distribution) เนื่องจากมีพารามิเตอร์ 2 ตัวที่ต้องการประมาณค่า รูปต่อไปนี้แสดงการประมาณการแจกแจงความน่าจะเป็นภายหลังจากตัวอย่างสุ่มของพารามิเตอร์ทั้งสองที่สร้างจากอัลอริทึม Metropolis\n\n\npar(mfrow=c(2,3))\nplot(theta.dat[,1],theta.dat[,2], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=0.005\")\nplot(theta.dat[,3],theta.dat[,4], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=0.02\")\nplot(theta.dat[,5],theta.dat[,6], type=\"l\",xlab=expression(mu),ylab=expression(sigma), main=\"sd.pro=2\")\n\nlibrary(MASS)\nden3d<-kde2d(theta.dat[1000:5000,1],theta.dat[1000:5000,2])\npersp(den3d, box=T,phi=20,theta=-30, xlab=\"mu\", ylab=expression(sigma))\n\nden3d<-kde2d(theta.dat[1000:5000,3],theta.dat[1000:5000,4])\npersp(den3d, box=T,phi=20,theta=50, xlab=expression(mu), ylab=expression(sigma))\n\nden3d<-kde2d(theta.dat[1000:5000,5],theta.dat[1000:5000,6])\npersp(den3d, box=T,phi=20,theta=50, xlab=expression(mu), ylab=expression(sigma))\n\n\n\n\nEfficiency\nจากตัวอย่างในข้างต้น ผู้อ่านจะเห็นว่าตัวอย่างที่สุ่มจากอัลกอริทึม Metropolis ข้างต้นมีลักษณะที่แตกต่างกันออกไปตามลักษณะของ proposal distribution ที่กำหนด\nถ้า proposal distribution มีลักษณะการกระจายที่แคบกว่าการแจกแจงความน่าจะเป็นภายหลัง/การแจกแจงเป้าหมาย ที่ต้องการประมาณมาก กระบวนการสุ่มที่สร้างขึ้นจากอัลกอริทึม Metropolis ในข้างต้นจะสร้างตัวอย่างสุ่มของพารามิเตอร์ที่เป็นตัวแทน ครอบคลุมการแจกแจงความน่าจะเป็นภายหลังที่ต้องการได้ช้า ภายใต้สถานการณ์ดังกล่าว ผู้วิเคราะห์จึงต้องใช้จำนวนการทวนซ้ำที่เพ่ิมจึ้นกว่าปกติเพื่อที่จะได้ตัวอย่างของพารามิเตอร์ที่เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังดังกล่าวได้ ในทางกลับกันหาก proposal distribution มีการกระจายที่กว้างเมื่อเปรียบเทียบกับการแจกแจงความน่าจะเป็นภายหลัง จะทำให้การพัฒนาค่าของพารามิเตอร์ในแต่ละรอบมีการเปลี่ยนแปลงมากเกินไป และอาจไม่สามารถลู่เข้าไปสู่การแจกแจงความน่าจะเป็นภายหลังที่ต้องการได้\nปัจจัยในข้างต้นส่งผลโดยตรงต่อประสิทธิภาพของอัลกอริทึม Metropolis การพิจารณาว่า proposal distribution ดังกล่าวมีความเหมาะสมแล้วหรือไม่ อาจพิจารณาได้จากอัตราส่วนการยอมรับ ซึ่งคำนวณได้จาก จำนวนพารามิเตอร์ที่ได้รับการยอมรับต่อจำนวนการทวนซ้ำทั้งหมด รูปต่อไปนี้แสดงการเปรียบเทียบกระบวนการสุ่มที่สร้างจากอัลกอริทึม MCMC ภายใต้สถานการณ์ที่มีการกำหนดการกระจายของ proposal distribution แตกต่างกัน\n\n\n\n\n\ncolSums(count)/5000\n\n\n[1] 0.6710 0.4490 0.0104\n\nอีกปัจจัยหนึ่งที่ส่งผลกระทบต่อประสิทธิภาพของอัลกอริทึม MCMC คือค่าเริ่มต้น (initial values) ของพารามิเตอร์ กล่าวคือหากผู้วิเคราะห์กำหนดค่าเริ่มต้นที่มีตำแหน่งอยู่ห่างหรืออยู่นอกขอบเขตปกติของค่าพารามิเตอร์จริงในการแจกแจงความน่าจะเป็นภายหลัง จะทำให้กระบวนสุ่มที่สร้างขึ้นมีแนวเดินที่ช้าและใช้จำนวนรอบทวนซ้ำจำนวนมากเพื่อให้ได้ตัวอย่างที่เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ ปรากฏการณ์ดังกล่าวทำให้ตัวอย่างในช่วงแรก ๆ ของกระบวนการสุ่มนั้นยังไม่ใช้ตัวอย่างที่อยู่ภายใต้การแจกแจงความน่าจะเป็นภายหลังที่ต้องการ ในการวิเคราะห์จึงมักมีการตัดตัวอย่างของพารามิเตอร์ในส่วนแรกของการกระบวนการสุ่มออกไปจากการวิเคราะห์จำนวนหนึ่ง เรียกส่วนดังกล่าวว่า burn-in period\nนอกจากนี้ก่อนการนำตัวอย่างของพารามิเตอร์ที่สุ่มได้ไปใช้ในการอนุมานเชิงสถิติต่อไปนั้น ผู้วิเคราะห์จำเป็นต้องตรวจสอบก่อนว่าตัวอย่างดังกล่าวสร้างจากกระบวนการสุ่มที่ลู่เข้าไปสู่การแจกแจงความน่าจะเป็นภายหลังแล้วหรือไม่ การตรวจสอบการลู่เข้านี้มีหลายวิธีการ อย่างไรก็ตามการตรวจสอบดังกล่าวเป็นเพียงการตรวจสอบแนวโน้มการลู่เข้าของกระบวนการสุ่มเท่านั้น แต่ไม่ได้สามารถใช้ยืนยันได้ว่ากระบวนการสุ่มดังกล่าวมีการลู่เข้าไปสู่การแจกแจงความน่าจะเป็นภายหลังจริง ๆ แล้วหรือไม่ วิธีการตรวจสอบ เช่น\nการตรวจสอบแนวโน้มการลู่เข้าด้วย Trace plot และ Density plot\nแผนภาพร่องรอย (trace plot) และแผนภาพโค้งความหนาแน่น (density plot) เป็นเครื่องมือพื้นฐานอย่างแรก ๆ ที่ผู้วิเคราะห์มักใช้พิจารณาแนวโน้มการลู่เข้าของกระบวนการสุ่มที่สร้างจากอัลกอริทึม MCMC รูปด้านล่างแสดงตัวอย่าง Trace plot ในลักษณะที่มีแนวโน้มลู่เข้าและไม่ลู่เข้าสู่การแจกแจงความน่าจะเป็นภายหลัง\n\n\n\nDensity plot (และ Histogram) เป็นทัศนภาพอีกประเภทหนึ่งที่ให้สารสนเทศคล้ายคลึงกับ trace plot จุดเด่นคือเป็นแผนภาพที่แสดงรูปทรงการแจกแจงของการแจกแจงความน่าจะเป็นภายหลังที่สร้างขึ้นจากกระบวนการสุ่มด้วย รูปด้านล่างแสดงตัวอย่าง density plot ของตัวอย่างสุ่มพารามิเตอร์ \\(\\mu\\) และ \\(\\sigma\\)\n\n\n\nในโปรแกรม R มี package-coda ที่ช่วยอำนวยความสะดวกแก่ผู้วิเคราะห์ในการตรวจสอบ/วินิจฉัยการลู่เข้าของลูกโซ่มาร์คอฟที่สร้างขึ้นจากอัลกอริทึม MCMC\n\n\n\nหากตัวอย่างสุ่มของพารามิเตอร์ (ลูกโซ่มาร์คอฟ) ไม่ได้บันทึกไว้ในรูปแบบ mcmc object ผู้วิเคราะห์จำเป็นต้องเปลี่ยนตัวแปรที่บันทึกข้อมูลดังกล่าวให้อยู่ในรูปแบบดังกล่าวด้วยฟังก์ชัน mcmc(x, start=1, end=numeric(0), thin=1)\n\n\n\nAutocorrelation\nกระบวนการสุ่มที่สร้างขึ้นจากอัลกอริทึม MCMC จะให้ตัวอย่างสุ่มที่มีความสัมพันธ์ระหว่างกัน ทั้งนี้เป็นเพราะตัวอย่างสุ่มที่สร้างขึ้นใหม่นั้น จะขึ้นกับตัวอย่างที่ถูกสร้างไว้ในรอบก่อนหน้าเสมอ ลักษณะดังกล่าวจึงทำให้เกิดอัตสหสัมพันธ์ขึ้นระหว่างตัวอย่าง หากค่าอัตสหสัมพันธ์ดังกล่าวมีค่าสูงในช่วงที่กว้าง จะส่งผลให้การลู่เข้าของกระบวนการสุ่มทำได้ช้า และตัวอย่างที่สร้างขึ้นไม่สามารถใช้เป็นตัวแทนของการแจกแจงความน่าจะเป็นภายหลังที่ต้องการได้\nค่าอัตสหสัมพันธ์สามารถคำนวณได้โดยใช้สูตรเดียวกับสหสัมพันธ์ของเพียร์สัน โดยเป็นการหาสหสัมพันธ์ระหว่างข้อมูลสองชุด ชุดแรกคือตัวอย่างของพารามิเตอร์ \\(\\theta_m, \\theta_{m-1}, \\theta_{m-2}, ...,\\theta_{2}\\) และชุดที่สองคือตัวอย่างของพารามิเตอร์ที่มีการเหลื่อมค่า 1 ช่วงเวลา \\(\\theta_{m-1}, \\theta_{m-2},...,\\theta_{1}\\) สหสัมพันธ์ระหว่างชุดข้อมูลทั้งสองนี้เรียกว่า อัตสหสัมพันธ์อันดับที่ 1 (lag-1 autocorrelation)\nในทำนองเดียวกัน อัตสหสัมพันธ์ในอันดับที่สูงกว่า 1 สามารถหาได้โดยการเหลื่อมข้อมูลเพิ่มขึ้นเป็น 2, 3, 4 ,… ช่วงเวลา ข้อสังเกตคือยิ่งมีการเหลื่อมช่วงเวลามากขึ้น จำนวนตัวอย่างที่นำมาคำนวณค่าอัตสหสัมพันธ์ก็จะลดลงทีละ 1 หน่วยไปเรื่อย ๆ การวิเคราะห์อัตสหสัมพันธ์ของกระบวนการสุ่มสามารถทำได้สองลักษณะ ลักษณะแรกคือวิเคราะห์จากค่าสถิติโดยตรง และลักษณะที่สองคือใช้แผนภาพอัตสหสัมพันธ์ โดยทั้งสองแบบสามารถทำได้ในโปรแกรม R ด้วย package-coda โดยเขียนคำสั่งดังนี้\n\n       mu_sdpro1 sigma_sdpro1   mu_sdpro2 sigma_sdpro2 mu_sdpro3\nLag 0  1.0000000    1.0000000  1.00000000   1.00000000 1.0000000\nLag 1  0.9994292    0.9998234  0.82152505   0.72753970 0.9860251\nLag 5  0.9971468    0.9990995  0.39664748   0.18920770 0.9336869\nLag 10 0.9942847    0.9981647  0.17519306   0.04112503 0.8774738\nLag 50 0.9709985    0.9898665 -0.02851881  -0.02866540 0.5591402\n       sigma_sdpro3\nLag 0     1.0000000\nLag 1     0.9832460\nLag 5     0.9159518\nLag 10    0.8293820\nLag 50    0.4494689\n\n\nEffective Sample Size (ESS)\nจากที่กล่าวในข้างต้นจะเห็นว่า ในสถานการณ์ที่กระบวนการสุ่มที่สร้างขึ้นมีอัตสหสัมพันธ์สูง ตัวอย่างสุ่มของพารามิเตอร์จะมีแนวโน้มซ้ำซ้อนกันมาก และทำให้การทวนซ้ำของกระบวนการสุ่มมีประสิทธิภาพต่ำกว่าจำนวนการทวนซ้ำที่กำหนดไว้ กล่าวคือจำนวนรอบทวนซ้ำที่กำหนดไว้อาจไม่เพียงพอที่จะนำไปประมาณการแจกแจงความน่าจะเป็นภายหลัง สถิติที่ช่วยวัดประสิทธิภาพในด้านนี้คือ effective sample size (ESS)\nกำหนดให้ \\(\\theta_1, \\theta_2, \\theta_3, ...,\\theta_m\\) เป็นตัวอย่างสุ่มของพารามิเตอร์ที่สร้างขึ้นจากอัลกอริทึม MCMC และ \\(n_0\\) เป็นระยะห่าง (lag) ที่น้อยที่สุดที่ตัวอย่างสุ่มของพารามิเตอร์มีอัตสหสัมพันธ์เท่ากับหรือใกล้เคียง 0 จากการกำหนดในข้างต้นจะได้ว่า ตัวอย่างสุ่มที่สร้างจากกระบวนการสุ่มข้างต้น และเป็นอิสระซึ่งกันและกันคือ\n\\(\\theta_{n_0}, \\theta_{2n_0}, \\theta_{3n_0},...,\\theta_{T}\\)\nจะเห็นว่าในกรณีที่เกิดอัตสหสัมพันธ์ขึ้น ตัวอย่างที่เป็นอิสระซึ่งกันและกันจะมีจำนวนน้อยกว่าจำนวนตัวอย่างรวม ค่า ESS จึงมีค่าเท่ากับ \\(m/n_0\\)\nการคำนวณค่า ESS ใน R สามารถทำได้โดยใช้ฟังก์ชัน effectiveSize()\n\n   mu_sdpro1 sigma_sdpro1    mu_sdpro2 sigma_sdpro2    mu_sdpro3 \n   1.4270665    0.4414857  489.8072701  788.4212271   28.6767087 \nsigma_sdpro3 \n  41.3083142 \n\nMonte Carlo Standard Error\n\n\nIterations = 1:5000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n               Mean      SD Naive SE Time-series SE\nmu_sdpro1    85.068 15.8021 0.223475      13.227925\nsigma_sdpro1 21.291 10.9451 0.154787      16.472555\nmu_sdpro2    99.119  0.1826 0.002582       0.008250\nsigma_sdpro2  9.944  0.1291 0.001825       0.004596\nmu_sdpro3    99.134  0.1512 0.002138       0.028234\nsigma_sdpro3  9.941  0.1132 0.001601       0.017609\n\n2. Quantiles for each variable:\n\n               2.5%    25%    50%   75% 97.5%\nmu_sdpro1    51.757 72.609 91.524 99.09 99.49\nsigma_sdpro1  9.753 10.005 19.253 33.43 36.84\nmu_sdpro2    98.770 99.002 99.116 99.25 99.47\nsigma_sdpro2  9.697  9.855  9.940 10.03 10.20\nmu_sdpro3    98.823 99.077 99.176 99.24 99.38\nsigma_sdpro3  9.693  9.879  9.948 10.01 10.15\n\n\\(SE_{naive}=\\sqrt{\\frac{Var(\\theta)}{m}}\\)\n\\(SE_{ts}=\\sqrt{\\frac{Var_{ts}(\\theta)}{m}}\\) โดยที่ \\(Var(\\theta)=\\frac{\\sigma^2}{(1-\\sum_{k=1}^K\\rho_k)^2}\\)\n\\(\\sigma^2\\) เป็นความแปรปรวนของความคลาดเคลื่อนสุ่มที่ประมาณจากโมเดล autoregressive (AR) อันดับที่ K ส่วน \\(\\rho_k\\) คือค่าสัมประสิทธิ์อัตสหสัมพันธ์อันดับที่ \\(k\\)\nPotential Scale Reduction (\\(\\hat{R}\\) หรือ RSRF)\nการตรวจสอบการลู่เข้าของลูกโซ่มาร์คอฟด้วยวิธีการที่กล่าวมา แม้จะได้ผลลัพธ์ว่ามีแนวโน้มที่ตัวอย่างลูกโซ่จะลู่เข้าไปสู่การแจกแจงใดการแจกแจงหนึ่ง แต่ก็ยังไม่สามารถยืนยันได้ว่าการแจกแจงดังกล่าวเป็นการแจกแจงเป้าหมายที่แท้จริงหรือไม่\nวิธีการหนึ่งที่ช่วยเพิ่มหลักฐานและเสริมความมั่นใจให้กับผู้วิเคราะห์ว่า ตัวอย่างลูกโซ่ที่สร้างขึ้นมีการแจกแจงที่ลู่เข้าไปหาการแจกแจงความน่าจะเป็นภายหลังที่ต้องการจริง ๆ คือ การสร้างตัวอย่างลูกโซ่หลาย ๆ ชุด โดยกำหนดค่าเริ่มต้นให้แตกต่างกัน จากนั้นสังเกตผลลัพธ์ที่ได้ หากตัวอย่างทุกชุดมีแนวโน้มที่ลู่เข้าไปหาการแจกแจงเดียวกัน ผู้วิเคราะห์จะมีหลักฐานที่สนับสนุนให้เชื่อได้ว่าตัวอย่างสุ่มที่สร้างขึ้นจากอัลกอริทึม MCMC ลู่เข้าไปหาการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ\nการวิเคราะห์การลู่เข้านี้สามารถวิเคราะห์ได้จากทั้ง trace plot และ density plot และใช้ค่าสถิติ potential scale reduction (\\(\\hat{R}\\)) สถิตินี้มีค่าเท่ากับอัตราส่วนระหว่างความแปรปรวนรวม (total variance) ของตัวอย่างลูกโซ่ต่อความแปรปรวนภายลูกโซ่ (within-chain variance) ดังนี้\n\\(\\hat{R}=\\sqrt{\\frac{Var(\\theta)}{W}}\\)\nโดยที่ \\(Var(\\theta)=(1-\\frac{1}{m}W+\\frac{1}{m}B)\\)\n\\(W=\\frac{1}{C}\\sum_{j=1}^CS^2_j\\)\n\\(S^2_j=\\frac{1}{n-1}\\sum_{i=1}^n(\\theta_{ij}-\\overline{\\theta}_{.j})^2\\)\n\\(B = \\frac{n}{C-n}\\sum_{j=1}^C(\\overline{\\theta}_j-\\overline{\\theta}_{..})\\)\nจากสูตรของ \\(\\hat{R}\\) ข้างต้นจะเห็นว่า ถ้า \\(\\hat{R} \\approx 1\\) นั่นหมายความว่าตัวอย่างลูกโซ่ที่สร้างขึ้นแต่ละชุด มีการแจกแจงที่ใกล้เคียงกัน กล่าวคือตัวอย่างลูกโซ่ที่สร้างขึ้นมีคุณสมบัติลู่เข้าไปยังการแจกแจงความน่าจะเป็นภายหลังที่ต้องการ แต่ถ้าหาก \\(\\hat{R}>1\\) บ่งชี้ว่าตัวอย่างลูกโซ่ที่สร้างขึ้นมีการลู่ออก\nเกณฑ์การพิจารณา \\(\\hat{R}<1.1\\)\nการอนุมานเชิงสถิติด้วย posterior distribution ที่สร้างจากอัลกอริทึม MCMC\nการอนุมานเชิงสถิติอาจทำได้ 3 ลักษณะดังที่กล่าวไปแล้วในบทเรียนก่อนได้ คือ\nการประมาณค่า (estimation)\nการทำนาย (Prediction)\nการเปรียบเทียบโมเดล/การทดสอบสมมุติฐาน\nในหัวข้อนี้จะแสดงตัวอย่างการใช้ตัวอย่างสุ่มที่สร้างจากอัลกอริทึม MCMC\nการประมาณค่า\nการประมาณค่าพารามิเตอร์จากการแจกแจงความน่าจะเป็นภายหลังที่สร้างจากตัวอย่างลูกโซ่มาร์คอฟนนั้นสามารถทำได้ สองลักษณะ ลักษณะแรกคือ การประมาณค่าแบบจุด (point estimation) และลักษณะที่สองคือการประมาณค่าแบบช่วง (interval estimation) รายละเอียดมีดังนี้\nการประมาณค่าแบบจุด ในทางทฤษฎีคือการหาค่าเฉลี่ย มัธยฐาน หรือฐานนิยมของการแจกแจงความน่าจะเป็นภายหลัง โดยปกติผู้วิเคราะห์มักใช้ค่าเฉลี่ยหรือค่าคาดหวังของการแจกแจงความน่าจะเป็นภายหลังเป็นค่าประมาณแบบจุด ในทางทฤษฎีค่าคาดหวังดังกล่าวสามารถหาได้จาก\n\\(E(\\theta)=\\int \\theta p(\\theta|y) d\\theta\\)\nในทางปฏิบัติหากผู้วิเคราะห์มีตัวอย่างลูกโซ่ที่สร้างจากอัลกอริทึม MCMC แล้วค่าคาดหวังดังกล่าวสามารถประมาณได้ดังนี้\n\\(E(\\theta) \\approx \\frac{1}{n}\\sum_{i=1}^n\\theta_i\\)\n\n\nIterations = 1:5000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n               Mean      SD Naive SE Time-series SE\nmu_sdpro1    85.068 15.8021 0.223475      13.227925\nsigma_sdpro1 21.291 10.9451 0.154787      16.472555\nmu_sdpro2    99.119  0.1826 0.002582       0.008250\nsigma_sdpro2  9.944  0.1291 0.001825       0.004596\nmu_sdpro3    99.134  0.1512 0.002138       0.028234\nsigma_sdpro3  9.941  0.1132 0.001601       0.017609\n\n2. Quantiles for each variable:\n\n               2.5%    25%    50%   75% 97.5%\nmu_sdpro1    51.757 72.609 91.524 99.09 99.49\nsigma_sdpro1  9.753 10.005 19.253 33.43 36.84\nmu_sdpro2    98.770 99.002 99.116 99.25 99.47\nsigma_sdpro2  9.697  9.855  9.940 10.03 10.20\nmu_sdpro3    98.823 99.077 99.176 99.24 99.38\nsigma_sdpro3  9.693  9.879  9.948 10.01 10.15\n\nอีกลักษณะหนึ่งคือการประมาณค่าแบบช่วง การประมาณแบบช่วงสามารถทำได้หลายวิธีการ เช่นการใช้ค่า quantile เพื่อสร้างช่วงการประมาณ ดังผลลัพธ์ในคำสั่ง summary() ข้างต้น และการสร้างช่วง HDI หรือ HPD ซึ่งสามารถคำนวณได้โดยใช้ฟังก์ชัน HPDinterval() ดังนี้\n\n                 lower    upper\nmu_sdpro1    53.720434 99.71204\nsigma_sdpro1  9.662923 36.33754\nmu_sdpro2    98.763984 99.45973\nsigma_sdpro2  9.694196 10.19990\nmu_sdpro3    98.822705 99.36235\nsigma_sdpro3  9.742272 10.15352\nattr(,\"Probability\")\n[1] 0.95\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": "posts/2022-02-03-mcmc-via-jags/mcmc-via-jags_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-02-05T01:41:48+07:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to My Blog",
    "description": "Welcome to our new blog, My Blog. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Nora Jones",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-03T15:32:21+07:00",
    "input_file": {}
  }
]
