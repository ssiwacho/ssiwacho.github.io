---
title: "Prior Sensitivity Analysis"
categories:
  - Bayesian Statistics
  - Sensityvity Analysis
description: |
  การวิเคราะห์ความไวต่อการแจกแจงความน่าจะเป็นก่อนหน้า
author:
  - name: Siwachoat Srisuttiyakorn
    url: {}
date: 2022-03-10
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 2
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction

สถิติแบบเบส์เป็นสถิติวิเคราะห์อีกวิธีการหนึ่งที่มีแนวคิดแตกต่างจากสถิติวิเคราะห์แบบดั้งเดิมค่อนข้างมาก เหตุผลที่นักวิเคราะห์ข้อมูลเลือกใช้สถิติวิเคราะห์แบบเบส์แทนการวิเคราะห์แบบดั้งเดิมนั้นมีหลายเหตุผล เช่น

1. โมเดลวิเคราะห์ของผู้วิเคราะห์มีความซับซ้อนมากเกินกว่าที่วิธีการแบบดั้งเดิมจะสามารถประมาณค่าพารามิเตอร์ได้ (สิวะโชติ ศรีสุทธิยากร, 2555; Depaoli, 2013; Kim et al, 2013)

2. ตัวอย่างวิจัยมีขนาดเล็กจนเป็นปัญหาสำหรับการวิเคราะห์แบบดั้งเดิม

3. ผู้วิเคราะห์ต้องการผนวกสารสนเทศจากแหล่งอื่นเกี่ยวกับพารามิเตอร์ในโมเดล นอกเหนือจากข้อมูลเชิงประจักษ์ ในกระบวนการประมาณค่าพารามิเตอร์

4. ผู้วิเคราะห์เลือกใช้สถิติแบบเบส์เพื่อให้ได้การอนุมานเชิงสถิติที่มีความแปลความหมายที่ตรงตามความต้องการมากกว่าการใช้สถิติแบบดั้งเดิม

ไม่ว่าจะมีเหตุผลใดก็ตามที่เลือกใช้สถิติแบบเบส์ในการวิเคราะห์ ทุกการวิเคราะห์ผู้วิเคราะห์จำเป็นต้องกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ภายในโมเดลเสมอ การแจกแจงความน่าจะเป็นก่อนหน้าดังกล่าวเมื่อนำมาผนวกรวมกับฟังก์ชันภาวะความควรจะเป็นผ่านกฎของเบส์ (Bayes' rule) จะทำให้ผู้วิเคราะห์สามารถประมาณการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ได้ ซึ่งทำให้การอนุมานเชิงสถิติแบบเบส์สามารถสร้างข้อสรุปต่าง ๆ ไปที่ค่าพารามิเตอร์ของโมเดลได้โดยตรง

การแจกแจงความน่าจะเป็นก่อนหน้าเป็นส่วนที่แสดงสารสนเทศหรือความรู้ที่ผู้วิเคราะห์มีเกี่ยวกับพารามิเตอร์ต่าง ๆ ภายในโมเดลการวิเคราะห์ ทั้งนี้สารสนเทศดังกล่าวนั้นไม่ได้มีแหล่งที่มาจากข้อมูลเชิงประจักษ์ แต่มาจากแหล่งอื่น ๆ เช่น ผลการสังเคราะห์งานวิจัยหรือการวิเคราะห์อภิมานจากงานวิจัยที่เกี่ยวข้องในอดีต ประสบการณ์หรือวิจารณญานของนักวิจัยหรือผู้เชี่ยวชาญ เป็นต้น จึงทำให้การกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าดังกล่าวสามารถทำได้อย่างหลากหลายลักษณะ แม้ว่าผู้วิเคราะห์จะเลือกใช้การแจกแจงความน่าจะเป็นเดียวกันก็ยังสามารถกำหนด hyperparameter ของการแจกแจงให้มีความแตกต่างกันได้ จากสาเหตุดังกล่าวจึงเป็นผลให้การแจกแจงความน่าจะเป็นก่อนหน้า เป็นปัจจัยหนึ่งที่อาจส่งผลต่อการประมาณการแจกแจงความน่าจะเป็นภายหลังของโมเดล

โดยทั่วไปการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ในโมเดลอาจจำแนกได้เป็น 3 ประเภทได้แก่ non-informative priors (หรือเรียกว่า diffuse priors), weak priors และ informative priors การแจกแจงความน่าจะเป็นก่อนหน้าแบบ non-informative และ weak มีลักษณะคล้ายกันคือ ผู้วิเคราะห์แทบจะไม่มีสารสนเทศเกี่ยวกับพารามิเตอร์น้อยหรือมีความคลุมเครีืออยู่มากเกี่ยวกับพารามิเตอร์ดังกล่าว การแจกแจงความน่าจะเป็นก่อนหน้าในสถานการณ์นี้จึงจะมีลักษณะเป็นการแจกแจงแบบ uniform หรือ


ในการวิเคราะห์ข้อมูลแบบเบส์ ผู้วิเคราะห์ส่วนใหญ่มักพบกับปัญหา 2 ประการเกี่ยวกับการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้า คือ (1) ผู้วิเคราะห์ไม่มีเหตุผลหรือหลักฐานเพียงพอในการกำหนดการแจกแจงความน่าจะเป็นก่อหน้าแบบ informative ที่เหมาะสม และ (2) ผู้วิเคราะห์ส่วนใหญ่ทราบว่า การแจกแจงความน่าจะเป็นก่อนหน้าเป็นปัจจัยที่อาจมีอิทธิพลอย่างรุนแรงต่อการประมาณค่ารวมทั้งการอนุมานเชิงสถิติต่าง ๆ ของโมเดล ซึ่งอาจทำให้ผลการวิเคราะห์ที่ได้รับนั้นมาจากสารสนเทศในการแจกแจงความน่าจะเป็นก่อนหน้าที่กำหนดโดยผู้วิเคราะห์มากกว่าที่จะมาจากข้อมูลเชิงประจักษ์ 

จากปัญหาดังกล่าว ผู้วิเคราะห์ส่วนใหญ่จึงมักเลือกใช้การแจกแจงความน่าจะเป็นก่อนหน้าแบบ non-informative หรือ weak informative มากกว่าที่จะกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าแบบ informative โดยเชื่อว่าการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าในลักษณะดังกล่าวจะไม่ส่งผลกระทบหรือมีผลกระทบน้อยมากต่อการแจกแจงความน่าจะเป็นภายหลัง และผลกระทบดังกล่าวจะมีแนวโน้มลดลงเรื่อย ๆ เมื่อตัวอย่างที่ใช้มีขนาดใหญ่มากขึ้น กล่าวคือการแจกแจงความน่าจะเป็นภายหลังจะขึ้นกับสารสนเทศจากข้อมูลตัวอย่างที่อยู่ในฟังก์ชันภาวะความควรจะเป็น (likelihood function) แต่เพียงอย่างเดียว

อย่างไรก็ตามจากผลการวิจัยของ Ghosh และ Muherjee (1992) แสดงให้เห็นว่าการแจกแจงความน่าจะเป็นก่อนหน้าแบบ non-informative ก็อาจส่งผลกระทบต่อการแจกแจงความน่าจะเป็นภายหลังได้ในบางกรณี แม้กระทั่งตัวอย่างจะมีขนาดใหญ่ก็ตาม ซึ่งผลกระทบดังกล่าวอาจทำให้การประมาณค่าพารามิเตอร์ที่ได้มีความผิดปกติ หรือคลาดเคลื่อนไปจากค่าจริง

ในเชิงเทคนิคการประมาณค่าพารามิเตอร์ในโมเดลที่มีความซับซ้่อนมาก ๆ โดยที่ตัวอย่างมีขนาดเล็กหรือไม่เพียงพอนั้น เป็นการยากที่อัลกอริทึมการประมาณจะเฟ้นหาค่าประมาณพารามิเตอร์ที่มีความแม่นยำได้อย่างมีประสิทธิภาพ การกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าแบบ non-informative หรือ weak informative ให้กับพารามิเตอร์จึงไม่เหมาะสม เพราะทั้งในฟังก์ชันภาวะความควรจะเป็น และฟังก์ชันความน่าจะเป็นก่อนหน้าต่างก็มีสารสนเทศที่จะใช้ประมาณพารามิเตอร์ไม่เพียงพอเหมือนกัน ทำให้การหาค่าประมาณพารามิเตอร์ของโมเดลทำได้อย่างไม่มีประสิทธิภาพ และยากที่จะได้ค่าประมาณที่มีความถูกต้อง

สถิติแบบเบส์สามารถใช้แก้ปัญหาข้างต้นได้ ด้วยการเติมสารสนเทศของพารามิเตอร์ภายในโมเดลผ่านการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าแบบ informative อย่างไรก็ตามการกำหนดดังกล่าวสามารถทำได้หลายลักษณะ ขึ้นอยู่กับสมมุติฐานและสารสนเทศเกี่ยวกับพารามิเตอร์จากแหล่งข้อมูลอื่น ๆ ที่ผู้วิเคราะห์รวบรวมมาได้ ซึ่งการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าที่มีความแตกต่างกันนี้ก็อาจทำให้การแจกแจงความน่าจะเป็นภายหลังที่คำนวณได้มีความแตกต่างกันไปด้วย


จากที่กล่าวมาในข้างต้นจะเห็นว่า การแจกแจงความน่าจะเป็นก่อนหน้านั้นเป็นปัจจัยที่อาจส่งผลต่อการคำนวณการแจกแจงความน่าจะเป็นภายหลังได้ ในหลาย ๆ กรณี แม้ว่าผู้วิเคราะห์จะกำหนดการแจกแจงความน่าจะเป็นก่อนหน้านั้นเป็นแบบ non-informative ก็ตาม การวิเคราะห์ความไวต่อการแจกแจงความน่าจะเป็นก่อนหน้า (sensitivity analysis of priors) จึงเป็นขั้นตอนมาตรฐานขั้นตอนหนึ่งที่นักสถิติแบบเบส์แนะนำให้ผู้วิเคราะห์ดำเนินการ และรายงานผลการวิเคราะห์ไว้ในรายงานการวิเคราะห์ข้อมูลด้วย หัวข้อถัดไปจะกล่าวถึงความหมายและขั้นตอนในการวิเคราะห์ความไวต่อการแจกแจงความน่าจะเป็นก่อนหน้าในการวิเคราะห์แบบเบส์

# Sensitivity Analysis

การวิเคราะห์ความไว เป็นวิธีการทางสถิติที่ใช้กับโมเดลสุดท้าย (final model) ที่ใช้ตอบคำถามวิจัย เพื่อวิเคราะห์ผลกระทบที่มีต่อการแจกแจงความน่าจะเป็นภายหลังหรือการประมาณค่าพารามิเตอร์ในโมเดล เมื่อมีการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าแตกต่างกัน ขั้นตอนการวิเคราะห์นี้ค่อนข้างมีความสำคัญถึงขนาดที่นักสถิติแบบเบส์บางท่าน กำหนดให้การวิเคราะห์ความไว เป็นหนึ่งในสิ่งที่ผู้วิเคราะห์จะต้องดำเนินการ และรายงานผล (Depaoli and van de Schoot, 2017) แต่ถึงแม้การวิเคราะห์ความไวจะเป็นขั้นตอนที่มีความสำคัญ แต่การทำ systematic review โดย van de Schoot และคณะ (2017) พบว่าตั้งแต่ปี ค.ศ. 1992 มีงานวิจัยเพียงร้อยละ 16.2 ของงานวิจัยที่ใช้การวิเคราะห์แบบเบส์ทั้งหมด ที่รายงานผลการวิเคราะห์ความไวดังกล่าว

การวิเคราะห์ความไว มี 5 ขั้นตอนหลัก ได้แก่

1. กำหนดการแจกแจงความน่าจะเป็นก่อนหน้าของโมเดลวิเคราะห์ การแจกแจงความน่าจะเป็นก่อนหน้าที่กำหนดในขั้นตอนนี้จะเรียกว่า reference priors ซึ่งเป็นการแจกแจงความน่าจะเป็นก่อนหน้าที่ผู้วิเคราะห์เลือกใช้เป็นหลักสำหรับการประมาณค่าพารามิเตอร์ในโมเดล อาจเป็นได้ทั้ง non-informative prior ที่เป็นค่าเริ่มต้นของโปรแกรมสำเร็จรูปต่าง ๆ หรือกำหนดแบบ informative โดยใช้สารสนเทศจากแหล่งข้อมูลอื่น ๆ เข้ามาช่วยกำหนดก็ได้

2. ประมาณค่าพารามิเตอร์ของโมเดล และตรวจสอบการลู่เข้าของพารามิเตอร์ทั้งหมด

3. กำหนด competing priors ที่เบี่ยงเบนหรือแตกต่างไปจาก reference priors การวิเคราะห์ความไวนี้ไม่ได้มีวัตถุประสงค์เพื่อเปรียบเทียบประสิทธิภาพระหว่างการกำหนด prior ที่แตกต่างกัน แต่วัตถุประสงค์หลักคือการวิเคราะห์ความเปลี่ยนแปลง/ความแกร่งของผลการวิเคราะห์ที่ได้เมื่อกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าในลักษณะต่าง ๆ 

4. ประมาณค่าพารามิเตอร์ในโมเดลที่มีการกำหนด competing priors จากนั้นเปรียบเทียบกับโมเดลต้นฉบับในข้อ 1. เพื่อวิเคราะห์ความไวหรือการเปลี่ยนแปลงของการแจกแจงความน่าจะเป็นภายหลังในแต่ละลักษณะของ priors

การนำเสนอผลการวิเคราะห์ความไวสามารถทำได้ทั้งในรูปแบบทัศนภาพข้อมูล และรูปแบบผลการวิเคราะห์เชิงตัวเลข ผลการวิเคราะห์ที่ได้อาจมีได้หลายลักษณะ ลักษณะแรกคือ priors ที่กำหนดมีลักษณะแตกต่างกัน แต่การแจกแจงความน่าจะเป็นภายหลังที่คำนวณได้จาก prior แต่ละแบบไม่แตกต่างกันมากนัก กรณีเช่นนี้สรุปได้ว่าผลการวิเคราะห์ที่ได้มีความแกร่งต่อการกำหนด priors ที่แตกต่างกัน ผลการการประมาณค่าพารามิเตอร์ภายในโมเดลดังกล่าว จึงมีความน่าเชื่อถือสูง เพราะไม่ว่าจะกำหนด prior แบบใดก็ตาม ข้อสรุปที่ได้ก็ยังไม่เปลี่ยนแปลง

ลักษณะที่สองเป็นสถานการณ์ที่กลับกัน กล่าวคือหากผู้วิเคราะห์พบว่า การแจกแจงความน่าจะเป็นภายหลังมีลักษณะที่เปลี่ยนแปลงไปอย่างมีนัยสำคัญเมื่อการแจกแจงความหน้าจะเป็นก่อนหน้ามีความแตกต่างกัน กรณีเช่นนี้ผลการวิเคราะห์ความไวอาจให้สารสนเทศกับผู้วิเคราะห์ว่า ผลการวิเคราะห์ที่ได้รับมีความแตกต่างกันไปตามข้อสมมุติหรือทฤษฎีที่นักวิจัยใช้ประกอบการกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าแต่ละชุด ผลการวิเคราะห์ความไวเช่นนี้ไม่ได้แปลว่าเกิดปัญหาขึ้นในการวิจัย แต่เป็นการแจ้งเตือนผู้วิเคราะห์ให้ระมัดระวังขอบเขตของการนำผลการวิเคราะห์/ผลการวิจัย ที่ได้ไปใช้งาน และอาจจะต้องมีการอภิปรายผลที่ได้ดังกล่าวในส่วนของการอภิปรายผลด้วย
 
หากการแจกแจงความน่าจะเป็นก่อนหน้าที่นำมาเปรียบเทียบกันมีความแตกต่างกันเพียงเล็กน้อย แต่การแจกแจงความน่าจะเป็นภายหลังที่คำนวณได้นั้นมีความแตกต่างกันอย่างมากจนผิดสังเกต กรณีเช่นนี้เป็นไปได้ว่าอาจเกิดความผิดพลาดในการเขียนคำสั่งหรือการะบุโมเดลวิเคราะห์ 

# Example


[ชุดข้อมูลตัวอย่าง](https://drive.google.com/file/d/1sLZq4RZ2IywV2O9UEG-ffmcxc0k7-QEu/view?usp=sharing)

```{r echo=TRUE}
dat<-read.csv("/Users/siwachoat/Documents/myblog/myblog/_posts/2022-02-19-glm1/regression_dat1.csv")
set.seed(123)
sample<-sample(1:400,20)
dat<-dat[sample,]
head(dat)

```

สมมุติว่าโมเดลสุดท้ายที่ผู้วิเคราะห์จะใช้เพื่อตอบคำถามวิจัยคือ

$Score_i = \beta_0+\beta_1Hour_i+ \beta_2Home.Status_i+\epsilon_i$

จากโมเดลข้างต้นจะเห็นว่ามีพารามิเตอร์จำนวน 4 ตัวได้แก่ สัมประสิทธิ์จุดตัดแกน 1 ตัว สัมประสิทธิ์ความชัน 2 ตัว และความแปรปรวนของความคลาดเคลื่อนสุ่มอีก 1 ตัว การวิเคราะห์ความไวเป็นการวิเคราะห์การเปลี่ยนแปลงที่เกิดขึ้นในการแจกแจงความน่าจะเป็นภายหลังของพารามิเตอร์ดังกล่าว เมื่อกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าให้มีความแตกต่างกัน ในทางปฏิบัติผู้วิเคราะห์อาจไม่จำเป็นต้องดำเนินการวิเคราะห์ความไวของพารามิเตอร์ให้ครบทุกตัวก็ได้ แต่อาจะเลือกวิเคราะห์เฉพาะบางพารามิเตอร์ที่มีความสำคัญ เช่นในกรณีนี้อาจทำการวิเคราะห์ความไวของพารามิเตอร์เพียง 2 ตัว ได้แก่ สัมประสิทธิ์ความชันของตัวแปร Hour และ Class.Behav 

การวิเคราะห์ความไวอาจดำเนินการตามขั้นตอนต่อไปนี้

### 1. กำหนด reference prior และ competing prior ของพารามิเตอร์ในโมเดล

พารามิเตอร์ตัวแรกคือสัมประสิทธิ์ความชันของตัวแปร Hour ซึ่งใช้แสดงผลของตัวแปร Hour ที่มีต่อคะแนนสอบ Score ของนักเรียน การกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์นี้สามารถกำหนดได้ด้วยฟังก์ชันความน่าจะเป็นหลายตัว เช่น การแจกแจงแบบ uniform การแจกแจงแบบปกติ และการแจกแจงแบบที เป็นต้น ในกรณีนี้กำหนดให้การแจกแจงความน่าจะเป็นก่อนหน้าของพารามิเตอร์ $\beta_1$ สำหรับการวิเคราะห์ความไวเป็นดังนี้

- reference prior: $\beta_1 \sim N(\mu=0, \sigma^2=10)$ สังเกตว่า reference prior นี้มีลักษณะเป็น weak informative รอบค่าเฉลี่ยเท่ากับ 0 การกำหนดการแจกแจงความน่าจะเป็นก่อนหน้าลักษณะนี้สะท้อนว่า ทฤษฎีหรือความรู้เกี่ยวกับพารามิเตอร์ตัวนี้ที่นักวิจัยใช้อ้างอิง เชื่อว่าตัวแปร Hour น่าจะไม่มีผลต่อคะแนนสอบของนักเรียน โดย อย่างไรก็ตามด้วยความที่น้ำหนักของทฤษฎีหรือความรู้ดังกล่าวอาจจะมีไม่มากนัก จึงกำหนดให้ความแปรปรวนของการแจกแจงนี้มีค่ามาก


- competing prior1: $\beta_1 \sim N(4,6^2)$ นักวิจัยอาจทบทวนวรรณกรรมจากงานวิจัยอีกกลุ่มหนึ่งที่มีผลวิจัยแตกต่างไปจากงานวิจัยที่ใช้ support reference prior โดยพบว่างานวิจัยในกลุ่มมีรายงานสัมประสิทธิ์ความชันมาตรฐาน (standardized regression coefficient) ของตัวแปร Hour ที่มีต่อ Score ไว้โดยมีค่าเฉลี่ยประมาณ 0.718 และมีส่วนเบี่ยงเบนมาตรฐานประมาณ 1 หน่วย จากการทบทวนวรรณกรรมนี้เมื่อแปลงเป็นค่าเฉลี่ยและความแปรปรวนของการแจกแจงความน่าจะเป็นก่อนหน้าของสัมประสิทธิ์ความชันแบบคะแนนดิบจะมีค่าเท่ากับ $0.718 \times \frac{SD_{Score}}{SD_{Hour}}=0.718 \times \frac{18.41488}{3.305527} \approx 4$ และ $1  \times \frac{SD_{Score}}{SD_{Hour}} \approx 6$ ตามลำดับ

- competing prior2: $\beta_1 \sim N(10,3^2)$ การกำหนด prior แบบนี้อาจเป็นเพราะนักวิจัยไปทบทวนวรรณกรรมอีกกลุ่มหนึ่งแล้วพบว่า อิทธิพลของ Hour ที่มีต่อ Score เป็นอิทธิพลทางบวกที่มีค่าสูงมาก ... เป็นต้น



พารามิเตอร์ตัวที่สองคือ สัมประสิทธิ์ความชันของตัวแปร Class.Behav ซึ่งใช้แสดงอิทธิพลของพฤติกรรมในชั้นเรียนที่มีต่อคะแนนสอบของนักเรียน ในกรณีนี้ผู้วิเคราะห์กำหนด reference prior และ competing prior ตามผลการทบทวนวรรณกรรม เป็นดังนี้

- reference prior: $\beta_2 \sim N(5,1)$

- competing prior 1: $\beta_2 \sim N(0,20)$

- competing prior 2: $\beta_2 \sim N(0,10)$

รูปต่อไปนี้แสดงการเปรียบเทียบ prior ของพารามิเตอร์สัมประสิทธิ์ความชันทั้งสองในข้างต้น

```{r layout="l-body-outset",fig.height=4, fig.width=9, echo=T}
library(dplyr)
library(ggplot2)
library(gridExtra)

x <- seq(-20, 20, length.out = 100)
p1<-data.frame(x,  f = dnorm(x)) %>%
     ggplot(aes(x, f)) +
     stat_function(fun=dnorm, args=list(mean=4, sd=6),
                   geom="area",col="black", lty=1, aes(fill="steelblue4"), alpha=0.6)+
     stat_function(fun=dnorm, args=list(mean=0, sd=10),
                   geom="area",col="black", lty=1, aes(fill="tan"), alpha=0.6)+
     stat_function(fun=dnorm, args=list(mean=10, sd=3),
                   geom="area",col="black", lty=1, aes(fill="tomato4"), alpha=0.6)+
     theme_minimal()+
     ylab("Density")+xlab(expression(beta[1]))+
     scale_fill_identity(guide="legend",
                         name="Priors",
                         breaks=c("tan","steelblue4","tomato4"),
                         labels=c("Reference prior",
                                  "Competing prior 1",
                                  "Competing prior 2"))

p2<-data.frame(x,  f = dnorm(x)) %>%
     ggplot(aes(x, f)) +
     stat_function(fun=dnorm, args=list(mean=0, sd=20),
                   geom="area",col="black", lty=1, aes(fill="steelblue4"), alpha=0.6)+
     stat_function(fun=dnorm, args=list(mean=5, sd=1),
                   geom="area",col="black", lty=1, aes(fill="tan"), alpha=0.6)+
     stat_function(fun=dnorm, args=list(mean=0, sd=5),
                   geom="area",col="black", lty=1, aes(fill="tomato4"), alpha=0.6)+
     theme_minimal()+
     ylab("Density")+xlab(expression(beta[2]))+
     scale_fill_identity(guide="legend",
                         name="Priors",
                         breaks=c("tan","steelblue4","tomato4"),
                         labels=c("Reference prior",
                                  "Competing prior 1",
                                  "Competing prior 2"))

grid.arrange(p1,p2, ncol=2)
```


### 2. ประมาณพารามิเตอร์ในโมเดลและตรวจสอบการลู่เข้าของพารามิเตอร์ในโมเดล

การแจกแจงความน่าจะเป็นก่อนหน้าที่กำหนดอย่างไม่เหมาะสมหรือมีความขัดแย้งกับข้อมูลจริงมากเกินไป อาจส่งผลต่อการลู่เข้าของพารามิเตอร์ การประมาณค่าพารามิเตอร์ในตัวอย่างนี้จะใช้ package-brms 

ผลการตรวจสอบการลู่เข้าด้านล่างพบว่า พารามิเตอร์ทุกตัวในทั้ง 3 โมเดล มีคุณสมบัติลู่เข้าสู่การแจกแจงสถานะคงที่ทั้งหมด

```{r echo=TRUE, warning=F, message=F}
library(brms)

### reference priors model
prior.refer<-get_prior(Score ~ Hour+Class.Behav, data=dat,
              family=gaussian())

# default priors
prior.refer

# priors specification
prior.refer[[1]][2]<-"normal(0,10)" #prior for beta1
prior.refer[[1]][3]<-"normal(5,1)" #prior for beta2
```

```{r results=F, message=F, warnings=F, echo=TRUE}
fit.refer<-brm(Score~Hour+Class.Behav, data=dat,
                   family=gaussian(),
                   prior=prior.refer,
                   warmup=1000,
                   iter=3000,
                   chains=3,
                   cores=10,
                   silent=0)


### competing priors model 1
prior.com1<-get_prior(Score ~ Hour+Class.Behav, data=dat,
              family=gaussian())

# priors specification
prior.com1[[1]][2]<-"normal(4,6)" #prior for beta1
prior.com1[[1]][3]<-"normal(0,20)" #prior for beta2

fit.com1<-brm(Score~Hour+Class.Behav, data=dat,
                   family=gaussian(),
                   prior=prior.com1,
                   warmup=1000,
                   iter=3000,
                   chains=3,
                   cores=10,
                   silent=0)

### competing priors model 2
prior.com2<-get_prior(Score ~ Hour+Class.Behav, data=dat,
              family=gaussian())

# priors specification
prior.com2[[1]][2]<-"normal(10,3)" #prior for beta1
prior.com2[[1]][3]<-"normal(0,10)" #prior for beta2

fit.com2<-brm(Score~Hour+Class.Behav, data=dat,
                   family=gaussian(),
                   prior=prior.com2,
                   warmup=1000,
                   iter=3000,
                   chains=3,
                   cores=10,
                   silent=0)

```


ผลการวิเคราะห์ต่อไปนี้ใช้ตรวจสอบคุณภาพหรือการลู่เข้าของลูกโซ่มาร์คอฟของพารามิเตอร์ที่สร้างขึ้นจากกระบวนการ MCMC

```{r echo=T}
library(MCMCvis)
MCMCtrace(fit.refer, 
          params=c("Intercept","Hour","Class.Behav","sigma"),
          pdf=F, type="trace", Rhat=TRUE, n.eff=TRUE)

MCMCtrace(fit.com1, 
          params=c("Intercept","Hour","Class.Behav","sigma"),
          pdf=F, type="trace", Rhat=TRUE, n.eff=TRUE)

MCMCtrace(fit.com2, 
          params=c("Intercept","Hour","Class.Behav","sigma"),
          pdf=F, type="trace", Rhat=TRUE, n.eff=TRUE)
```

### 3. เปรียบเทียบ posterior distribution จากทั้ง 3 โมเดล

ขั้นตอนสุดท้ายเป็นการเปรียบเทียบ posterior distribution ระหว่างโมเดลทั้ง 3 การเปรียบเทียบดังกล่าวสามารถทำได้สองลักษณะ คือการเปรียบเทียบโดยใช้ทัศนภาพข้อมูล และการเปรียบเทียบเชิงตัวเลข ผลการวิเคราะห์ต่อไปนี้แสดงการเปรียบเทียบด้วยทัศนภาพข้อมูล โดยใช้แผนภาพความหนาแน่น

```{r message=F, layout="l-body-outset",fig.height=4, fig.width=9, echo=T}
library(coda)
library(tidyr)
refer<-data.frame(as.mcmc(fit.refer, combine_chains=TRUE))
com1<-data.frame(as.mcmc(fit.com1, combine_chains=TRUE))
com2<-data.frame(as.mcmc(fit.com2, combine_chains=TRUE))

refer$model<-1
com1$model<-2
com2$model<-3

combine<-rbind(refer, com1 ,com2)
p1<-combine%>%
  ggplot(aes(x=b_Intercept, y=..density.., fill=factor(model)))+
  geom_density(alpha=0.6)+
  xlab(expression(beta[0]))+
  scale_fill_identity(guide="legend",
                         name="Posterior",
                         labels=c("Reference prior",
                                  "Competing prior 1",
                                  "Competing prior 2"))

p2<-combine%>%
  ggplot(aes(x=b_Hour, y=..density.., fill=factor(model)))+
  geom_density(alpha=0.6)+
  xlab(expression(beta[1]))+
  scale_fill_identity(guide="legend",
                         name="Posterior",
                         labels=c("Reference prior",
                                  "Competing prior 1",
                                  "Competing prior 2"))

p3<-combine%>%
  ggplot(aes(x=b_Class.Behav, y=..density.., fill=factor(model)))+
  geom_density(alpha=0.6)+
  xlab(expression(beta[2]))+
  scale_fill_identity(guide="legend",
                         name="Posterior",
                         labels=c("Reference prior",
                                  "Competing prior 1",
                                  "Competing prior 2"))

p4<-combine%>%
  ggplot(aes(x=sigma, y=..density.., fill=factor(model)))+
  geom_density(alpha=0.6)+
  xlab(expression(sigma[epsilon]))+
  scale_fill_identity(guide="legend",
                         name="Priors",
                         labels=c("Reference prior",
                                  "Competing prior 1",
                                  "Competing prior 2"))

grid.arrange(p1,p2,p3,p4, ncol=2, nrow=2)
```

ผลการวิเคราะห์ข้างต้นจะเห็นว่าในภาพรวม competing prior ทำให้เกิดความแตกต่างในการประมาณ posterior distribution โดยเฉพาะของพารามิเตอร์ slope อย่างไรก็ตามผลการวิเคราะห์ดังกล่าวอาจจะยังให้รายละเอียดที่เป็นภาพใหญ่ การสรุปผลเกี่ยวกับความแตกต่างระหว่าง posteior อาจจะต้องการผลการวิเคราะห์อื่น ๆ ประกอบเพิ่มเติม เช่น การเปรียบเทียบด้วย boxplot ร่วมกับ stripplot และ violin plot (เป็นแบบฝึกหัดให้ผู้อ่าน)

อีกลักษณะหนึ่งคือการเปรียบเทียบเชิงตัวเลข โดยใช้โมเดลที่กำหนด reference prior เป็นค่าอ้างอิงของโมเดลที่กำหนด competing prior การเปรียบเทียบดังกล่าวอาจใช้ร้อยละของความเบี่ยงเบนเมื่อเปรียบเทียบกับผลการประมาณเมื่อกำหนด reference prior ดังตัวอย่างด้านล่าง


```{r echo=TRUE}
library(kableExtra)
compair1<-combine%>%
          group_by(model)%>%
          summarise(intercept= mean(b_Intercept),
                    beta1 = mean(b_Hour),
                    beta2 = mean(b_Class.Behav),
                    sigma = mean(sigma))%>%t()%>%
          data.frame()
compair1<-compair1[-1,]
names(compair1)<-c("reference","competing1","competing2")

compair1%>%mutate(percent_r1=(competing1-reference)*100/reference,
                 percent_r2=(competing2-reference)*100/reference)%>%
kable(digits=3,
      col.names=c("Reference Priors",
                  "Competing1",
                  "Competing2",
                  "Competing1 vs Reference",
                  "Competing2 vs Reference"))%>%
  kable_styling(font_size=10)%>%
  add_header_above(c(" "=1, "Posterior Means"=3, "Percentage Deviation"=2))
```



```{r echo=TRUE}
compair2<-combine%>%
          group_by(model)%>%
          summarise(intercept= sd(b_Intercept),
                    beta1 = sd(b_Hour),
                    beta2 = sd(b_Class.Behav),
                    sigma = sd(sigma))%>%t()%>%
          data.frame()
compair2<-compair2[-1,]
names(compair2)<-c("reference","competing1","competing2")

compair2%>%mutate(percent_r1=(competing1-reference)*100/reference,
                 percent_r2=(competing2-reference)*100/reference)%>%
kable(digits=3,
      col.names=c("Reference Priors",
                  "Competing1",
                  "Competing2",
                  "Competing1 vs Reference",
                  "Competing2 vs Reference"))%>%
  kable_styling(font_size=10)%>%
  add_header_above(c(" "=1, "Posterior SD"=3, "Percentage Deviation"=2))

```


นอกจากการเปรียบเทียบด้วยค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐานภายหลังแล้ว ยังสามารถเปรียบเทียบจากช่วง HPD ก็ได้ ดังนี้

```{r echo=TRUE}
par(family="ChulaCharasNew")
MCMCplot(fit.com1, fit.refer, params=c("Intercept","Hour","Class.Behav","sigma"), HPD=TRUE)
MCMCplot(fit.com2, fit.refer, params=c("Intercept","Hour","Class.Behav","sigma"), HPD=TRUE)

```

--- 


Distill is a publication format for scientific and technical writing, native to the web.

Learn more about using Distill at <https://rstudio.github.io/distill>.


