<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>ML: สัปดาห์ที่ 2:  Linear Regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="อ.ดร.สิวะโชติ ศรีสุทธิยากร" />
    <script src="week2_files/header-attrs/header-attrs.js"></script>
    <script src="week2_files/kePrint/kePrint.js"></script>
    <link rel="stylesheet" href="xaringan-themer1.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# ML: สัปดาห์ที่ 2: </br> Linear Regression
### อ.ดร.สิวะโชติ ศรีสุทธิยากร

---


class: center, middle






&lt;img src="Asset 1.png", width=30%&gt;



---
class: middle, center, inverse


&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/aaOB-ErYq6Y" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;


---
class: middle

.left-column[

### Supervised Learning

&lt;section style="font-size:14px;"&gt;
เป็นการเรียนรู้รูปแบบความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระที่พบเจอในชุดข้อมูลฝึกหัด (training dataset) และสร้างโมเดลทางสถิติที่เหมาะสมเพื่อทำนาย (predicting) หรือคาดการณ์ผลลัพธ์ (output) ของตัวแปรตาม ด้วยข้อมูลของตัวแปรอิสระ
&lt;/section&gt;

&lt;img src="XY.png"&gt;

]

.right-column[

Supervised Learning จำแนกได้เป็นสองประเภทตามลักษณะของตัวแปรตาม

- **Regression** (สำหรับตัวแปรตามแบบต่อเนื่อง)

- **Classification** (สำหรับตัวแปรตามแบบจัดประเภท)

.pull-left[

&lt;small&gt;

การพัฒนา supervised learning model หรืออาจเรียกว่า predictive model มีขั้นตอนดังนี้

1. Problem Definition

2. Hypothesis Generation

3. Data Collection

4. Data Exploration and Preparation

5. Developing ML model

6. Model Implementation

&lt;/small&gt;
]


.pull-right[
&lt;/br&gt;

&lt;img src="modeling.png" width=100%&gt;
]

]

---
class: middle, center

&lt;img src="predict.png" width=70%&gt;




---
class: middle

.left-column[

### Types of Regression

&lt;small&gt;
regression เป็น area ที่ใหญ่ โดยสามารถจำแนกเป็นโมเดล regression ย่อย ๆ ได้หลากหลายโมเดล ทั้งนี้ขึ้นอยู่กับลักษณะค่าสังเกตของตัวแปรตาม และลักษณะความสัมพันธ์โดยธรรมชาติระหว่างตัวแปรตามกับตัวแปรอิสระ
&lt;/small&gt;
]


.right-column[
&lt;table class="table" style="font-size: 12px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; ประเภท &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; ลักษณะการใช้งาน &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Simple linear &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting a quantitative response variable from quantitative/qualitative explanatory variable. &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Polynomial &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting a quantitative response variable from quantitative explanatory variable when the relationship is modeled as an nth order polynomial &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Multiple Linear &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting a quantitative response variable from two or more quantitative/qualitative explanatory variables. &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Multilevel &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting a response variable from data that have hierarchical structure. &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Multivariate &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting more than one response variables from one and more explanatory variables. &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Logistic &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting a categorical response variable from one or more explanatory variables. &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Poisson &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting a response variable representing counts from one or more explanatory variables. &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Cox proportaional hazards &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting time to event (death, failure,...) from one or more explanatory variables. &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Time-series &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Modeling time-series data with correlated errors. &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Nonlinear &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting a quantitative response variable from one or more explanatory variables, where the form of the model is nonlinear. &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Nonparametric &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting a quantitative response variable from one or more explanatory variables, where the form of the model is derived from the data and not specified a priori, &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; Robust &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predicting a quantitative response variable from one or more explanatory variables using an approach that's resistant to the effect of influential observtions. &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

---
class: middle


.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* Evaluating Models

* Multiple Regression

]

---
class: middle


.left-column[

## Linear Regression


* **Basic Concepts**

* Training Models

* Evaluating Models

* Multiple Regression

]



.right-column[


**Linear regression**

&lt;small&gt;

 เป็นโมเดลการเรียนรู้ที่ classic และง่ายที่สุด วัตถุประสงค์ของการวิเคราะห์อาจจำแนกเป็นสองด้าน

* อธิบายความสัมพันธ์เชิงสาเหตุระหว่างตัวแปรอิสระ (independent variables) กับตัวแปรตาม (dependent variables) 

* ทำนายแนวโน้มการเกิดค่าสังเกตของตัวแปรตาม โดยใช้ linear combination

&lt;/small&gt;

`$$\hat{y}=b_0+b_1x_1+b_2x_2+...+b_px_p \approx y$$`
&lt;small&gt;
เมื่อ `\(y\)` คือค่าสังเกตจริงของตัวแปรตาม, `\(x\)` คือค่าสังเกตจริงของตัวแปรอิสระ, `\(b_j\)` คือสัมประสิทธิ์การถดถอย (regression coefficients) และ `\(\hat{y}\)` คือค่าทำนายตัวแปรตาม `\(y\)` โดยที่ สัมประสิทธิ์ภายใน linear combination ประมาณได้จากข้อมูลค่าสังเกตค่าด้วยอัลกอริทึมการเรียนรู้ เช่น least squares method 
&lt;/small&gt;
]


--

.right-column[

**Simple Linear Regression**

.pull-left[
&lt;small&gt;
ฝ่าย HR ของมหาวิทยาลัยต้องการพัฒนาโมเดลทำนายเงินเดือนของอาจารย์ (Salary) ด้วยประสบการณ์ในการทำงานด้านวิชาการของอาจารย์ (YearsExperience) ทั้งนี้เพื่อใช้เป็นสารสนเทศประกอบการกำหนดข้อเสนอการจ้างงานสำหรับอาจารย์ใหม่ของมหาวิทยาลัย
&lt;/small&gt;
]

.pull-right[
&lt;img src="simreg.png", width=100%&gt;

]


]



---
class: middle


.left-column[

## Linear Regression


* **Basic Concepts**

* Training Models

* Evaluating Models

* Multiple Regression

]


.right-column[

.pull-left[
&lt;/br&gt;

&lt;img src="week2_files/figure-html/unnamed-chunk-2-1.png" width="504" /&gt;&lt;img src="week2_files/figure-html/unnamed-chunk-2-2.png" width="504" /&gt;
]

.pull-right[

&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;


**no relationship between y and x**


&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;

**linear relationship between y and x**

- 1st linear combination: 

`$$\hat{y}=\bar{y}+0x$$`

- 2nd linear combination: 

`$$\hat{y}=19+1.5x$$`

]

]

---
class: middle


.left-column[

## Linear Regression


* **Basic Concepts**

* Training Models

* Evaluating Models

* Multiple Regression

]


.right-column[


### Y = signal + noise

- **signal** = some math function ---&gt; eg. linear function: `\(f(x)=\beta_0+\beta_1x\)`

- **noise** = random error ---&gt; `\(\epsilon_i=y_i-\hat{y}_i\)` ---&gt; `\(\sigma^2\)`


.pull-left[
&lt;img src="week2_files/figure-html/unnamed-chunk-3-1.png" width="504" /&gt;
]

.pull-right[

&lt;small&gt;

* `\(f(x)\)` ที่กำหนดในแต่ละการวิเคราะห์เป็นสมมุติฐาน ซึ่งมีความเป็นไปได้สูงที่จะไม่ใช่โมเดลจริงของประชากร

* อัลกอริทึมการเรียนรู้จะประมาณค่าพารามิเตอร์ภายในฟังก์ชัน `\(f(x)\)` เพื่อปรับเหมาะให้ฟังก์ชันดังกล่าวสามารถเรียนรู้ความสัมพันธ์ระหว่างตัวแปรใน traning data ได้ดีที่สุด

* `\(b_1 \approx \beta_1\)` คือพารามิเตอร์ความชัน (slope) ---&gt; `\(\frac{\Delta\overline{y}}{\Delta{x}}\)`

* `\(b_0 \approx \beta_0\)` คือพารามิเตอร์จุดตัดแกน (intercept)

 
&lt;/small&gt;

]
]


---
class: middle


.left-column[

## Linear Regression


* Basic Concepts

* **Training Models**

* Evaluating Models

* Multiple Regression


&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;

&lt;small&gt;
**Note:** ภาษา ML เรียก `\(SSE=\sum_{i=1}^n(y_i-\hat{y}_i)^2\)` ว่า ฟังก์ชันความสูญเสีย (Loss function)
&lt;/small&gt;
]

.right-column[

&lt;small&gt;

### Least Squares Algorithm

เป็นวิธีประมาณค่าโดยตรง วิธีนี้จะคำนวณหาค่าชุดของพารามิเตอร์ที่ดีที่สุดของโมเดลที่ทำให้โมเดลมีความสอดคล้องกับ training data มากที่สุด (ie. optimize intercept and slope parameter of the model) การคำนวณค่าประมาณพารามิเตอร์ดังกล่าวจะคำนวณด้วยสูตรปิด (closed form)

`$$\min_{\beta}SSE \rightarrow b=(X^TX)^{-1}(X^TY)$$`


### Gradient Descent Algorithm

เป็น iterative optimization approach กล่าวคือไม่ได้มีสูตรปิดตายตัวสำหรับหาค่าประมาณพารามิเตอร์ แต่จะใช้การทวนซ้ำเพื่อหาชุดของค่าพารามิเตอร์ที่เป็นคำตอบที่ดีที่สุด
1. กำหนด model และค่าเริ่มต้นของพารามิเตอร์ภายในโมเดล (initial value)

2. คำนวณค่า 1st order derivative ของ Loss function ของโมเดลด้วยค่าพารามิเตอร์ที่กำหนด (derivative=0 หรือไม่?)

3. ถ้า derivative `\(\neq0\)` แทนพารามิเตอร์ค่าใหม่ ดังนี้ `\(new = old-stepSize\)` `\((stepSize = derivative \times LearningRate)\)`

4. ทวนซ้ำขั้นตอนที่ 2 และ 3 จนกระทั่ง derivative `\(=0\)`

&lt;/small&gt;

]



---
name: yourturn
template: section

.left-column[
# .fancy[Your turn]
]
---
name: yourturn1
template: yourturn


.right-column[

### Training Simple Regression Model

&lt;small&gt;
ฝ่าย HR ของมหาวิทยาลัยต้องการพัฒนาโมเดลทำนายเงินเดือนของอาจารย์ (Salary) ด้วยประสบการณ์ในการทำงานด้านวิชาการของอาจารย์ (YearsExperience) ทั้งนี้เพื่อใช้เป็นสารสนเทศประกอบการกำหนดข้อเสนอการจ้างงานสำหรับอาจารย์ใหม่ของมหาวิทยาลัย



1. นำชุดข้อมูล [datasets_Salary_Data.csv](https://drive.google.com/file/d/11v2nEFVj2wfYfwruVgCUlu5eWiyJrYN6/view?usp=sharing) เข้าสู่ R

2. สำรวจข้อมูลเบื้องต้นด้วยฟังก์ชัน `summary()` และ `str()`

3. สร้าง scatter plot เพื่อสำรวจความสัมพันธ์ระหว่าง `Salary` กับ `YearsExperience` (นิสิตคิดว่าสามารถ fit linear model ให้กับข้อมูลชุดนี้ได้หรือไม่?)

4. แบ่งข้อมูลออกเป็น 2 ส่วนอย่างสุ่ม ได้แก่ trainning data และ testing data ด้วยอัตราส่วน 80:20

5. ประมาณค่าพารามิเตอร์ในโมเดลด้วย least squares algorithm โดยใช้ฟังก์ชัน `lm()`

6. ประเมินคุณภาพของโมเดล

&lt;/small&gt;
]

---
name: yourturn1
template: yourturn

### Importing and Exploring Data



```r
dat&lt;-read.csv("datasets_Salary_Data.csv")
summary(dat)
```



```
##  YearsExperience      Salary      
##  Min.   : 1.100   Min.   : 37731  
##  1st Qu.: 3.200   1st Qu.: 56721  
##  Median : 4.700   Median : 65237  
##  Mean   : 5.313   Mean   : 76003  
##  3rd Qu.: 7.700   3rd Qu.:100545  
##  Max.   :10.500   Max.   :122391
```


```r
str(dat)
```

```
## 'data.frame':	30 obs. of  2 variables:
##  $ YearsExperience: num  1.1 1.3 1.5 2 2.2 2.9 3 3.2 3.2 3.7 ...
##  $ Salary         : num  39343 46205 37731 43525 39891 ...
```



---
name: yourturn1
template: yourturn

### Exploring Data



```r
library(ggplot2)
library(dplyr)

dat%&gt;%ggplot(aes(x=YearsExperience,y=Salary))+
        geom_point(size=2)
```


&lt;img src="week2_files/figure-html/unnamed-chunk-8-1.png" width="648" /&gt;


---
name: yourturn1
template: yourturn

### Splitting Data


```r
set.seed(123)# specify the initial seed
dat$id&lt;-1:30 # create ID
train.id&lt;-sample(dat$id,0.8*30) #random sampling 80% of data
train.dat&lt;-dat[train.id,] # training data
test.dat&lt;-dat[-train.id,] # test data
```



```r
str(train.dat)
```

```
## 'data.frame':	24 obs. of  3 variables:
##  $ YearsExperience: num  4.5 5.9 4.1 1.5 3.7 5.3 7.1 3.9 2.2 6 ...
##  $ Salary         : num  61111 81363 57081 37731 57189 ...
##  $ id             : int  15 19 14 3 10 18 22 11 5 20 ...
```


```r
str(test.dat)
```

```
## 'data.frame':	6 obs. of  3 variables:
##  $ YearsExperience: num  1.3 2.9 4 4 4.9 10.3
##  $ Salary         : num  46205 56642 55794 56957 67938 ...
##  $ id             : int  2 6 12 13 16 29
```

---
name: yourturn1
template: yourturn

### Training Simple Regression Model

&lt;small&gt;
ฟังก์ชันพื้นฐานสำหรับประมาณค่าพารามิเตอร์ใน Linear regression model คือ `lm()` ที่มีรูปแบบการเขียนคำสั่งพื้นฐานดังนี้

&lt;/small&gt;

`fit&lt;-lm(formula, data)`

&lt;small&gt;
โดยที่ `formula` คืออาร์กิวเมนท์สำหรับระบุรูปแบบของ training model โดยเขียนในรูปแบบ `y~x1+x2+x3` และ `data` คือชุดข้อมูล (data.frame) ที่ต้องประกอบด้วยค่าสังเกตของตัวแปรตามและตัวแปรอิสระ
&lt;/small&gt;



&lt;center&gt;
&lt;img src="extract.png" width=75%&gt;
&lt;/center&gt;


---
name: yourturn1
template: yourturn

&lt;/br&gt;

&lt;small&gt;

```r
fit&lt;-lm(Salary~YearsExperience, data=train.dat)
summary(fit) #extract training model information
```

```
## 
## Call:
## lm(formula = Salary ~ YearsExperience, data = train.dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8231.8 -4239.8  -160.2  3747.9 11063.2 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      25437.1     2628.7   9.677 2.19e-09 ***
## YearsExperience   9573.3      427.3  22.405  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5769 on 22 degrees of freedom
## Multiple R-squared:  0.958,	Adjusted R-squared:  0.9561 
## F-statistic:   502 on 1 and 22 DF,  p-value: &lt; 2.2e-16
```
&lt;/small&gt;

---
class: middle


.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;- In-sample fit&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]


.right-column[

### In-sample fit (model validation)

&lt;small&gt;
Model validation is defined within regulatory guidance as “the set of processes and activities intended to verify that models are performing as expected, in line with their design objectives, and business uses.” It also identifies “potential limitations and assumptions, and assesses their possible impact.” (Khurana, 2019)
&lt;/small&gt;

.pull-left[

&lt;img src="assumption.png"&gt;
]

.pull-right[
&lt;/br&gt;

**Linear regression's assumptions**

&lt;small&gt;
1. Linearity (correct functional form)
2. Normality
3. Independence
4. Homoskedasticity
5. No outliers
6. No Multicollinearity (for MRA)
&lt;/small&gt;
]

&lt;small&gt;
**Note:** ในทางปฏิบัติผู้วิเคราะห์สามารถใช้การวิเคราะห์เศษเหลือ (residual analysis) เพื่อ validate training model
&lt;/small&gt;
]


---
class: middle


.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]

.right-column[

### In-sample fit: Residuals 

`$$e_i=y_i-\hat{y_i} \approx \epsilon_i$$`


.pull-left[


**Hypothetical (population) model**

`\(y_i=f(x_i)+\epsilon_i\)` 

&lt;small&gt;


เมื่อ `\(y_i\)` คือค่าสังเกตของตัวแปรตามใน training data และค่าคลาดเคลื่อนสุ่มมีข้อตกลงเบื้องต้นคือ `\(\epsilon_i \stackrel{i.i.d.}{\sim} Normal(0,\sigma^2)\)`

&lt;/small&gt;

**Estimated hypothetical model** 

`\(\hat{y_i}=\hat{f}(x_i) \approx f(x_i)\)` 

&lt;small&gt;

เรียก `\(\hat{y_i}\)` ว่าค่าทำนาย (predicted value) ของตัวแปรตาม โดยค่าทำนายนี้คำนวณจาก linear combination ของตัวแปรอิสระ

&lt;/small&gt;


]

.pull-right[




&lt;img src="week2_files/figure-html/unnamed-chunk-13-1.png" width="504" /&gt;
]


]

---
class: middle


.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]

.right-column[

### Types of residuals


.pull-left[
&lt;small&gt;

**raw residual:** 

`$$e_i=y_i-\hat{y}_i$$` 
&lt;small&gt;

การคำนวณเศษเหลือดังกล่าวใน R สามารถทำได้โดยใช้ฟังก์ชัน `residuals(lm.model)` เมื่อ `lm.model` คือ lm object

&lt;/small&gt;

**standardized residuals:**  

`$$e_i^*=\frac{e_i}{\sqrt{MSE(1-h_i)}}$$`
&lt;small&gt;

เมื่อ `\(h_i\)` คือค่า leverage ของ observation ที่ `\(i\)`

การคำนวณ standardized residuals ใน R สามารถทำได้โดยใช้ฟังก์ชัน `rstandard(lm.model)`

&lt;/small&gt;
]

.pull-right[
**deleted studentized residuals**

`$$d_i=\frac{y_i-\hat{y}_{(-i)}}{\sqrt{MSE_{-i}(1-h_i)}}$$`

&lt;small&gt;
เมื่อ `\(h_i\)` คือค่า leverage ของ observation ที่ `\(i\)`

การคำนวณ studentized residuals ใน R สามารถทำได้โดยใช้ฟังก์ชัน `rstudent(lm.model)`

&lt;/small&gt;

]

]



---
name: insample
class: middle


.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]

.right-column[


### In-sample fit: Residual plot


.pull-left[



```r
par(mfrow=c(2,2), mar=c(5,5,2,1))
plot(fit)
```

&lt;small&gt;

- [**residuals vs fitted**](#resfit) for checking `\(E[\epsilon|X]=0\)`

- **QQ plot: ordered residuals vs normal quantiles** for checking `\(\epsilon \sim Normal\)`

- [**Scale-location plot**](#hetero) for checking `\(Var[\epsilon|X]=\sigma^2\)`

- [**residuals vs leverage**](#resvslev) for detecting and evaluating influential outlier

&lt;/small&gt;


]

.pull.right[
&lt;img src="week2_files/figure-html/unnamed-chunk-15-1.png" width="360" /&gt;
]
]

---
class: middle
name: resfit

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]




.right-column[

### residuals vs fitted (1)



```r
par(mar=c(5,5,1,1))
plot(fit,1) #residuals vs fitted plot
```

&lt;img src="week2_files/figure-html/unnamed-chunk-16-1.png" width="360" /&gt;


]

---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]

.right-column[

.pull-left[
### residuals vs fitted (2)

&lt;small&gt;

**Misspecification model** residuals vs fitted plot สามารถใช้เพื่อวินิจฉัยการวิเคราะห์ระบุโมเดลทำนายผิดพลาดของผู้วิเคราะห์ได้ เช่น

* **True (unknown) population model** คือ `\(y=\beta_0+\beta_1x+\beta_2x^2+\epsilon\)`

* **Hypothetical model** ของผู้วิเคราะห์กลับเป็น `\(y=\beta_0+\beta_2x+u\)` `\(\rightarrow \hat{y}=b_0+b_1x\)` 

* จะเห็นว่า true population model กับ hypothetical model มีความแตกต่างกัน ซึ่งเกิดเป็นปัญหาการระบุโมเดลผิดพลาด (misspecification errors) ปัญหาดังกล่าวสามารถสะท้อนได้จากการวิเคราะห์เศษเหลือดังนี้ `\(e=y-\hat{y} \approx u = \beta_2x^2+\epsilon\)`

&lt;/small&gt;
]


.pull-right[

&lt;/br&gt;
&lt;/br&gt;

&lt;img src="week2_files/figure-html/unnamed-chunk-17-1.png" width="504" /&gt;

]
]

---
class: middle
name: hetero


.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]

.right-column[

### Scale-location plot (1)

&lt;small&gt;

* ใช้แสดงการกระจายของ residuals บนแต่ละระดับของตัวแปรอิสระ

* Homoscedasticity assumption `\(\rightarrow Var[\epsilon|X]=\sigma^2\)` ดังนั้นภายในข้อตกลงนี้การกระจายของ residuals ควรต้องมีขนาดที่ใกล้เคียงกันในแต่ละระดับของตัวแปรอิสระ

&lt;/small&gt;

&lt;img src="week2_files/figure-html/unnamed-chunk-18-1.png" width="504" /&gt;
]

---
class: middle
name: hetero


.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]

.right-column[

### Scale-location plot (2)

&lt;small&gt;
กรณีที่เกิดปัญหา heteroscedasticity การกระจายของ residuals จะไม่เท่ากันในแต่ละระดับของตัวแปรอิสระ และอาจเป็นฟังก์ชันที่ขึ้นกับตัวแปรอิสระด้วย ดังตัวอย่าง

&lt;/small&gt;

&lt;img src="week2_files/figure-html/unnamed-chunk-19-1.png" width="864" /&gt;
]

---
class: middle
name: hetero


.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]

.right-column[

### Breusch-Pagan Test

.pull-left[
&lt;small&gt;

The Breusch-Pagan test fits a linear regression model to the residuals of a linear regression model (by default the same explanatory variables are taken as in the main regression model) and rejects if too much of the variance is explained by the additional explanatory variables. ([Hotthorn et al.(2019)](https://cran.r-project.org/web/packages/lmtest/lmtest.pdf))

- คำนวณค่าเศษเหลือกำลังสองของโมเดล

`$$e^2_i=y_i-\hat{y}_i$$`


- ประมาณค่าสมการถดถอยของเศษเหลือกำลังสองกับตัวแปรอิสระหรือ linear combination ของตัวแปรอิสระ 

`$$e_i^2=\alpha_0+\alpha_1\hat{y}_i+\nu_i$$`
&lt;/small&gt;
]

.pull-right[

&lt;small&gt;

- ทดสอบนัยสำคัญของ heteroscadasticity `\(H_0: \alpha_1=0\)` โดยตัวสถิติทดสอบคือ Lagrange multiplier (LM test) คำนวณดังนี้

`$$LM = nR^2 \sim \chi^2_{df=จำนวนพารามิเตอร์}$$`

&lt;/small&gt;


```r
#install.packages("lmtest")
library(lmtest)
bptest(Salary~YearsExperience, data=train.dat)
```

```
## 
## 	studentized Breusch-Pagan test
## 
## data:  Salary ~ YearsExperience
## BP = 6.6339e-06, df = 1, p-value = 0.9979
```
]

]
---
class: middle
name: hetero


.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]

.right-column[

### White's Test

&lt;small&gt;

อีกวิธีการหนึ่งที่สามารถใช้สำรวจปัญหา heteroscedasticity คือการใช้สถิติทดสอบ White's test ที่ใช้เศษเหลือของโมเดลการวิเคราะห์เป็นข้อมูลสำหรับคำนวณสถิติทดสอบ มีขั้นตอนดังนี้

1. คำนวณค่าเศษเหลือกำลังสองของโมเดล `\(e^2_i=y_i-\hat{y}_i\)`

2. ประมาณค่าสมการถดถอย `\(e_i^2=\alpha_0+\alpha_1\hat{y}_i+\alpha_2\hat{y}^2_i\)`

3. ทดสอบนัยสำคัญของ heteroscadasticity `\(H_0: \alpha_1=\alpha_2=0\)` โดยตัวสถิติทดสอบคือ Lagrange multiplier (LM test) คำนวณดังนี้

`$$LM = nR^2 \sim \chi^2_{df=จำนวนพารามิเตอร์}$$`
&lt;/small&gt;

]

---
name: outlier
class: middle



.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]


.right-column[


.pull-left[
&lt;small&gt;

### Outliers

หน่วยข้อมูลที่มีค่าสังเกตของตัวแปรอยู่ในตำแหน่งที่ห่างไกลจากค่าสังเกตส่วนใหญ่ชุดข้อมูล เรียกว่าค่าผิดปกติ (outlier)

&lt;/small&gt;

&lt;img src="week2_files/figure-html/unnamed-chunk-21-1.png" width="360" /&gt;
]





.pull-right[

### Influential observation

&lt;small&gt;

- ค่าผิดปกติบางค่าอาจไม่ได้ส่งผลกระทบอะไรต่อการประมาณค่าพารามิเตอร์ในโมเดล แต่บางค่าก็อาจส่งผลกระทบอย่างมาก

- ค่าผิดปกติที่เมื่อถูกนำออกจากการประมาณค่าพารามิเตอร์ของโมเดลแล้วทำให้ค่าประมาณหรือค่าทำนายของโมเดลมีการเปลี่ยนแปลงไปอย่างมีนัยสำคัญ จะเรียกว่า [**ค่าสังเกตที่มีอิทธิพล (influential observations)**](https://shiny.rit.albany.edu/stat/outliers/)


&lt;/small&gt;

&lt;center&gt;&lt;img src="influential.png" width=80%&gt;&lt;/center&gt;

]

]


---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]


.right-column[

.pull-left[

### Leverage measure

`\(h_i=\frac{1}{n}+\frac{(x_i-\overline{x})^2}{\sum_j(x_j-\overline{x})^2}\)`

&lt;small&gt;

ค่า leverage value มีคุณสมบัติคือ

- `\(\sum_{i=1}^nh_i=p+1\)` เมื่อ `\(p\)` คือจำนวนตัวแปรอิสระของโมเดล ซึ่งจะได้ว่า `\(\overline{h}=\frac{p+1}{n}\)`

- เกณฑ์การพิจารณาระดับ leverage ของหน่วยข้อมูลจึงอาจพิจารณาจากจำนวนของค่าเฉลี่ยข้างต้น เช่น `\(h_i&gt;2\overline{h}\)`
 หรือ `\(h_i&gt;3\overline{h}\)` เป็นต้น
 
&lt;/small&gt;

]

.pull-right[



```r
leverage&lt;-hatvalues(fit)
par(mar=c(5,1,1,1))
boxplot(leverage,horizontal = T)
```

&lt;img src="week2_files/figure-html/unnamed-chunk-22-1.png" width="288" /&gt;



```r
summary(leverage)
```

```
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 0.04189 0.05205 0.07197 0.08333 0.10886 0.17880
```

]

]

---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]


.right-column[


.pull-left[
### Influence measure: Cook's Distance

&lt;small&gt;

Cook's distance วัดปริมาณการเปลี่ยนแปลงของค่าพารามิเตอร์ในโมเดล เมื่อตัดค่าสังเกตที่ `\(i\)` ออกจากโมเดลการวิเคราะห์

`\(D_i=\frac{y_i-\hat{y}_i}{MSE(1-h_i)}\times\frac{h_i}{1-h_i}\times\frac{1}{p+1}\)`

เมื่อ `\(p\)` คือจำนวนตัวแปรอิสระภายในโมเดล โดยเกณฑ์การพิจารณาค่าสังเกตที่มีอิทธิพลเช่น `\(D_i&gt;0.5\)` หรือ `\(D_i&gt;1\)`

&lt;/small&gt;
]

.pull-right[


```r
cook&lt;-cooks.distance(fit)
summary(cook)
```

```
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## 7.138e-05 2.038e-03 3.380e-02 3.789e-02 6.113e-02 1.418e-01
```


```r
par(mar=c(5,5,1,1))
plot(leverage,cook,xlim=c(0,0.2),pch=16)
```

&lt;img src="week2_files/figure-html/unnamed-chunk-25-1.png" width="432" /&gt;


]

]


---
name: resvslev
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]


.right-column[

### Residuals vs Leverage


```r
par(mar=c(5,5,1,1))
plot(fit,5)
```

&lt;img src="week2_files/figure-html/unnamed-chunk-26-1.png" width="576" /&gt;

]

---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression


]

.right-column[

.pull-left[
### DFFITs

- use to indicate the influential observation

- standardized function of difference between the predicted value for the observation when it is included in the dataset and when (only) it is excluded from the dataset.

`$$DFFITs=\frac{\hat{y}_i-\hat{y}_{i(-i)}}{\sqrt{MSE_{-i}h_i}}$$`
]

.pull-right[

```r
dffits&lt;-dffits(fit)
summary(dffits)
```

```
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## -0.410368 -0.302310 -0.004315 -0.011456  0.221940  0.562698
```

```r
par(mar=c(5,5,1,1))
plot(leverage,dffits)
```

&lt;img src="week2_files/figure-html/unnamed-chunk-27-1.png" width="432" /&gt;
]
]

---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]


.right-column[

### In-sample fit (Goodness of fit: R-square)

&lt;center&gt;&lt;img src="partitionSS.png" width=100%&gt;&lt;/center&gt;

]



---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]

.right-column[

### Badness of fit





- **RMSE (root mean squared error): ** `\(RMSE = \sqrt{\frac{SSError}{df}}=\sqrt{\frac{SSError}{n-k}}\)`


- **MAE (mean absolute error): ** `\(MAE = \sum_{i=1}^n \frac{|y_i-\hat{y}_i|}{(n-p-1)}\)` 

&lt;small&gt;

&lt;p style="text-indent:2.7em;"&gt;เมื่อ `\(p\)` คือจำนวนตัวแปรอิสระ&lt;/p&gt;

&lt;/small&gt;

- **-2LL (deviance): ** `\(-2LL=-2ln(\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-\hat{y}_i)^2})\)`


&lt;small&gt;

&lt;p style="text-indent:2.7em;"&gt;Note: normality assumption must be assumed.&lt;/p&gt;

&lt;/small&gt;

- **BIC (bayesian information criterion): ** `\(BIC = ln(n)(p+1)-2LL\)`






]

---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

**&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;**
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* Multiple Regression

]


.right-column[

### In-sample fit: Biased or Underfitting Model

&lt;img src="biasedmodel.png"&gt;



- เปลี่ยนหรือเพิ่มตัวแปรอิสระในโมเดล

- ลดการกำหนดข้อจำกัด (contraints) ของโมเดล

- เปลี่ยน algorithm ที่ใช้ในการเรียนรู้ เช่น regularization, bagging หรือ boosting เป็นต้น

]

---
name: outsample
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* **Evaluating Models**

&lt;p style="text-indent:3em;"&gt;[- In-sample fit](#insample)&lt;/p&gt;
**&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;**

* Multiple Regression

]


.right-column[

### Out-sample fit (Model Evaluation)

&lt;img src="outsample.png"&gt;



```r
test&lt;-test.dat$Salary # Salary in test data
predict&lt;-predict(fit,test.dat) # predicted value in test data
RMSE&lt;-sqrt(sum(test-predict)^2/length(test)) # calculate test data RMSE
R2&lt;-cor(test,predict)^2 # calculate test data R-square
```

.pull-left[


```r
RMSE
```

```
## [1] 3675.618
```

]

.pull-right[


```r
R2
```

```
## [1] 0.9551703
```

]

]

---
class: middle
name: MRA

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* Evaluating Models

&lt;p style="text-indent:3em;"&gt;- In-sample fit&lt;/p&gt;
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* **Multiple Regression**

]

.right-column[

### Multiple Regression

&lt;img src="MRA.png" width=80%&gt;

]

---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* Evaluating Models

&lt;p style="text-indent:3em;"&gt;- In-sample fit&lt;/p&gt;
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* [**Multiple Regression**](#MRA)

]

.right-column[

### Multiple Regression


**Hypothetical model**

`\(y_i=f(x_i)+\epsilon_i\)`

**Fitted function**

`\(\hat{y}_i=b_0+b_1x_1+b_2x_2+...+b_px_p=\sum_{j=0}^p b_jx_j\)`


&lt;img src="MRA2.png" width=50%&gt;


]

---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* Evaluating Models

&lt;p style="text-indent:3em;"&gt;- In-sample fit&lt;/p&gt;
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* [**Multiple Regression**](#MRA)

]

.right-column[

### Multiple Regression

ปัจจัยทางเศรษฐกิจและสังคม สภาพภูมิอากาศ และภูมิศาสตร์ มีผลอย่างไรต่ออัตราการฆาตกรรม? และสามารถใช้ทำนายอัตราการฆาตกรรมได้หรือไม่?





```r
head(state.x77)
```

```
##            Population Income Illiteracy Life Exp Murder HS Grad Frost   Area
## Alabama          3615   3624        2.1    69.05   15.1    41.3    20  50708
## Alaska            365   6315        1.5    69.31   11.3    66.7   152 566432
## Arizona          2212   4530        1.8    70.55    7.8    58.1    15 113417
## Arkansas         2110   3378        1.9    70.66   10.1    39.9    65  51945
## California      21198   5114        1.1    71.71   10.3    62.6    20 156361
## Colorado         2541   4884        0.7    72.06    6.8    63.9   166 103766
```



```r
class(state.x77)
```

```
## [1] "matrix" "array"
```

]


---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* Evaluating Models

&lt;p style="text-indent:3em;"&gt;- In-sample fit&lt;/p&gt;
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* [**Multiple Regression**](#MRA)

]

.right-column[



```r
dat2&lt;-data.frame(state.x77) # convert matrix "state.x77" into data.frame
round(cor(dat2),2)
```

```
##            Population Income Illiteracy Life.Exp Murder HS.Grad Frost  Area
## Population       1.00   0.21       0.11    -0.07   0.34   -0.10 -0.33  0.02
## Income           0.21   1.00      -0.44     0.34  -0.23    0.62  0.23  0.36
## Illiteracy       0.11  -0.44       1.00    -0.59   0.70   -0.66 -0.67  0.08
## Life.Exp        -0.07   0.34      -0.59     1.00  -0.78    0.58  0.26 -0.11
## Murder           0.34  -0.23       0.70    -0.78   1.00   -0.49 -0.54  0.23
## HS.Grad         -0.10   0.62      -0.66     0.58  -0.49    1.00  0.37  0.33
## Frost           -0.33   0.23      -0.67     0.26  -0.54    0.37  1.00  0.06
## Area             0.02   0.36       0.08    -0.11   0.23    0.33  0.06  1.00
```
]

---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* Evaluating Models

&lt;p style="text-indent:3em;"&gt;- In-sample fit&lt;/p&gt;
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* [**Multiple Regression**](#MRA)


&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;

&lt;small&gt;

- **Note:** [correlation matrix visualization](https://briatte.github.io/ggcorr/)

&lt;/small&gt;
]

.right-column[



```r
#install.packages(c("GGally","ggplot2"))
library(ggplot2)
library(GGally)

ggcorr(dat2, geom = "blank", label = TRUE, hjust = 0.75) +
  geom_point(size = 10, aes(color = coefficient &gt; 0, alpha = abs(coefficient) &gt; 0.5)) +
  scale_alpha_manual(values = c("TRUE" = 0.25, "FALSE" = 0)) +
  guides(color = FALSE, alpha = FALSE)+
  theme(plot.margin = margin(1,1,1,1))
```

&lt;img src="week2_files/figure-html/unnamed-chunk-34-1.png" width="504" /&gt;
]

]

---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* Evaluating Models

&lt;p style="text-indent:3em;"&gt;- In-sample fit&lt;/p&gt;
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* [**Multiple Regression**](#MRA)

]

.right-column[

### Splitting Data


```r
dat2$id&lt;-1:dim(state.x77)[1] 
train.id&lt;-sample(dat2$id,0.8*dim(state.x77)[1])
train.dat&lt;-dat2[train.id,]
test.dat&lt;-dat2[-train.id,]
```


```r
dim(train.dat)
```

```
## [1] 40  9
```

```r
dim(test.dat)
```

```
## [1] 10  9
```

]


---
class: middle

.left-column[

## Linear Regression


* Basic Concepts

* Training Models

* Evaluating Models

&lt;p style="text-indent:3em;"&gt;- In-sample fit&lt;/p&gt;
&lt;p style="text-indent:3em;"&gt;- Out-sample fit&lt;/p&gt;

* [**Multiple Regression**](#MRA)

]

.right-column[

### Fitting MRA to the Training data (All in)


```r
fit.mra&lt;-lm(Murder~., data=train.dat)
summary(fit.mra)
```

```
## 
## Call:
## lm(formula = Murder ~ ., data = train.dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3840 -1.0666  0.0322  1.0294  3.5121 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.147e+02  2.150e+01   5.336  8.2e-06 ***
## Population   1.672e-04  7.170e-05   2.333   0.0263 *  
## Income       1.192e-04  7.446e-04   0.160   0.8738    
## Illiteracy   1.364e+00  9.763e-01   1.397   0.1725    
## Life.Exp    -1.538e+00  3.071e-01  -5.009  2.1e-05 ***
## HS.Grad      3.223e-03  6.934e-02   0.046   0.9632    
## Frost       -1.281e-02  9.519e-03  -1.346   0.1881    
## Area         5.098e-06  4.129e-06   1.235   0.2262    
## id          -1.118e-02  2.344e-02  -0.477   0.6366    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.793 on 31 degrees of freedom
## Multiple R-squared:  0.8078,	Adjusted R-squared:  0.7582 
## F-statistic: 16.28 on 8 and 31 DF,  p-value: 3.882e-09
```

]

---
name: yourturn1
template: yourturn

.right-column[

### Model validation and Evaluvation


&lt;small&gt;

- ขอให้นิสิตวิเคราะห์ in-sample fit และ out-sample fit ของโมเดล All in ในข้างต้น

- assumption เฉพาะของ MRA คือ no multicollinearity ผู้วิเคราะห์สามารถใช้ค่า variance inflation factor (VIF) เพื่อตรวจสอบ assumption ดังกล่าวได้ ฟังก์ชันใน R สำหรับคำนวณค่าสถิติ VIF คือ `vif(lm.model)`

&lt;/small&gt;

]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
